2019-03-26 14:32:22 [scrapy.utils.log] INFO: Scrapy 1.6.0 started (bot: GovSpider2)
2019-03-26 14:32:22 [scrapy.utils.log] INFO: Versions: lxml 4.3.2.0, libxml2 2.9.9, cssselect 1.0.3, parsel 1.5.1, w3lib 1.20.0, Twisted 18.9.0, Python 3.7.2 (default, Feb 13 2019, 10:07:58) - [Clang 10.0.0 (clang-1000.11.45.5)], pyOpenSSL 19.0.0 (OpenSSL 1.1.1b  26 Feb 2019), cryptography 2.6.1, Platform Darwin-18.2.0-x86_64-i386-64bit
2019-03-26 14:32:22 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'GovSpider2', 'LOG_FILE': 'log/spiderlog20190326.txt', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'GovSpider2.spiders', 'ROBOTSTXT_OBEY': True, 'SPIDER_MODULES': ['GovSpider2.spiders']}
2019-03-26 14:32:22 [scrapy.extensions.telnet] INFO: Telnet Password: b9d09ed0df5650ac
2019-03-26 14:32:22 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats']
2019-03-26 14:32:22 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.robotstxt.RobotsTxtMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2019-03-26 14:32:22 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2019-03-26 14:32:22 [scrapy.middleware] INFO: Enabled item pipelines:
['GovSpider2.pipelines.Govspider2Pipeline']
2019-03-26 14:32:22 [scrapy.core.engine] INFO: Spider opened
2019-03-26 14:32:22 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-03-26 14:32:22 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023
2019-03-26 14:32:25 [scrapy.spidermiddlewares.httperror] INFO: Ignoring response <404 http://www.lm.gov.cn/gb/employment/2004-06/04/content_34302.htm>: HTTP status code is not handled or not allowed
2019-03-26 14:32:25 [scrapy.spidermiddlewares.httperror] INFO: Ignoring response <404 http://www.lm.gov.cn/gb/employment/2004-06/30/content_38180.htm>: HTTP status code is not handled or not allowed
2019-03-26 14:32:25 [scrapy.spidermiddlewares.httperror] INFO: Ignoring response <404 http://www.lm.gov.cn/gb/employment/2004-07/09/content_31814.htm>: HTTP status code is not handled or not allowed
2019-03-26 14:32:28 [scrapy.core.engine] INFO: Closing spider (finished)
2019-03-26 14:32:28 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 89827,
 'downloader/request_count': 244,
 'downloader/request_method_count/GET': 244,
 'downloader/response_bytes': 4283458,
 'downloader/response_count': 244,
 'downloader/response_status_count/200': 240,
 'downloader/response_status_count/404': 4,
 'dupefilter/filtered': 321,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2019, 3, 26, 6, 32, 28, 325382),
 'httperror/response_ignored_count': 3,
 'httperror/response_ignored_status_count/404': 3,
 'log_count/INFO': 12,
 'memusage/max': 50085888,
 'memusage/startup': 50081792,
 'offsite/domains': 3,
 'offsite/filtered': 3,
 'request_depth_max': 2,
 'response_received_count': 244,
 'robotstxt/request_count': 2,
 'robotstxt/response_count': 2,
 'robotstxt/response_status_count/200': 1,
 'robotstxt/response_status_count/404': 1,
 'scheduler/dequeued': 242,
 'scheduler/dequeued/memory': 242,
 'scheduler/enqueued': 242,
 'scheduler/enqueued/memory': 242,
 'start_time': datetime.datetime(2019, 3, 26, 6, 32, 22, 276427)}
2019-03-26 14:32:28 [scrapy.core.engine] INFO: Spider closed (finished)
2019-03-26 14:39:51 [scrapy.utils.log] INFO: Scrapy 1.6.0 started (bot: GovSpider2)
2019-03-26 14:39:51 [scrapy.utils.log] INFO: Versions: lxml 4.3.2.0, libxml2 2.9.9, cssselect 1.0.3, parsel 1.5.1, w3lib 1.20.0, Twisted 18.9.0, Python 3.7.2 (default, Feb 13 2019, 10:07:58) - [Clang 10.0.0 (clang-1000.11.45.5)], pyOpenSSL 19.0.0 (OpenSSL 1.1.1b  26 Feb 2019), cryptography 2.6.1, Platform Darwin-18.2.0-x86_64-i386-64bit
2019-03-26 14:39:51 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'GovSpider2', 'LOG_FILE': 'log/spiderlog20190326.txt', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'GovSpider2.spiders', 'ROBOTSTXT_OBEY': True, 'SPIDER_MODULES': ['GovSpider2.spiders']}
2019-03-26 14:39:51 [scrapy.extensions.telnet] INFO: Telnet Password: 3cd22c1ce25cdd97
2019-03-26 14:39:51 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats']
2019-03-26 14:39:51 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.robotstxt.RobotsTxtMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2019-03-26 14:39:51 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2019-03-26 14:39:51 [scrapy.middleware] INFO: Enabled item pipelines:
['GovSpider2.pipelines.Govspider2Pipeline']
2019-03-26 14:39:51 [scrapy.core.engine] INFO: Spider opened
2019-03-26 14:39:51 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-03-26 14:39:51 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023
2019-03-26 14:39:53 [scrapy.core.engine] INFO: Closing spider (finished)
2019-03-26 14:39:53 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 13963,
 'downloader/request_count': 38,
 'downloader/request_method_count/GET': 38,
 'downloader/response_bytes': 623719,
 'downloader/response_count': 38,
 'downloader/response_status_count/200': 38,
 'dupefilter/filtered': 35,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2019, 3, 26, 6, 39, 53, 652665),
 'log_count/INFO': 9,
 'memusage/max': 49893376,
 'memusage/startup': 49889280,
 'request_depth_max': 2,
 'response_received_count': 38,
 'robotstxt/request_count': 1,
 'robotstxt/response_count': 1,
 'robotstxt/response_status_count/200': 1,
 'scheduler/dequeued': 37,
 'scheduler/dequeued/memory': 37,
 'scheduler/enqueued': 37,
 'scheduler/enqueued/memory': 37,
 'start_time': datetime.datetime(2019, 3, 26, 6, 39, 51, 202055)}
2019-03-26 14:39:53 [scrapy.core.engine] INFO: Spider closed (finished)
2019-03-26 14:40:28 [scrapy.utils.log] INFO: Scrapy 1.6.0 started (bot: GovSpider2)
2019-03-26 14:40:28 [scrapy.utils.log] INFO: Versions: lxml 4.3.2.0, libxml2 2.9.9, cssselect 1.0.3, parsel 1.5.1, w3lib 1.20.0, Twisted 18.9.0, Python 3.7.2 (default, Feb 13 2019, 10:07:58) - [Clang 10.0.0 (clang-1000.11.45.5)], pyOpenSSL 19.0.0 (OpenSSL 1.1.1b  26 Feb 2019), cryptography 2.6.1, Platform Darwin-18.2.0-x86_64-i386-64bit
2019-03-26 14:40:28 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'GovSpider2', 'LOG_FILE': 'log/spiderlog20190326.txt', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'GovSpider2.spiders', 'ROBOTSTXT_OBEY': True, 'SPIDER_MODULES': ['GovSpider2.spiders']}
2019-03-26 14:40:28 [scrapy.extensions.telnet] INFO: Telnet Password: ec8351c0e8a1c7b0
2019-03-26 14:40:28 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats']
2019-03-26 14:40:28 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.robotstxt.RobotsTxtMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2019-03-26 14:40:28 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2019-03-26 14:40:28 [scrapy.middleware] INFO: Enabled item pipelines:
['GovSpider2.pipelines.Govspider2Pipeline']
2019-03-26 14:40:28 [scrapy.core.engine] INFO: Spider opened
2019-03-26 14:40:28 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-03-26 14:40:28 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023
2019-03-26 14:40:28 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.gov.cn/banshi/2005-07/06/content_12279.htm> (referer: http://www.gov.cn/banshi/wjrs/crj.htm)
Traceback (most recent call last):
  File "/usr/local/lib/python3.7/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python3.7/site-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/Users/a824810056/Desktop/py2.7-GovSpider/GovSpider2/GovSpider2/spiders/govSpider.py", line 55, in parse_item
    subStr = referUrl.rsplit('/')
TypeError: a bytes-like object is required, not 'str'
2019-03-26 14:40:29 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.gov.cn/banshi/2005-05/26/content_1300.htm> (referer: http://www.gov.cn/banshi/wjrs/crj.htm)
Traceback (most recent call last):
  File "/usr/local/lib/python3.7/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python3.7/site-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/Users/a824810056/Desktop/py2.7-GovSpider/GovSpider2/GovSpider2/spiders/govSpider.py", line 55, in parse_item
    subStr = referUrl.rsplit('/')
TypeError: a bytes-like object is required, not 'str'
2019-03-26 14:40:29 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.gov.cn/banshi/2005-07/08/content_13036.htm> (referer: http://www.gov.cn/banshi/wjrs/crj.htm)
Traceback (most recent call last):
  File "/usr/local/lib/python3.7/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python3.7/site-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/Users/a824810056/Desktop/py2.7-GovSpider/GovSpider2/GovSpider2/spiders/govSpider.py", line 55, in parse_item
    subStr = referUrl.rsplit('/')
TypeError: a bytes-like object is required, not 'str'
2019-03-26 14:40:29 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.gov.cn/banshi/2006-10/09/content_408016.htm> (referer: http://www.gov.cn/banshi/wjrs/crj.htm)
Traceback (most recent call last):
  File "/usr/local/lib/python3.7/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python3.7/site-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/Users/a824810056/Desktop/py2.7-GovSpider/GovSpider2/GovSpider2/spiders/govSpider.py", line 55, in parse_item
    subStr = referUrl.rsplit('/')
TypeError: a bytes-like object is required, not 'str'
2019-03-26 14:40:29 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.gov.cn/banshi/2006-08/23/content_368260.htm> (referer: http://www.gov.cn/banshi/wjrs/crj.htm)
Traceback (most recent call last):
  File "/usr/local/lib/python3.7/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python3.7/site-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/Users/a824810056/Desktop/py2.7-GovSpider/GovSpider2/GovSpider2/spiders/govSpider.py", line 55, in parse_item
    subStr = referUrl.rsplit('/')
TypeError: a bytes-like object is required, not 'str'
2019-03-26 14:40:29 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.gov.cn/banshi/2006-10/09/content_408005.htm> (referer: http://www.gov.cn/banshi/wjrs/crj.htm)
Traceback (most recent call last):
  File "/usr/local/lib/python3.7/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python3.7/site-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/Users/a824810056/Desktop/py2.7-GovSpider/GovSpider2/GovSpider2/spiders/govSpider.py", line 55, in parse_item
    subStr = referUrl.rsplit('/')
TypeError: a bytes-like object is required, not 'str'
2019-03-26 14:40:29 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.gov.cn/banshi/2006-10/09/content_408018.htm> (referer: http://www.gov.cn/banshi/wjrs/crj.htm)
Traceback (most recent call last):
  File "/usr/local/lib/python3.7/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python3.7/site-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/Users/a824810056/Desktop/py2.7-GovSpider/GovSpider2/GovSpider2/spiders/govSpider.py", line 55, in parse_item
    subStr = referUrl.rsplit('/')
TypeError: a bytes-like object is required, not 'str'
2019-03-26 14:40:29 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.gov.cn/banshi/2006-10/09/content_408010.htm> (referer: http://www.gov.cn/banshi/wjrs/crj.htm)
Traceback (most recent call last):
  File "/usr/local/lib/python3.7/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python3.7/site-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/Users/a824810056/Desktop/py2.7-GovSpider/GovSpider2/GovSpider2/spiders/govSpider.py", line 55, in parse_item
    subStr = referUrl.rsplit('/')
TypeError: a bytes-like object is required, not 'str'
2019-03-26 14:40:29 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.gov.cn/banshi/2005-06/08/content_4837.htm> (referer: http://www.gov.cn/banshi/wjrs/crj.htm)
Traceback (most recent call last):
  File "/usr/local/lib/python3.7/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python3.7/site-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/Users/a824810056/Desktop/py2.7-GovSpider/GovSpider2/GovSpider2/spiders/govSpider.py", line 55, in parse_item
    subStr = referUrl.rsplit('/')
TypeError: a bytes-like object is required, not 'str'
2019-03-26 14:40:29 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.gov.cn/banshi/2005-06/08/content_4836.htm> (referer: http://www.gov.cn/banshi/wjrs/crj.htm)
Traceback (most recent call last):
  File "/usr/local/lib/python3.7/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python3.7/site-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/Users/a824810056/Desktop/py2.7-GovSpider/GovSpider2/GovSpider2/spiders/govSpider.py", line 55, in parse_item
    subStr = referUrl.rsplit('/')
TypeError: a bytes-like object is required, not 'str'
2019-03-26 14:40:29 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.gov.cn/banshi/2007-05/10/content_610216.htm> (referer: http://www.gov.cn/banshi/wjrs/crj.htm)
Traceback (most recent call last):
  File "/usr/local/lib/python3.7/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python3.7/site-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/Users/a824810056/Desktop/py2.7-GovSpider/GovSpider2/GovSpider2/spiders/govSpider.py", line 55, in parse_item
    subStr = referUrl.rsplit('/')
TypeError: a bytes-like object is required, not 'str'
2019-03-26 14:40:29 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.gov.cn/banshi/2012-11/19/content_2269877.htm> (referer: http://www.gov.cn/banshi/wjrs/crj.htm)
Traceback (most recent call last):
  File "/usr/local/lib/python3.7/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python3.7/site-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/Users/a824810056/Desktop/py2.7-GovSpider/GovSpider2/GovSpider2/spiders/govSpider.py", line 55, in parse_item
    subStr = referUrl.rsplit('/')
TypeError: a bytes-like object is required, not 'str'
2019-03-26 14:40:29 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.gov.cn/banshi/2012-11/19/content_2269878.htm> (referer: http://www.gov.cn/banshi/wjrs/crj.htm)
Traceback (most recent call last):
  File "/usr/local/lib/python3.7/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python3.7/site-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/Users/a824810056/Desktop/py2.7-GovSpider/GovSpider2/GovSpider2/spiders/govSpider.py", line 55, in parse_item
    subStr = referUrl.rsplit('/')
TypeError: a bytes-like object is required, not 'str'
2019-03-26 14:40:29 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.gov.cn/banshi/2005-09/12/content_31017.htm> (referer: http://www.gov.cn/banshi/wjrs/crj.htm)
Traceback (most recent call last):
  File "/usr/local/lib/python3.7/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python3.7/site-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/Users/a824810056/Desktop/py2.7-GovSpider/GovSpider2/GovSpider2/spiders/govSpider.py", line 55, in parse_item
    subStr = referUrl.rsplit('/')
TypeError: a bytes-like object is required, not 'str'
2019-03-26 14:40:29 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.gov.cn/banshi/2006-10/09/content_408014.htm> (referer: http://www.gov.cn/banshi/wjrs/crj.htm)
Traceback (most recent call last):
  File "/usr/local/lib/python3.7/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python3.7/site-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/Users/a824810056/Desktop/py2.7-GovSpider/GovSpider2/GovSpider2/spiders/govSpider.py", line 55, in parse_item
    subStr = referUrl.rsplit('/')
TypeError: a bytes-like object is required, not 'str'
2019-03-26 14:40:29 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.gov.cn/banshi/2012-11/19/content_2269879.htm> (referer: http://www.gov.cn/banshi/wjrs/crj.htm)
Traceback (most recent call last):
  File "/usr/local/lib/python3.7/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python3.7/site-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/Users/a824810056/Desktop/py2.7-GovSpider/GovSpider2/GovSpider2/spiders/govSpider.py", line 55, in parse_item
    subStr = referUrl.rsplit('/')
TypeError: a bytes-like object is required, not 'str'
2019-03-26 14:40:29 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.gov.cn/banshi/2012-11/19/content_2269876.htm> (referer: http://www.gov.cn/banshi/wjrs/crj.htm)
Traceback (most recent call last):
  File "/usr/local/lib/python3.7/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python3.7/site-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/Users/a824810056/Desktop/py2.7-GovSpider/GovSpider2/GovSpider2/spiders/govSpider.py", line 55, in parse_item
    subStr = referUrl.rsplit('/')
TypeError: a bytes-like object is required, not 'str'
2019-03-26 14:40:29 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.gov.cn/banshi/2012-11/19/content_2269880.htm> (referer: http://www.gov.cn/banshi/wjrs/crj.htm)
Traceback (most recent call last):
  File "/usr/local/lib/python3.7/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python3.7/site-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/Users/a824810056/Desktop/py2.7-GovSpider/GovSpider2/GovSpider2/spiders/govSpider.py", line 55, in parse_item
    subStr = referUrl.rsplit('/')
TypeError: a bytes-like object is required, not 'str'
2019-03-26 14:40:29 [scrapy.core.engine] INFO: Closing spider (finished)
2019-03-26 14:40:29 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 7317,
 'downloader/request_count': 20,
 'downloader/request_method_count/GET': 20,
 'downloader/response_bytes': 335313,
 'downloader/response_count': 20,
 'downloader/response_status_count/200': 20,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2019, 3, 26, 6, 40, 29, 335067),
 'log_count/ERROR': 18,
 'log_count/INFO': 9,
 'memusage/max': 49856512,
 'memusage/startup': 49852416,
 'request_depth_max': 1,
 'response_received_count': 20,
 'robotstxt/request_count': 1,
 'robotstxt/response_count': 1,
 'robotstxt/response_status_count/200': 1,
 'scheduler/dequeued': 19,
 'scheduler/dequeued/memory': 19,
 'scheduler/enqueued': 19,
 'scheduler/enqueued/memory': 19,
 'spider_exceptions/TypeError': 18,
 'start_time': datetime.datetime(2019, 3, 26, 6, 40, 28, 667962)}
2019-03-26 14:40:29 [scrapy.core.engine] INFO: Spider closed (finished)
2019-03-26 14:41:03 [scrapy.utils.log] INFO: Scrapy 1.6.0 started (bot: GovSpider2)
2019-03-26 14:41:03 [scrapy.utils.log] INFO: Versions: lxml 4.3.2.0, libxml2 2.9.9, cssselect 1.0.3, parsel 1.5.1, w3lib 1.20.0, Twisted 18.9.0, Python 3.7.2 (default, Feb 13 2019, 10:07:58) - [Clang 10.0.0 (clang-1000.11.45.5)], pyOpenSSL 19.0.0 (OpenSSL 1.1.1b  26 Feb 2019), cryptography 2.6.1, Platform Darwin-18.2.0-x86_64-i386-64bit
2019-03-26 14:41:03 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'GovSpider2', 'LOG_FILE': 'log/spiderlog20190326.txt', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'GovSpider2.spiders', 'ROBOTSTXT_OBEY': True, 'SPIDER_MODULES': ['GovSpider2.spiders']}
2019-03-26 14:41:03 [scrapy.extensions.telnet] INFO: Telnet Password: 12e13398d797c73c
2019-03-26 14:41:03 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats']
2019-03-26 14:41:03 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.robotstxt.RobotsTxtMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2019-03-26 14:41:03 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2019-03-26 14:41:03 [scrapy.middleware] INFO: Enabled item pipelines:
['GovSpider2.pipelines.Govspider2Pipeline']
2019-03-26 14:41:03 [scrapy.core.engine] INFO: Spider opened
2019-03-26 14:41:03 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-03-26 14:41:03 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023
2019-03-26 14:41:04 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.gov.cn/banshi/2005-07/06/content_12279.htm> (referer: http://www.gov.cn/banshi/wjrs/crj.htm)
Traceback (most recent call last):
  File "/usr/local/lib/python3.7/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python3.7/site-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/Users/a824810056/Desktop/py2.7-GovSpider/GovSpider2/GovSpider2/spiders/govSpider.py", line 55, in parse_item
    subStr = referUrl.rsplit('/')
TypeError: a bytes-like object is required, not 'str'
2019-03-26 14:41:04 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.gov.cn/banshi/2006-10/09/content_408010.htm> (referer: http://www.gov.cn/banshi/wjrs/crj.htm)
Traceback (most recent call last):
  File "/usr/local/lib/python3.7/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python3.7/site-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/Users/a824810056/Desktop/py2.7-GovSpider/GovSpider2/GovSpider2/spiders/govSpider.py", line 55, in parse_item
    subStr = referUrl.rsplit('/')
TypeError: a bytes-like object is required, not 'str'
2019-03-26 14:41:04 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.gov.cn/banshi/2005-07/08/content_13036.htm> (referer: http://www.gov.cn/banshi/wjrs/crj.htm)
Traceback (most recent call last):
  File "/usr/local/lib/python3.7/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python3.7/site-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/Users/a824810056/Desktop/py2.7-GovSpider/GovSpider2/GovSpider2/spiders/govSpider.py", line 55, in parse_item
    subStr = referUrl.rsplit('/')
TypeError: a bytes-like object is required, not 'str'
2019-03-26 14:41:04 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.gov.cn/banshi/2005-05/26/content_1300.htm> (referer: http://www.gov.cn/banshi/wjrs/crj.htm)
Traceback (most recent call last):
  File "/usr/local/lib/python3.7/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python3.7/site-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/Users/a824810056/Desktop/py2.7-GovSpider/GovSpider2/GovSpider2/spiders/govSpider.py", line 55, in parse_item
    subStr = referUrl.rsplit('/')
TypeError: a bytes-like object is required, not 'str'
2019-03-26 14:41:04 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.gov.cn/banshi/2006-10/09/content_408016.htm> (referer: http://www.gov.cn/banshi/wjrs/crj.htm)
Traceback (most recent call last):
  File "/usr/local/lib/python3.7/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python3.7/site-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/Users/a824810056/Desktop/py2.7-GovSpider/GovSpider2/GovSpider2/spiders/govSpider.py", line 55, in parse_item
    subStr = referUrl.rsplit('/')
TypeError: a bytes-like object is required, not 'str'
2019-03-26 14:41:04 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.gov.cn/banshi/2005-06/08/content_4836.htm> (referer: http://www.gov.cn/banshi/wjrs/crj.htm)
Traceback (most recent call last):
  File "/usr/local/lib/python3.7/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python3.7/site-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/Users/a824810056/Desktop/py2.7-GovSpider/GovSpider2/GovSpider2/spiders/govSpider.py", line 55, in parse_item
    subStr = referUrl.rsplit('/')
TypeError: a bytes-like object is required, not 'str'
2019-03-26 14:41:04 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.gov.cn/banshi/2005-06/08/content_4837.htm> (referer: http://www.gov.cn/banshi/wjrs/crj.htm)
Traceback (most recent call last):
  File "/usr/local/lib/python3.7/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python3.7/site-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/Users/a824810056/Desktop/py2.7-GovSpider/GovSpider2/GovSpider2/spiders/govSpider.py", line 55, in parse_item
    subStr = referUrl.rsplit('/')
TypeError: a bytes-like object is required, not 'str'
2019-03-26 14:41:04 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.gov.cn/banshi/2006-08/23/content_368260.htm> (referer: http://www.gov.cn/banshi/wjrs/crj.htm)
Traceback (most recent call last):
  File "/usr/local/lib/python3.7/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python3.7/site-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/Users/a824810056/Desktop/py2.7-GovSpider/GovSpider2/GovSpider2/spiders/govSpider.py", line 55, in parse_item
    subStr = referUrl.rsplit('/')
TypeError: a bytes-like object is required, not 'str'
2019-03-26 14:41:04 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.gov.cn/banshi/2012-11/19/content_2269878.htm> (referer: http://www.gov.cn/banshi/wjrs/crj.htm)
Traceback (most recent call last):
  File "/usr/local/lib/python3.7/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python3.7/site-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/Users/a824810056/Desktop/py2.7-GovSpider/GovSpider2/GovSpider2/spiders/govSpider.py", line 55, in parse_item
    subStr = referUrl.rsplit('/')
TypeError: a bytes-like object is required, not 'str'
2019-03-26 14:41:04 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.gov.cn/banshi/2012-11/19/content_2269879.htm> (referer: http://www.gov.cn/banshi/wjrs/crj.htm)
Traceback (most recent call last):
  File "/usr/local/lib/python3.7/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python3.7/site-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/Users/a824810056/Desktop/py2.7-GovSpider/GovSpider2/GovSpider2/spiders/govSpider.py", line 55, in parse_item
    subStr = referUrl.rsplit('/')
TypeError: a bytes-like object is required, not 'str'
2019-03-26 14:41:04 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.gov.cn/banshi/2005-09/12/content_31017.htm> (referer: http://www.gov.cn/banshi/wjrs/crj.htm)
Traceback (most recent call last):
  File "/usr/local/lib/python3.7/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python3.7/site-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/Users/a824810056/Desktop/py2.7-GovSpider/GovSpider2/GovSpider2/spiders/govSpider.py", line 55, in parse_item
    subStr = referUrl.rsplit('/')
TypeError: a bytes-like object is required, not 'str'
2019-03-26 14:41:04 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.gov.cn/banshi/2012-11/19/content_2269880.htm> (referer: http://www.gov.cn/banshi/wjrs/crj.htm)
Traceback (most recent call last):
  File "/usr/local/lib/python3.7/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python3.7/site-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/Users/a824810056/Desktop/py2.7-GovSpider/GovSpider2/GovSpider2/spiders/govSpider.py", line 55, in parse_item
    subStr = referUrl.rsplit('/')
TypeError: a bytes-like object is required, not 'str'
2019-03-26 14:41:04 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.gov.cn/banshi/2006-10/09/content_408018.htm> (referer: http://www.gov.cn/banshi/wjrs/crj.htm)
Traceback (most recent call last):
  File "/usr/local/lib/python3.7/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python3.7/site-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/Users/a824810056/Desktop/py2.7-GovSpider/GovSpider2/GovSpider2/spiders/govSpider.py", line 55, in parse_item
    subStr = referUrl.rsplit('/')
TypeError: a bytes-like object is required, not 'str'
2019-03-26 14:41:04 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.gov.cn/banshi/2012-11/19/content_2269877.htm> (referer: http://www.gov.cn/banshi/wjrs/crj.htm)
Traceback (most recent call last):
  File "/usr/local/lib/python3.7/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python3.7/site-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/Users/a824810056/Desktop/py2.7-GovSpider/GovSpider2/GovSpider2/spiders/govSpider.py", line 55, in parse_item
    subStr = referUrl.rsplit('/')
TypeError: a bytes-like object is required, not 'str'
2019-03-26 14:41:04 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.gov.cn/banshi/2007-05/10/content_610216.htm> (referer: http://www.gov.cn/banshi/wjrs/crj.htm)
Traceback (most recent call last):
  File "/usr/local/lib/python3.7/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python3.7/site-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/Users/a824810056/Desktop/py2.7-GovSpider/GovSpider2/GovSpider2/spiders/govSpider.py", line 55, in parse_item
    subStr = referUrl.rsplit('/')
TypeError: a bytes-like object is required, not 'str'
2019-03-26 14:41:04 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.gov.cn/banshi/2006-10/09/content_408014.htm> (referer: http://www.gov.cn/banshi/wjrs/crj.htm)
Traceback (most recent call last):
  File "/usr/local/lib/python3.7/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python3.7/site-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/Users/a824810056/Desktop/py2.7-GovSpider/GovSpider2/GovSpider2/spiders/govSpider.py", line 55, in parse_item
    subStr = referUrl.rsplit('/')
TypeError: a bytes-like object is required, not 'str'
2019-03-26 14:41:04 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.gov.cn/banshi/2006-10/09/content_408005.htm> (referer: http://www.gov.cn/banshi/wjrs/crj.htm)
Traceback (most recent call last):
  File "/usr/local/lib/python3.7/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python3.7/site-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/Users/a824810056/Desktop/py2.7-GovSpider/GovSpider2/GovSpider2/spiders/govSpider.py", line 55, in parse_item
    subStr = referUrl.rsplit('/')
TypeError: a bytes-like object is required, not 'str'
2019-03-26 14:41:04 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.gov.cn/banshi/2012-11/19/content_2269876.htm> (referer: http://www.gov.cn/banshi/wjrs/crj.htm)
Traceback (most recent call last):
  File "/usr/local/lib/python3.7/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python3.7/site-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/Users/a824810056/Desktop/py2.7-GovSpider/GovSpider2/GovSpider2/spiders/govSpider.py", line 55, in parse_item
    subStr = referUrl.rsplit('/')
TypeError: a bytes-like object is required, not 'str'
2019-03-26 14:41:04 [scrapy.core.engine] INFO: Closing spider (finished)
2019-03-26 14:41:04 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 7317,
 'downloader/request_count': 20,
 'downloader/request_method_count/GET': 20,
 'downloader/response_bytes': 335314,
 'downloader/response_count': 20,
 'downloader/response_status_count/200': 20,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2019, 3, 26, 6, 41, 4, 619858),
 'log_count/ERROR': 18,
 'log_count/INFO': 9,
 'memusage/max': 50167808,
 'memusage/startup': 50163712,
 'request_depth_max': 1,
 'response_received_count': 20,
 'robotstxt/request_count': 1,
 'robotstxt/response_count': 1,
 'robotstxt/response_status_count/200': 1,
 'scheduler/dequeued': 19,
 'scheduler/dequeued/memory': 19,
 'scheduler/enqueued': 19,
 'scheduler/enqueued/memory': 19,
 'spider_exceptions/TypeError': 18,
 'start_time': datetime.datetime(2019, 3, 26, 6, 41, 3, 780329)}
2019-03-26 14:41:04 [scrapy.core.engine] INFO: Spider closed (finished)
2019-03-26 14:41:25 [scrapy.utils.log] INFO: Scrapy 1.6.0 started (bot: GovSpider2)
2019-03-26 14:41:25 [scrapy.utils.log] INFO: Versions: lxml 4.3.2.0, libxml2 2.9.9, cssselect 1.0.3, parsel 1.5.1, w3lib 1.20.0, Twisted 18.9.0, Python 3.7.2 (default, Feb 13 2019, 10:07:58) - [Clang 10.0.0 (clang-1000.11.45.5)], pyOpenSSL 19.0.0 (OpenSSL 1.1.1b  26 Feb 2019), cryptography 2.6.1, Platform Darwin-18.2.0-x86_64-i386-64bit
2019-03-26 14:41:25 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'GovSpider2', 'LOG_FILE': 'log/spiderlog20190326.txt', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'GovSpider2.spiders', 'ROBOTSTXT_OBEY': True, 'SPIDER_MODULES': ['GovSpider2.spiders']}
2019-03-26 14:41:25 [scrapy.extensions.telnet] INFO: Telnet Password: 397060be776a9979
2019-03-26 14:41:25 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats']
2019-03-26 14:41:25 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.robotstxt.RobotsTxtMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2019-03-26 14:41:25 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2019-03-26 14:41:25 [scrapy.middleware] INFO: Enabled item pipelines:
['GovSpider2.pipelines.Govspider2Pipeline']
2019-03-26 14:41:25 [scrapy.core.engine] INFO: Spider opened
2019-03-26 14:41:25 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-03-26 14:41:25 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023
2019-03-26 14:41:26 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.gov.cn/banshi/2005-07/06/content_12279.htm> (referer: http://www.gov.cn/banshi/wjrs/crj.htm)
Traceback (most recent call last):
  File "/usr/local/lib/python3.7/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python3.7/site-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/Users/a824810056/Desktop/py2.7-GovSpider/GovSpider2/GovSpider2/spiders/govSpider.py", line 49, in parse_item
    referUrl = response.request.headers.get('Referer', None).text()
AttributeError: 'bytes' object has no attribute 'text'
2019-03-26 14:41:26 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.gov.cn/banshi/2006-10/09/content_408010.htm> (referer: http://www.gov.cn/banshi/wjrs/crj.htm)
Traceback (most recent call last):
  File "/usr/local/lib/python3.7/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python3.7/site-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/Users/a824810056/Desktop/py2.7-GovSpider/GovSpider2/GovSpider2/spiders/govSpider.py", line 49, in parse_item
    referUrl = response.request.headers.get('Referer', None).text()
AttributeError: 'bytes' object has no attribute 'text'
2019-03-26 14:41:26 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.gov.cn/banshi/2005-05/26/content_1300.htm> (referer: http://www.gov.cn/banshi/wjrs/crj.htm)
Traceback (most recent call last):
  File "/usr/local/lib/python3.7/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python3.7/site-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/Users/a824810056/Desktop/py2.7-GovSpider/GovSpider2/GovSpider2/spiders/govSpider.py", line 49, in parse_item
    referUrl = response.request.headers.get('Referer', None).text()
AttributeError: 'bytes' object has no attribute 'text'
2019-03-26 14:41:26 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.gov.cn/banshi/2005-07/08/content_13036.htm> (referer: http://www.gov.cn/banshi/wjrs/crj.htm)
Traceback (most recent call last):
  File "/usr/local/lib/python3.7/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python3.7/site-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/Users/a824810056/Desktop/py2.7-GovSpider/GovSpider2/GovSpider2/spiders/govSpider.py", line 49, in parse_item
    referUrl = response.request.headers.get('Referer', None).text()
AttributeError: 'bytes' object has no attribute 'text'
2019-03-26 14:41:26 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.gov.cn/banshi/2006-10/09/content_408005.htm> (referer: http://www.gov.cn/banshi/wjrs/crj.htm)
Traceback (most recent call last):
  File "/usr/local/lib/python3.7/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python3.7/site-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/Users/a824810056/Desktop/py2.7-GovSpider/GovSpider2/GovSpider2/spiders/govSpider.py", line 49, in parse_item
    referUrl = response.request.headers.get('Referer', None).text()
AttributeError: 'bytes' object has no attribute 'text'
2019-03-26 14:41:26 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.gov.cn/banshi/2006-10/09/content_408018.htm> (referer: http://www.gov.cn/banshi/wjrs/crj.htm)
Traceback (most recent call last):
  File "/usr/local/lib/python3.7/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python3.7/site-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/Users/a824810056/Desktop/py2.7-GovSpider/GovSpider2/GovSpider2/spiders/govSpider.py", line 49, in parse_item
    referUrl = response.request.headers.get('Referer', None).text()
AttributeError: 'bytes' object has no attribute 'text'
2019-03-26 14:41:26 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.gov.cn/banshi/2006-08/23/content_368260.htm> (referer: http://www.gov.cn/banshi/wjrs/crj.htm)
Traceback (most recent call last):
  File "/usr/local/lib/python3.7/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python3.7/site-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/Users/a824810056/Desktop/py2.7-GovSpider/GovSpider2/GovSpider2/spiders/govSpider.py", line 49, in parse_item
    referUrl = response.request.headers.get('Referer', None).text()
AttributeError: 'bytes' object has no attribute 'text'
2019-03-26 14:41:26 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.gov.cn/banshi/2012-11/19/content_2269877.htm> (referer: http://www.gov.cn/banshi/wjrs/crj.htm)
Traceback (most recent call last):
  File "/usr/local/lib/python3.7/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python3.7/site-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/Users/a824810056/Desktop/py2.7-GovSpider/GovSpider2/GovSpider2/spiders/govSpider.py", line 49, in parse_item
    referUrl = response.request.headers.get('Referer', None).text()
AttributeError: 'bytes' object has no attribute 'text'
2019-03-26 14:41:26 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.gov.cn/banshi/2012-11/19/content_2269876.htm> (referer: http://www.gov.cn/banshi/wjrs/crj.htm)
Traceback (most recent call last):
  File "/usr/local/lib/python3.7/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python3.7/site-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/Users/a824810056/Desktop/py2.7-GovSpider/GovSpider2/GovSpider2/spiders/govSpider.py", line 49, in parse_item
    referUrl = response.request.headers.get('Referer', None).text()
AttributeError: 'bytes' object has no attribute 'text'
2019-03-26 14:41:26 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.gov.cn/banshi/2012-11/19/content_2269878.htm> (referer: http://www.gov.cn/banshi/wjrs/crj.htm)
Traceback (most recent call last):
  File "/usr/local/lib/python3.7/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python3.7/site-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/Users/a824810056/Desktop/py2.7-GovSpider/GovSpider2/GovSpider2/spiders/govSpider.py", line 49, in parse_item
    referUrl = response.request.headers.get('Referer', None).text()
AttributeError: 'bytes' object has no attribute 'text'
2019-03-26 14:41:26 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.gov.cn/banshi/2012-11/19/content_2269879.htm> (referer: http://www.gov.cn/banshi/wjrs/crj.htm)
Traceback (most recent call last):
  File "/usr/local/lib/python3.7/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python3.7/site-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/Users/a824810056/Desktop/py2.7-GovSpider/GovSpider2/GovSpider2/spiders/govSpider.py", line 49, in parse_item
    referUrl = response.request.headers.get('Referer', None).text()
AttributeError: 'bytes' object has no attribute 'text'
2019-03-26 14:41:26 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.gov.cn/banshi/2005-06/08/content_4836.htm> (referer: http://www.gov.cn/banshi/wjrs/crj.htm)
Traceback (most recent call last):
  File "/usr/local/lib/python3.7/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python3.7/site-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/Users/a824810056/Desktop/py2.7-GovSpider/GovSpider2/GovSpider2/spiders/govSpider.py", line 49, in parse_item
    referUrl = response.request.headers.get('Referer', None).text()
AttributeError: 'bytes' object has no attribute 'text'
2019-03-26 14:41:26 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.gov.cn/banshi/2005-06/08/content_4837.htm> (referer: http://www.gov.cn/banshi/wjrs/crj.htm)
Traceback (most recent call last):
  File "/usr/local/lib/python3.7/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python3.7/site-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/Users/a824810056/Desktop/py2.7-GovSpider/GovSpider2/GovSpider2/spiders/govSpider.py", line 49, in parse_item
    referUrl = response.request.headers.get('Referer', None).text()
AttributeError: 'bytes' object has no attribute 'text'
2019-03-26 14:41:26 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.gov.cn/banshi/2006-10/09/content_408014.htm> (referer: http://www.gov.cn/banshi/wjrs/crj.htm)
Traceback (most recent call last):
  File "/usr/local/lib/python3.7/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python3.7/site-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/Users/a824810056/Desktop/py2.7-GovSpider/GovSpider2/GovSpider2/spiders/govSpider.py", line 49, in parse_item
    referUrl = response.request.headers.get('Referer', None).text()
AttributeError: 'bytes' object has no attribute 'text'
2019-03-26 14:41:26 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.gov.cn/banshi/2005-09/12/content_31017.htm> (referer: http://www.gov.cn/banshi/wjrs/crj.htm)
Traceback (most recent call last):
  File "/usr/local/lib/python3.7/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python3.7/site-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/Users/a824810056/Desktop/py2.7-GovSpider/GovSpider2/GovSpider2/spiders/govSpider.py", line 49, in parse_item
    referUrl = response.request.headers.get('Referer', None).text()
AttributeError: 'bytes' object has no attribute 'text'
2019-03-26 14:41:26 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.gov.cn/banshi/2006-10/09/content_408016.htm> (referer: http://www.gov.cn/banshi/wjrs/crj.htm)
Traceback (most recent call last):
  File "/usr/local/lib/python3.7/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python3.7/site-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/Users/a824810056/Desktop/py2.7-GovSpider/GovSpider2/GovSpider2/spiders/govSpider.py", line 49, in parse_item
    referUrl = response.request.headers.get('Referer', None).text()
AttributeError: 'bytes' object has no attribute 'text'
2019-03-26 14:41:26 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.gov.cn/banshi/2007-05/10/content_610216.htm> (referer: http://www.gov.cn/banshi/wjrs/crj.htm)
Traceback (most recent call last):
  File "/usr/local/lib/python3.7/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python3.7/site-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/Users/a824810056/Desktop/py2.7-GovSpider/GovSpider2/GovSpider2/spiders/govSpider.py", line 49, in parse_item
    referUrl = response.request.headers.get('Referer', None).text()
AttributeError: 'bytes' object has no attribute 'text'
2019-03-26 14:41:26 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.gov.cn/banshi/2012-11/19/content_2269880.htm> (referer: http://www.gov.cn/banshi/wjrs/crj.htm)
Traceback (most recent call last):
  File "/usr/local/lib/python3.7/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python3.7/site-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/Users/a824810056/Desktop/py2.7-GovSpider/GovSpider2/GovSpider2/spiders/govSpider.py", line 49, in parse_item
    referUrl = response.request.headers.get('Referer', None).text()
AttributeError: 'bytes' object has no attribute 'text'
2019-03-26 14:41:26 [scrapy.core.engine] INFO: Closing spider (finished)
2019-03-26 14:41:26 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 7317,
 'downloader/request_count': 20,
 'downloader/request_method_count/GET': 20,
 'downloader/response_bytes': 335313,
 'downloader/response_count': 20,
 'downloader/response_status_count/200': 20,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2019, 3, 26, 6, 41, 26, 295865),
 'log_count/ERROR': 18,
 'log_count/INFO': 9,
 'memusage/max': 49766400,
 'memusage/startup': 49762304,
 'request_depth_max': 1,
 'response_received_count': 20,
 'robotstxt/request_count': 1,
 'robotstxt/response_count': 1,
 'robotstxt/response_status_count/200': 1,
 'scheduler/dequeued': 19,
 'scheduler/dequeued/memory': 19,
 'scheduler/enqueued': 19,
 'scheduler/enqueued/memory': 19,
 'spider_exceptions/AttributeError': 18,
 'start_time': datetime.datetime(2019, 3, 26, 6, 41, 25, 774640)}
2019-03-26 14:41:26 [scrapy.core.engine] INFO: Spider closed (finished)
2019-03-26 14:41:43 [scrapy.utils.log] INFO: Scrapy 1.6.0 started (bot: GovSpider2)
2019-03-26 14:41:43 [scrapy.utils.log] INFO: Versions: lxml 4.3.2.0, libxml2 2.9.9, cssselect 1.0.3, parsel 1.5.1, w3lib 1.20.0, Twisted 18.9.0, Python 3.7.2 (default, Feb 13 2019, 10:07:58) - [Clang 10.0.0 (clang-1000.11.45.5)], pyOpenSSL 19.0.0 (OpenSSL 1.1.1b  26 Feb 2019), cryptography 2.6.1, Platform Darwin-18.2.0-x86_64-i386-64bit
2019-03-26 14:41:43 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'GovSpider2', 'LOG_FILE': 'log/spiderlog20190326.txt', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'GovSpider2.spiders', 'ROBOTSTXT_OBEY': True, 'SPIDER_MODULES': ['GovSpider2.spiders']}
2019-03-26 14:41:44 [scrapy.extensions.telnet] INFO: Telnet Password: 111429529c9093d0
2019-03-26 14:41:44 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats']
2019-03-26 14:41:44 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.robotstxt.RobotsTxtMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2019-03-26 14:41:44 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2019-03-26 14:41:44 [scrapy.middleware] INFO: Enabled item pipelines:
['GovSpider2.pipelines.Govspider2Pipeline']
2019-03-26 14:41:44 [scrapy.core.engine] INFO: Spider opened
2019-03-26 14:41:44 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-03-26 14:41:44 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023
2019-03-26 14:41:44 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.gov.cn/banshi/2005-07/06/content_12279.htm> (referer: http://www.gov.cn/banshi/wjrs/crj.htm)
Traceback (most recent call last):
  File "/usr/local/lib/python3.7/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python3.7/site-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/Users/a824810056/Desktop/py2.7-GovSpider/GovSpider2/GovSpider2/spiders/govSpider.py", line 49, in parse_item
    referUrl = response.request.headers.get('Referer', None).extract()
AttributeError: 'bytes' object has no attribute 'extract'
2019-03-26 14:41:44 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.gov.cn/banshi/2006-10/09/content_408010.htm> (referer: http://www.gov.cn/banshi/wjrs/crj.htm)
Traceback (most recent call last):
  File "/usr/local/lib/python3.7/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python3.7/site-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/Users/a824810056/Desktop/py2.7-GovSpider/GovSpider2/GovSpider2/spiders/govSpider.py", line 49, in parse_item
    referUrl = response.request.headers.get('Referer', None).extract()
AttributeError: 'bytes' object has no attribute 'extract'
2019-03-26 14:41:44 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.gov.cn/banshi/2005-07/08/content_13036.htm> (referer: http://www.gov.cn/banshi/wjrs/crj.htm)
Traceback (most recent call last):
  File "/usr/local/lib/python3.7/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python3.7/site-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/Users/a824810056/Desktop/py2.7-GovSpider/GovSpider2/GovSpider2/spiders/govSpider.py", line 49, in parse_item
    referUrl = response.request.headers.get('Referer', None).extract()
AttributeError: 'bytes' object has no attribute 'extract'
2019-03-26 14:41:44 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.gov.cn/banshi/2005-05/26/content_1300.htm> (referer: http://www.gov.cn/banshi/wjrs/crj.htm)
Traceback (most recent call last):
  File "/usr/local/lib/python3.7/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python3.7/site-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/Users/a824810056/Desktop/py2.7-GovSpider/GovSpider2/GovSpider2/spiders/govSpider.py", line 49, in parse_item
    referUrl = response.request.headers.get('Referer', None).extract()
AttributeError: 'bytes' object has no attribute 'extract'
2019-03-26 14:41:44 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.gov.cn/banshi/2006-10/09/content_408014.htm> (referer: http://www.gov.cn/banshi/wjrs/crj.htm)
Traceback (most recent call last):
  File "/usr/local/lib/python3.7/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python3.7/site-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/Users/a824810056/Desktop/py2.7-GovSpider/GovSpider2/GovSpider2/spiders/govSpider.py", line 49, in parse_item
    referUrl = response.request.headers.get('Referer', None).extract()
AttributeError: 'bytes' object has no attribute 'extract'
2019-03-26 14:41:44 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.gov.cn/banshi/2005-09/12/content_31017.htm> (referer: http://www.gov.cn/banshi/wjrs/crj.htm)
Traceback (most recent call last):
  File "/usr/local/lib/python3.7/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python3.7/site-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/Users/a824810056/Desktop/py2.7-GovSpider/GovSpider2/GovSpider2/spiders/govSpider.py", line 49, in parse_item
    referUrl = response.request.headers.get('Referer', None).extract()
AttributeError: 'bytes' object has no attribute 'extract'
2019-03-26 14:41:44 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.gov.cn/banshi/2005-06/08/content_4837.htm> (referer: http://www.gov.cn/banshi/wjrs/crj.htm)
Traceback (most recent call last):
  File "/usr/local/lib/python3.7/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python3.7/site-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/Users/a824810056/Desktop/py2.7-GovSpider/GovSpider2/GovSpider2/spiders/govSpider.py", line 49, in parse_item
    referUrl = response.request.headers.get('Referer', None).extract()
AttributeError: 'bytes' object has no attribute 'extract'
2019-03-26 14:41:44 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.gov.cn/banshi/2005-06/08/content_4836.htm> (referer: http://www.gov.cn/banshi/wjrs/crj.htm)
Traceback (most recent call last):
  File "/usr/local/lib/python3.7/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python3.7/site-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/Users/a824810056/Desktop/py2.7-GovSpider/GovSpider2/GovSpider2/spiders/govSpider.py", line 49, in parse_item
    referUrl = response.request.headers.get('Referer', None).extract()
AttributeError: 'bytes' object has no attribute 'extract'
2019-03-26 14:41:44 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.gov.cn/banshi/2006-10/09/content_408016.htm> (referer: http://www.gov.cn/banshi/wjrs/crj.htm)
Traceback (most recent call last):
  File "/usr/local/lib/python3.7/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python3.7/site-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/Users/a824810056/Desktop/py2.7-GovSpider/GovSpider2/GovSpider2/spiders/govSpider.py", line 49, in parse_item
    referUrl = response.request.headers.get('Referer', None).extract()
AttributeError: 'bytes' object has no attribute 'extract'
2019-03-26 14:41:44 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.gov.cn/banshi/2007-05/10/content_610216.htm> (referer: http://www.gov.cn/banshi/wjrs/crj.htm)
Traceback (most recent call last):
  File "/usr/local/lib/python3.7/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python3.7/site-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/Users/a824810056/Desktop/py2.7-GovSpider/GovSpider2/GovSpider2/spiders/govSpider.py", line 49, in parse_item
    referUrl = response.request.headers.get('Referer', None).extract()
AttributeError: 'bytes' object has no attribute 'extract'
2019-03-26 14:41:44 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.gov.cn/banshi/2012-11/19/content_2269878.htm> (referer: http://www.gov.cn/banshi/wjrs/crj.htm)
Traceback (most recent call last):
  File "/usr/local/lib/python3.7/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python3.7/site-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/Users/a824810056/Desktop/py2.7-GovSpider/GovSpider2/GovSpider2/spiders/govSpider.py", line 49, in parse_item
    referUrl = response.request.headers.get('Referer', None).extract()
AttributeError: 'bytes' object has no attribute 'extract'
2019-03-26 14:41:44 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.gov.cn/banshi/2012-11/19/content_2269876.htm> (referer: http://www.gov.cn/banshi/wjrs/crj.htm)
Traceback (most recent call last):
  File "/usr/local/lib/python3.7/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python3.7/site-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/Users/a824810056/Desktop/py2.7-GovSpider/GovSpider2/GovSpider2/spiders/govSpider.py", line 49, in parse_item
    referUrl = response.request.headers.get('Referer', None).extract()
AttributeError: 'bytes' object has no attribute 'extract'
2019-03-26 14:41:44 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.gov.cn/banshi/2012-11/19/content_2269880.htm> (referer: http://www.gov.cn/banshi/wjrs/crj.htm)
Traceback (most recent call last):
  File "/usr/local/lib/python3.7/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python3.7/site-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/Users/a824810056/Desktop/py2.7-GovSpider/GovSpider2/GovSpider2/spiders/govSpider.py", line 49, in parse_item
    referUrl = response.request.headers.get('Referer', None).extract()
AttributeError: 'bytes' object has no attribute 'extract'
2019-03-26 14:41:44 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.gov.cn/banshi/2012-11/19/content_2269877.htm> (referer: http://www.gov.cn/banshi/wjrs/crj.htm)
Traceback (most recent call last):
  File "/usr/local/lib/python3.7/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python3.7/site-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/Users/a824810056/Desktop/py2.7-GovSpider/GovSpider2/GovSpider2/spiders/govSpider.py", line 49, in parse_item
    referUrl = response.request.headers.get('Referer', None).extract()
AttributeError: 'bytes' object has no attribute 'extract'
2019-03-26 14:41:44 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.gov.cn/banshi/2006-08/23/content_368260.htm> (referer: http://www.gov.cn/banshi/wjrs/crj.htm)
Traceback (most recent call last):
  File "/usr/local/lib/python3.7/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python3.7/site-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/Users/a824810056/Desktop/py2.7-GovSpider/GovSpider2/GovSpider2/spiders/govSpider.py", line 49, in parse_item
    referUrl = response.request.headers.get('Referer', None).extract()
AttributeError: 'bytes' object has no attribute 'extract'
2019-03-26 14:41:44 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.gov.cn/banshi/2006-10/09/content_408005.htm> (referer: http://www.gov.cn/banshi/wjrs/crj.htm)
Traceback (most recent call last):
  File "/usr/local/lib/python3.7/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python3.7/site-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/Users/a824810056/Desktop/py2.7-GovSpider/GovSpider2/GovSpider2/spiders/govSpider.py", line 49, in parse_item
    referUrl = response.request.headers.get('Referer', None).extract()
AttributeError: 'bytes' object has no attribute 'extract'
2019-03-26 14:41:44 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.gov.cn/banshi/2006-10/09/content_408018.htm> (referer: http://www.gov.cn/banshi/wjrs/crj.htm)
Traceback (most recent call last):
  File "/usr/local/lib/python3.7/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python3.7/site-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/Users/a824810056/Desktop/py2.7-GovSpider/GovSpider2/GovSpider2/spiders/govSpider.py", line 49, in parse_item
    referUrl = response.request.headers.get('Referer', None).extract()
AttributeError: 'bytes' object has no attribute 'extract'
2019-03-26 14:41:44 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.gov.cn/banshi/2012-11/19/content_2269879.htm> (referer: http://www.gov.cn/banshi/wjrs/crj.htm)
Traceback (most recent call last):
  File "/usr/local/lib/python3.7/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python3.7/site-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/Users/a824810056/Desktop/py2.7-GovSpider/GovSpider2/GovSpider2/spiders/govSpider.py", line 49, in parse_item
    referUrl = response.request.headers.get('Referer', None).extract()
AttributeError: 'bytes' object has no attribute 'extract'
2019-03-26 14:41:44 [scrapy.core.engine] INFO: Closing spider (finished)
2019-03-26 14:41:44 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 7317,
 'downloader/request_count': 20,
 'downloader/request_method_count/GET': 20,
 'downloader/response_bytes': 335313,
 'downloader/response_count': 20,
 'downloader/response_status_count/200': 20,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2019, 3, 26, 6, 41, 44, 531933),
 'log_count/ERROR': 18,
 'log_count/INFO': 9,
 'memusage/max': 49967104,
 'memusage/startup': 49963008,
 'request_depth_max': 1,
 'response_received_count': 20,
 'robotstxt/request_count': 1,
 'robotstxt/response_count': 1,
 'robotstxt/response_status_count/200': 1,
 'scheduler/dequeued': 19,
 'scheduler/dequeued/memory': 19,
 'scheduler/enqueued': 19,
 'scheduler/enqueued/memory': 19,
 'spider_exceptions/AttributeError': 18,
 'start_time': datetime.datetime(2019, 3, 26, 6, 41, 44, 62182)}
2019-03-26 14:41:44 [scrapy.core.engine] INFO: Spider closed (finished)
2019-03-26 14:46:59 [scrapy.utils.log] INFO: Scrapy 1.6.0 started (bot: GovSpider2)
2019-03-26 14:46:59 [scrapy.utils.log] INFO: Versions: lxml 4.3.2.0, libxml2 2.9.9, cssselect 1.0.3, parsel 1.5.1, w3lib 1.20.0, Twisted 18.9.0, Python 3.7.2 (default, Feb 13 2019, 10:07:58) - [Clang 10.0.0 (clang-1000.11.45.5)], pyOpenSSL 19.0.0 (OpenSSL 1.1.1b  26 Feb 2019), cryptography 2.6.1, Platform Darwin-18.2.0-x86_64-i386-64bit
2019-03-26 14:46:59 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'GovSpider2', 'LOG_FILE': 'log/spiderlog20190326.txt', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'GovSpider2.spiders', 'ROBOTSTXT_OBEY': True, 'SPIDER_MODULES': ['GovSpider2.spiders']}
2019-03-26 14:46:59 [scrapy.extensions.telnet] INFO: Telnet Password: 65f9baca6e41ad70
2019-03-26 14:46:59 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats']
2019-03-26 14:46:59 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.robotstxt.RobotsTxtMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2019-03-26 14:46:59 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2019-03-26 14:46:59 [scrapy.middleware] INFO: Enabled item pipelines:
['GovSpider2.pipelines.Govspider2Pipeline']
2019-03-26 14:46:59 [scrapy.core.engine] INFO: Spider opened
2019-03-26 14:46:59 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-03-26 14:46:59 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023
2019-03-26 14:47:00 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.gov.cn/banshi/2005-05/26/content_1300.htm> (referer: http://www.gov.cn/banshi/wjrs/crj.htm)
Traceback (most recent call last):
  File "/usr/local/lib/python3.7/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python3.7/site-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/Users/a824810056/Desktop/py2.7-GovSpider/GovSpider2/GovSpider2/spiders/govSpider.py", line 52, in parse_item
    print(referUrl.object)
AttributeError: 'bytes' object has no attribute 'object'
2019-03-26 14:47:00 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.gov.cn/banshi/2005-07/06/content_12279.htm> (referer: http://www.gov.cn/banshi/wjrs/crj.htm)
Traceback (most recent call last):
  File "/usr/local/lib/python3.7/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python3.7/site-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/Users/a824810056/Desktop/py2.7-GovSpider/GovSpider2/GovSpider2/spiders/govSpider.py", line 52, in parse_item
    print(referUrl.object)
AttributeError: 'bytes' object has no attribute 'object'
2019-03-26 14:47:00 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.gov.cn/banshi/2005-07/08/content_13036.htm> (referer: http://www.gov.cn/banshi/wjrs/crj.htm)
Traceback (most recent call last):
  File "/usr/local/lib/python3.7/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python3.7/site-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/Users/a824810056/Desktop/py2.7-GovSpider/GovSpider2/GovSpider2/spiders/govSpider.py", line 52, in parse_item
    print(referUrl.object)
AttributeError: 'bytes' object has no attribute 'object'
2019-03-26 14:47:00 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.gov.cn/banshi/2006-10/09/content_408010.htm> (referer: http://www.gov.cn/banshi/wjrs/crj.htm)
Traceback (most recent call last):
  File "/usr/local/lib/python3.7/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python3.7/site-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/Users/a824810056/Desktop/py2.7-GovSpider/GovSpider2/GovSpider2/spiders/govSpider.py", line 52, in parse_item
    print(referUrl.object)
AttributeError: 'bytes' object has no attribute 'object'
2019-03-26 14:47:00 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.gov.cn/banshi/2006-10/09/content_408018.htm> (referer: http://www.gov.cn/banshi/wjrs/crj.htm)
Traceback (most recent call last):
  File "/usr/local/lib/python3.7/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python3.7/site-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/Users/a824810056/Desktop/py2.7-GovSpider/GovSpider2/GovSpider2/spiders/govSpider.py", line 52, in parse_item
    print(referUrl.object)
AttributeError: 'bytes' object has no attribute 'object'
2019-03-26 14:47:00 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.gov.cn/banshi/2006-08/23/content_368260.htm> (referer: http://www.gov.cn/banshi/wjrs/crj.htm)
Traceback (most recent call last):
  File "/usr/local/lib/python3.7/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python3.7/site-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/Users/a824810056/Desktop/py2.7-GovSpider/GovSpider2/GovSpider2/spiders/govSpider.py", line 52, in parse_item
    print(referUrl.object)
AttributeError: 'bytes' object has no attribute 'object'
2019-03-26 14:47:00 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.gov.cn/banshi/2006-10/09/content_408016.htm> (referer: http://www.gov.cn/banshi/wjrs/crj.htm)
Traceback (most recent call last):
  File "/usr/local/lib/python3.7/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python3.7/site-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/Users/a824810056/Desktop/py2.7-GovSpider/GovSpider2/GovSpider2/spiders/govSpider.py", line 52, in parse_item
    print(referUrl.object)
AttributeError: 'bytes' object has no attribute 'object'
2019-03-26 14:47:00 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.gov.cn/banshi/2006-10/09/content_408014.htm> (referer: http://www.gov.cn/banshi/wjrs/crj.htm)
Traceback (most recent call last):
  File "/usr/local/lib/python3.7/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python3.7/site-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/Users/a824810056/Desktop/py2.7-GovSpider/GovSpider2/GovSpider2/spiders/govSpider.py", line 52, in parse_item
    print(referUrl.object)
AttributeError: 'bytes' object has no attribute 'object'
2019-03-26 14:47:00 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.gov.cn/banshi/2005-09/12/content_31017.htm> (referer: http://www.gov.cn/banshi/wjrs/crj.htm)
Traceback (most recent call last):
  File "/usr/local/lib/python3.7/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python3.7/site-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/Users/a824810056/Desktop/py2.7-GovSpider/GovSpider2/GovSpider2/spiders/govSpider.py", line 52, in parse_item
    print(referUrl.object)
AttributeError: 'bytes' object has no attribute 'object'
2019-03-26 14:47:00 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.gov.cn/banshi/2007-05/10/content_610216.htm> (referer: http://www.gov.cn/banshi/wjrs/crj.htm)
Traceback (most recent call last):
  File "/usr/local/lib/python3.7/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python3.7/site-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/Users/a824810056/Desktop/py2.7-GovSpider/GovSpider2/GovSpider2/spiders/govSpider.py", line 52, in parse_item
    print(referUrl.object)
AttributeError: 'bytes' object has no attribute 'object'
2019-03-26 14:47:00 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.gov.cn/banshi/2012-11/19/content_2269877.htm> (referer: http://www.gov.cn/banshi/wjrs/crj.htm)
Traceback (most recent call last):
  File "/usr/local/lib/python3.7/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python3.7/site-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/Users/a824810056/Desktop/py2.7-GovSpider/GovSpider2/GovSpider2/spiders/govSpider.py", line 52, in parse_item
    print(referUrl.object)
AttributeError: 'bytes' object has no attribute 'object'
2019-03-26 14:47:00 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.gov.cn/banshi/2012-11/19/content_2269878.htm> (referer: http://www.gov.cn/banshi/wjrs/crj.htm)
Traceback (most recent call last):
  File "/usr/local/lib/python3.7/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python3.7/site-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/Users/a824810056/Desktop/py2.7-GovSpider/GovSpider2/GovSpider2/spiders/govSpider.py", line 52, in parse_item
    print(referUrl.object)
AttributeError: 'bytes' object has no attribute 'object'
2019-03-26 14:47:00 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.gov.cn/banshi/2012-11/19/content_2269879.htm> (referer: http://www.gov.cn/banshi/wjrs/crj.htm)
Traceback (most recent call last):
  File "/usr/local/lib/python3.7/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python3.7/site-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/Users/a824810056/Desktop/py2.7-GovSpider/GovSpider2/GovSpider2/spiders/govSpider.py", line 52, in parse_item
    print(referUrl.object)
AttributeError: 'bytes' object has no attribute 'object'
2019-03-26 14:47:00 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.gov.cn/banshi/2005-06/08/content_4836.htm> (referer: http://www.gov.cn/banshi/wjrs/crj.htm)
Traceback (most recent call last):
  File "/usr/local/lib/python3.7/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python3.7/site-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/Users/a824810056/Desktop/py2.7-GovSpider/GovSpider2/GovSpider2/spiders/govSpider.py", line 52, in parse_item
    print(referUrl.object)
AttributeError: 'bytes' object has no attribute 'object'
2019-03-26 14:47:00 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.gov.cn/banshi/2012-11/19/content_2269880.htm> (referer: http://www.gov.cn/banshi/wjrs/crj.htm)
Traceback (most recent call last):
  File "/usr/local/lib/python3.7/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python3.7/site-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/Users/a824810056/Desktop/py2.7-GovSpider/GovSpider2/GovSpider2/spiders/govSpider.py", line 52, in parse_item
    print(referUrl.object)
AttributeError: 'bytes' object has no attribute 'object'
2019-03-26 14:47:00 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.gov.cn/banshi/2005-06/08/content_4837.htm> (referer: http://www.gov.cn/banshi/wjrs/crj.htm)
Traceback (most recent call last):
  File "/usr/local/lib/python3.7/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python3.7/site-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/Users/a824810056/Desktop/py2.7-GovSpider/GovSpider2/GovSpider2/spiders/govSpider.py", line 52, in parse_item
    print(referUrl.object)
AttributeError: 'bytes' object has no attribute 'object'
2019-03-26 14:47:00 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.gov.cn/banshi/2006-10/09/content_408005.htm> (referer: http://www.gov.cn/banshi/wjrs/crj.htm)
Traceback (most recent call last):
  File "/usr/local/lib/python3.7/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python3.7/site-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/Users/a824810056/Desktop/py2.7-GovSpider/GovSpider2/GovSpider2/spiders/govSpider.py", line 52, in parse_item
    print(referUrl.object)
AttributeError: 'bytes' object has no attribute 'object'
2019-03-26 14:47:00 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.gov.cn/banshi/2012-11/19/content_2269876.htm> (referer: http://www.gov.cn/banshi/wjrs/crj.htm)
Traceback (most recent call last):
  File "/usr/local/lib/python3.7/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python3.7/site-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/Users/a824810056/Desktop/py2.7-GovSpider/GovSpider2/GovSpider2/spiders/govSpider.py", line 52, in parse_item
    print(referUrl.object)
AttributeError: 'bytes' object has no attribute 'object'
2019-03-26 14:47:00 [scrapy.core.engine] INFO: Closing spider (finished)
2019-03-26 14:47:00 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 7317,
 'downloader/request_count': 20,
 'downloader/request_method_count/GET': 20,
 'downloader/response_bytes': 335314,
 'downloader/response_count': 20,
 'downloader/response_status_count/200': 20,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2019, 3, 26, 6, 47, 0, 386343),
 'log_count/ERROR': 18,
 'log_count/INFO': 9,
 'memusage/max': 49979392,
 'memusage/startup': 49975296,
 'request_depth_max': 1,
 'response_received_count': 20,
 'robotstxt/request_count': 1,
 'robotstxt/response_count': 1,
 'robotstxt/response_status_count/200': 1,
 'scheduler/dequeued': 19,
 'scheduler/dequeued/memory': 19,
 'scheduler/enqueued': 19,
 'scheduler/enqueued/memory': 19,
 'spider_exceptions/AttributeError': 18,
 'start_time': datetime.datetime(2019, 3, 26, 6, 46, 59, 466801)}
2019-03-26 14:47:00 [scrapy.core.engine] INFO: Spider closed (finished)
2019-03-26 14:50:12 [scrapy.utils.log] INFO: Scrapy 1.6.0 started (bot: GovSpider2)
2019-03-26 14:50:12 [scrapy.utils.log] INFO: Versions: lxml 4.3.2.0, libxml2 2.9.9, cssselect 1.0.3, parsel 1.5.1, w3lib 1.20.0, Twisted 18.9.0, Python 3.7.2 (default, Feb 13 2019, 10:07:58) - [Clang 10.0.0 (clang-1000.11.45.5)], pyOpenSSL 19.0.0 (OpenSSL 1.1.1b  26 Feb 2019), cryptography 2.6.1, Platform Darwin-18.2.0-x86_64-i386-64bit
2019-03-26 14:50:12 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'GovSpider2', 'LOG_FILE': 'log/spiderlog20190326.txt', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'GovSpider2.spiders', 'ROBOTSTXT_OBEY': True, 'SPIDER_MODULES': ['GovSpider2.spiders']}
2019-03-26 14:50:12 [scrapy.extensions.telnet] INFO: Telnet Password: 12428a18b47879fc
2019-03-26 14:50:12 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats']
2019-03-26 14:50:12 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.robotstxt.RobotsTxtMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2019-03-26 14:50:12 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2019-03-26 14:50:12 [scrapy.middleware] INFO: Enabled item pipelines:
['GovSpider2.pipelines.Govspider2Pipeline']
2019-03-26 14:50:12 [scrapy.core.engine] INFO: Spider opened
2019-03-26 14:50:12 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-03-26 14:50:12 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023
2019-03-26 14:50:14 [scrapy.core.engine] INFO: Closing spider (finished)
2019-03-26 14:50:14 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 7317,
 'downloader/request_count': 20,
 'downloader/request_method_count/GET': 20,
 'downloader/response_bytes': 335332,
 'downloader/response_count': 20,
 'downloader/response_status_count/200': 20,
 'dupefilter/filtered': 18,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2019, 3, 26, 6, 50, 14, 566993),
 'log_count/INFO': 9,
 'memusage/max': 49864704,
 'memusage/startup': 49860608,
 'request_depth_max': 2,
 'response_received_count': 20,
 'robotstxt/request_count': 1,
 'robotstxt/response_count': 1,
 'robotstxt/response_status_count/200': 1,
 'scheduler/dequeued': 19,
 'scheduler/dequeued/memory': 19,
 'scheduler/enqueued': 19,
 'scheduler/enqueued/memory': 19,
 'start_time': datetime.datetime(2019, 3, 26, 6, 50, 12, 607159)}
2019-03-26 14:50:14 [scrapy.core.engine] INFO: Spider closed (finished)
2019-03-26 14:50:45 [scrapy.utils.log] INFO: Scrapy 1.6.0 started (bot: GovSpider2)
2019-03-26 14:50:45 [scrapy.utils.log] INFO: Versions: lxml 4.3.2.0, libxml2 2.9.9, cssselect 1.0.3, parsel 1.5.1, w3lib 1.20.0, Twisted 18.9.0, Python 3.7.2 (default, Feb 13 2019, 10:07:58) - [Clang 10.0.0 (clang-1000.11.45.5)], pyOpenSSL 19.0.0 (OpenSSL 1.1.1b  26 Feb 2019), cryptography 2.6.1, Platform Darwin-18.2.0-x86_64-i386-64bit
2019-03-26 14:50:45 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'GovSpider2', 'LOG_FILE': 'log/spiderlog20190326.txt', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'GovSpider2.spiders', 'ROBOTSTXT_OBEY': True, 'SPIDER_MODULES': ['GovSpider2.spiders']}
2019-03-26 14:50:45 [scrapy.extensions.telnet] INFO: Telnet Password: 170b5ca334db903b
2019-03-26 14:50:45 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats']
2019-03-26 14:50:45 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.robotstxt.RobotsTxtMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2019-03-26 14:50:45 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2019-03-26 14:50:45 [scrapy.middleware] INFO: Enabled item pipelines:
['GovSpider2.pipelines.Govspider2Pipeline']
2019-03-26 14:50:45 [scrapy.core.engine] INFO: Spider opened
2019-03-26 14:50:45 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-03-26 14:50:45 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023
2019-03-26 14:50:46 [scrapy.core.engine] INFO: Closing spider (finished)
2019-03-26 14:50:46 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 7317,
 'downloader/request_count': 20,
 'downloader/request_method_count/GET': 20,
 'downloader/response_bytes': 335313,
 'downloader/response_count': 20,
 'downloader/response_status_count/200': 20,
 'dupefilter/filtered': 18,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2019, 3, 26, 6, 50, 46, 553051),
 'log_count/INFO': 9,
 'memusage/max': 50155520,
 'memusage/startup': 50155520,
 'request_depth_max': 2,
 'response_received_count': 20,
 'robotstxt/request_count': 1,
 'robotstxt/response_count': 1,
 'robotstxt/response_status_count/200': 1,
 'scheduler/dequeued': 19,
 'scheduler/dequeued/memory': 19,
 'scheduler/enqueued': 19,
 'scheduler/enqueued/memory': 19,
 'start_time': datetime.datetime(2019, 3, 26, 6, 50, 45, 892583)}
2019-03-26 14:50:46 [scrapy.core.engine] INFO: Spider closed (finished)
2019-03-26 15:05:51 [scrapy.utils.log] INFO: Scrapy 1.6.0 started (bot: GovSpider2)
2019-03-26 15:05:51 [scrapy.utils.log] INFO: Versions: lxml 4.3.2.0, libxml2 2.9.9, cssselect 1.0.3, parsel 1.5.1, w3lib 1.20.0, Twisted 18.9.0, Python 3.7.2 (default, Feb 13 2019, 10:07:58) - [Clang 10.0.0 (clang-1000.11.45.5)], pyOpenSSL 19.0.0 (OpenSSL 1.1.1b  26 Feb 2019), cryptography 2.6.1, Platform Darwin-18.2.0-x86_64-i386-64bit
2019-03-26 15:05:51 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'GovSpider2', 'LOG_FILE': 'log/spiderlog20190326.txt', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'GovSpider2.spiders', 'ROBOTSTXT_OBEY': True, 'SPIDER_MODULES': ['GovSpider2.spiders']}
2019-03-26 15:05:51 [scrapy.extensions.telnet] INFO: Telnet Password: b50bde47b5e9097a
2019-03-26 15:05:51 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats']
2019-03-26 15:05:51 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.robotstxt.RobotsTxtMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2019-03-26 15:05:51 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2019-03-26 15:05:51 [scrapy.middleware] INFO: Enabled item pipelines:
['GovSpider2.pipelines.Govspider2Pipeline']
2019-03-26 15:05:51 [scrapy.core.engine] INFO: Spider opened
2019-03-26 15:05:51 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-03-26 15:05:51 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023
2019-03-26 15:05:52 [scrapy.core.engine] INFO: Closing spider (finished)
2019-03-26 15:05:52 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 7317,
 'downloader/request_count': 20,
 'downloader/request_method_count/GET': 20,
 'downloader/response_bytes': 335332,
 'downloader/response_count': 20,
 'downloader/response_status_count/200': 20,
 'dupefilter/filtered': 18,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2019, 3, 26, 7, 5, 52, 997091),
 'log_count/INFO': 9,
 'memusage/max': 50106368,
 'memusage/startup': 50102272,
 'request_depth_max': 2,
 'response_received_count': 20,
 'robotstxt/request_count': 1,
 'robotstxt/response_count': 1,
 'robotstxt/response_status_count/200': 1,
 'scheduler/dequeued': 19,
 'scheduler/dequeued/memory': 19,
 'scheduler/enqueued': 19,
 'scheduler/enqueued/memory': 19,
 'start_time': datetime.datetime(2019, 3, 26, 7, 5, 51, 356947)}
2019-03-26 15:05:52 [scrapy.core.engine] INFO: Spider closed (finished)
2019-03-26 15:06:42 [scrapy.utils.log] INFO: Scrapy 1.6.0 started (bot: GovSpider2)
2019-03-26 15:06:42 [scrapy.utils.log] INFO: Versions: lxml 4.3.2.0, libxml2 2.9.9, cssselect 1.0.3, parsel 1.5.1, w3lib 1.20.0, Twisted 18.9.0, Python 3.7.2 (default, Feb 13 2019, 10:07:58) - [Clang 10.0.0 (clang-1000.11.45.5)], pyOpenSSL 19.0.0 (OpenSSL 1.1.1b  26 Feb 2019), cryptography 2.6.1, Platform Darwin-18.2.0-x86_64-i386-64bit
2019-03-26 15:06:42 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'GovSpider2', 'LOG_FILE': 'log/spiderlog20190326.txt', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'GovSpider2.spiders', 'ROBOTSTXT_OBEY': True, 'SPIDER_MODULES': ['GovSpider2.spiders']}
2019-03-26 15:06:42 [scrapy.extensions.telnet] INFO: Telnet Password: 829a33abae0bed67
2019-03-26 15:06:42 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats']
2019-03-26 15:06:42 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.robotstxt.RobotsTxtMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2019-03-26 15:06:42 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2019-03-26 15:06:42 [scrapy.middleware] INFO: Enabled item pipelines:
['GovSpider2.pipelines.Govspider2Pipeline']
2019-03-26 15:06:42 [scrapy.core.engine] INFO: Spider opened
2019-03-26 15:06:42 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-03-26 15:06:42 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023
2019-03-26 15:06:44 [scrapy.core.engine] INFO: Closing spider (finished)
2019-03-26 15:06:44 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 13963,
 'downloader/request_count': 38,
 'downloader/request_method_count/GET': 38,
 'downloader/response_bytes': 623700,
 'downloader/response_count': 38,
 'downloader/response_status_count/200': 38,
 'dupefilter/filtered': 35,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2019, 3, 26, 7, 6, 44, 222216),
 'log_count/INFO': 9,
 'memusage/max': 50225152,
 'memusage/startup': 50221056,
 'request_depth_max': 2,
 'response_received_count': 38,
 'robotstxt/request_count': 1,
 'robotstxt/response_count': 1,
 'robotstxt/response_status_count/200': 1,
 'scheduler/dequeued': 37,
 'scheduler/dequeued/memory': 37,
 'scheduler/enqueued': 37,
 'scheduler/enqueued/memory': 37,
 'start_time': datetime.datetime(2019, 3, 26, 7, 6, 42, 282369)}
2019-03-26 15:06:44 [scrapy.core.engine] INFO: Spider closed (finished)
2019-03-26 15:07:04 [scrapy.utils.log] INFO: Scrapy 1.6.0 started (bot: GovSpider2)
2019-03-26 15:07:04 [scrapy.utils.log] INFO: Versions: lxml 4.3.2.0, libxml2 2.9.9, cssselect 1.0.3, parsel 1.5.1, w3lib 1.20.0, Twisted 18.9.0, Python 3.7.2 (default, Feb 13 2019, 10:07:58) - [Clang 10.0.0 (clang-1000.11.45.5)], pyOpenSSL 19.0.0 (OpenSSL 1.1.1b  26 Feb 2019), cryptography 2.6.1, Platform Darwin-18.2.0-x86_64-i386-64bit
2019-03-26 15:07:04 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'GovSpider2', 'LOG_FILE': 'log/spiderlog20190326.txt', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'GovSpider2.spiders', 'ROBOTSTXT_OBEY': True, 'SPIDER_MODULES': ['GovSpider2.spiders']}
2019-03-26 15:07:04 [scrapy.extensions.telnet] INFO: Telnet Password: 3720de3a9173e345
2019-03-26 15:07:04 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats']
2019-03-26 15:07:04 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.robotstxt.RobotsTxtMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2019-03-26 15:07:04 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2019-03-26 15:07:04 [scrapy.middleware] INFO: Enabled item pipelines:
['GovSpider2.pipelines.Govspider2Pipeline']
2019-03-26 15:07:04 [scrapy.core.engine] INFO: Spider opened
2019-03-26 15:07:04 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-03-26 15:07:04 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023
2019-03-26 15:07:06 [scrapy.core.engine] INFO: Closing spider (finished)
2019-03-26 15:07:06 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 11301,
 'downloader/request_count': 31,
 'downloader/request_method_count/GET': 31,
 'downloader/response_bytes': 515835,
 'downloader/response_count': 31,
 'downloader/response_status_count/200': 31,
 'dupefilter/filtered': 28,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2019, 3, 26, 7, 7, 6, 225547),
 'log_count/INFO': 9,
 'memusage/max': 49885184,
 'memusage/startup': 49881088,
 'offsite/domains': 1,
 'offsite/filtered': 1,
 'request_depth_max': 2,
 'response_received_count': 31,
 'robotstxt/request_count': 1,
 'robotstxt/response_count': 1,
 'robotstxt/response_status_count/200': 1,
 'scheduler/dequeued': 30,
 'scheduler/dequeued/memory': 30,
 'scheduler/enqueued': 30,
 'scheduler/enqueued/memory': 30,
 'start_time': datetime.datetime(2019, 3, 26, 7, 7, 4, 654896)}
2019-03-26 15:07:06 [scrapy.core.engine] INFO: Spider closed (finished)
2019-03-26 15:09:16 [scrapy.utils.log] INFO: Scrapy 1.6.0 started (bot: GovSpider2)
2019-03-26 15:09:16 [scrapy.utils.log] INFO: Versions: lxml 4.3.2.0, libxml2 2.9.9, cssselect 1.0.3, parsel 1.5.1, w3lib 1.20.0, Twisted 18.9.0, Python 3.7.2 (default, Feb 13 2019, 10:07:58) - [Clang 10.0.0 (clang-1000.11.45.5)], pyOpenSSL 19.0.0 (OpenSSL 1.1.1b  26 Feb 2019), cryptography 2.6.1, Platform Darwin-18.2.0-x86_64-i386-64bit
2019-03-26 15:09:16 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'GovSpider2', 'LOG_FILE': 'log/spiderlog20190326.txt', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'GovSpider2.spiders', 'ROBOTSTXT_OBEY': True, 'SPIDER_MODULES': ['GovSpider2.spiders']}
2019-03-26 15:09:16 [scrapy.extensions.telnet] INFO: Telnet Password: 2830c7d19f24b790
2019-03-26 15:09:16 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats']
2019-03-26 15:09:16 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.robotstxt.RobotsTxtMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2019-03-26 15:09:16 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2019-03-26 15:09:16 [scrapy.middleware] INFO: Enabled item pipelines:
['GovSpider2.pipelines.Govspider2Pipeline']
2019-03-26 15:09:16 [scrapy.core.engine] INFO: Spider opened
2019-03-26 15:09:16 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-03-26 15:09:16 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023
2019-03-26 15:09:17 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.gov.cn/banshi/2005-07/06/content_12279.htm> (referer: http://www.gov.cn/banshi/wjrs/crj.htm)
Traceback (most recent call last):
  File "/usr/local/lib/python3.7/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python3.7/site-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/Users/a824810056/Desktop/py2.7-GovSpider/GovSpider2/GovSpider2/spiders/govSpider.py", line 72, in parse_item
    os.mkdir(newPath)
FileNotFoundError: [Errno 2] No such file or directory: '/Users/a824810056/Desktop/py2.7-GovSpider/GovSpider2/foregin/banshi/wjrs/crj'
2019-03-26 15:09:17 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.gov.cn/banshi/2005-09/12/content_31017.htm> (referer: http://www.gov.cn/banshi/wjrs/crj.htm)
Traceback (most recent call last):
  File "/usr/local/lib/python3.7/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python3.7/site-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/Users/a824810056/Desktop/py2.7-GovSpider/GovSpider2/GovSpider2/spiders/govSpider.py", line 72, in parse_item
    os.mkdir(newPath)
FileNotFoundError: [Errno 2] No such file or directory: '/Users/a824810056/Desktop/py2.7-GovSpider/GovSpider2/foregin/banshi/wjrs/crj'
2019-03-26 15:09:17 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.gov.cn/banshi/2006-10/09/content_408014.htm> (referer: http://www.gov.cn/banshi/wjrs/crj.htm)
Traceback (most recent call last):
  File "/usr/local/lib/python3.7/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python3.7/site-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/Users/a824810056/Desktop/py2.7-GovSpider/GovSpider2/GovSpider2/spiders/govSpider.py", line 72, in parse_item
    os.mkdir(newPath)
FileNotFoundError: [Errno 2] No such file or directory: '/Users/a824810056/Desktop/py2.7-GovSpider/GovSpider2/foregin/banshi/wjrs/crj'
2019-03-26 15:09:17 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.gov.cn/banshi/2006-10/09/content_408010.htm> (referer: http://www.gov.cn/banshi/wjrs/crj.htm)
Traceback (most recent call last):
  File "/usr/local/lib/python3.7/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python3.7/site-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/Users/a824810056/Desktop/py2.7-GovSpider/GovSpider2/GovSpider2/spiders/govSpider.py", line 72, in parse_item
    os.mkdir(newPath)
FileNotFoundError: [Errno 2] No such file or directory: '/Users/a824810056/Desktop/py2.7-GovSpider/GovSpider2/foregin/banshi/wjrs/crj'
2019-03-26 15:09:17 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.gov.cn/banshi/2005-06/08/content_4836.htm> (referer: http://www.gov.cn/banshi/wjrs/crj.htm)
Traceback (most recent call last):
  File "/usr/local/lib/python3.7/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python3.7/site-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/Users/a824810056/Desktop/py2.7-GovSpider/GovSpider2/GovSpider2/spiders/govSpider.py", line 72, in parse_item
    os.mkdir(newPath)
FileNotFoundError: [Errno 2] No such file or directory: '/Users/a824810056/Desktop/py2.7-GovSpider/GovSpider2/foregin/banshi/wjrs/crj'
2019-03-26 15:09:17 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.gov.cn/banshi/2006-08/23/content_368260.htm> (referer: http://www.gov.cn/banshi/wjrs/crj.htm)
Traceback (most recent call last):
  File "/usr/local/lib/python3.7/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python3.7/site-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/Users/a824810056/Desktop/py2.7-GovSpider/GovSpider2/GovSpider2/spiders/govSpider.py", line 72, in parse_item
    os.mkdir(newPath)
FileNotFoundError: [Errno 2] No such file or directory: '/Users/a824810056/Desktop/py2.7-GovSpider/GovSpider2/foregin/banshi/wjrs/crj'
2019-03-26 15:09:17 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.gov.cn/banshi/2006-10/09/content_408005.htm> (referer: http://www.gov.cn/banshi/wjrs/crj.htm)
Traceback (most recent call last):
  File "/usr/local/lib/python3.7/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python3.7/site-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/Users/a824810056/Desktop/py2.7-GovSpider/GovSpider2/GovSpider2/spiders/govSpider.py", line 72, in parse_item
    os.mkdir(newPath)
FileNotFoundError: [Errno 2] No such file or directory: '/Users/a824810056/Desktop/py2.7-GovSpider/GovSpider2/foregin/banshi/wjrs/crj'
2019-03-26 15:09:17 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.gov.cn/banshi/2006-10/09/content_408016.htm> (referer: http://www.gov.cn/banshi/wjrs/crj.htm)
Traceback (most recent call last):
  File "/usr/local/lib/python3.7/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python3.7/site-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/Users/a824810056/Desktop/py2.7-GovSpider/GovSpider2/GovSpider2/spiders/govSpider.py", line 72, in parse_item
    os.mkdir(newPath)
FileNotFoundError: [Errno 2] No such file or directory: '/Users/a824810056/Desktop/py2.7-GovSpider/GovSpider2/foregin/banshi/wjrs/crj'
2019-03-26 15:09:17 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.gov.cn/banshi/2006-10/09/content_408018.htm> (referer: http://www.gov.cn/banshi/wjrs/crj.htm)
Traceback (most recent call last):
  File "/usr/local/lib/python3.7/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python3.7/site-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/Users/a824810056/Desktop/py2.7-GovSpider/GovSpider2/GovSpider2/spiders/govSpider.py", line 72, in parse_item
    os.mkdir(newPath)
FileNotFoundError: [Errno 2] No such file or directory: '/Users/a824810056/Desktop/py2.7-GovSpider/GovSpider2/foregin/banshi/wjrs/crj'
2019-03-26 15:09:17 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.gov.cn/banshi/2012-11/19/content_2269877.htm> (referer: http://www.gov.cn/banshi/wjrs/crj.htm)
Traceback (most recent call last):
  File "/usr/local/lib/python3.7/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python3.7/site-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/Users/a824810056/Desktop/py2.7-GovSpider/GovSpider2/GovSpider2/spiders/govSpider.py", line 72, in parse_item
    os.mkdir(newPath)
FileNotFoundError: [Errno 2] No such file or directory: '/Users/a824810056/Desktop/py2.7-GovSpider/GovSpider2/foregin/banshi/wjrs/crj'
2019-03-26 15:09:17 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.gov.cn/banshi/2012-11/19/content_2269878.htm> (referer: http://www.gov.cn/banshi/wjrs/crj.htm)
Traceback (most recent call last):
  File "/usr/local/lib/python3.7/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python3.7/site-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/Users/a824810056/Desktop/py2.7-GovSpider/GovSpider2/GovSpider2/spiders/govSpider.py", line 72, in parse_item
    os.mkdir(newPath)
FileNotFoundError: [Errno 2] No such file or directory: '/Users/a824810056/Desktop/py2.7-GovSpider/GovSpider2/foregin/banshi/wjrs/crj'
2019-03-26 15:09:17 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.gov.cn/banshi/2005-06/08/content_4837.htm> (referer: http://www.gov.cn/banshi/wjrs/crj.htm)
Traceback (most recent call last):
  File "/usr/local/lib/python3.7/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python3.7/site-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/Users/a824810056/Desktop/py2.7-GovSpider/GovSpider2/GovSpider2/spiders/govSpider.py", line 72, in parse_item
    os.mkdir(newPath)
FileNotFoundError: [Errno 2] No such file or directory: '/Users/a824810056/Desktop/py2.7-GovSpider/GovSpider2/foregin/banshi/wjrs/crj'
2019-03-26 15:09:17 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.gov.cn/banshi/2005-05/26/content_1300.htm> (referer: http://www.gov.cn/banshi/wjrs/crj.htm)
Traceback (most recent call last):
  File "/usr/local/lib/python3.7/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python3.7/site-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/Users/a824810056/Desktop/py2.7-GovSpider/GovSpider2/GovSpider2/spiders/govSpider.py", line 72, in parse_item
    os.mkdir(newPath)
FileNotFoundError: [Errno 2] No such file or directory: '/Users/a824810056/Desktop/py2.7-GovSpider/GovSpider2/foregin/banshi/wjrs/crj'
2019-03-26 15:09:17 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.gov.cn/banshi/2012-11/19/content_2269879.htm> (referer: http://www.gov.cn/banshi/wjrs/crj.htm)
Traceback (most recent call last):
  File "/usr/local/lib/python3.7/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python3.7/site-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/Users/a824810056/Desktop/py2.7-GovSpider/GovSpider2/GovSpider2/spiders/govSpider.py", line 72, in parse_item
    os.mkdir(newPath)
FileNotFoundError: [Errno 2] No such file or directory: '/Users/a824810056/Desktop/py2.7-GovSpider/GovSpider2/foregin/banshi/wjrs/crj'
2019-03-26 15:09:17 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.gov.cn/banshi/2012-11/19/content_2269876.htm> (referer: http://www.gov.cn/banshi/wjrs/crj.htm)
Traceback (most recent call last):
  File "/usr/local/lib/python3.7/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python3.7/site-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/Users/a824810056/Desktop/py2.7-GovSpider/GovSpider2/GovSpider2/spiders/govSpider.py", line 72, in parse_item
    os.mkdir(newPath)
FileNotFoundError: [Errno 2] No such file or directory: '/Users/a824810056/Desktop/py2.7-GovSpider/GovSpider2/foregin/banshi/wjrs/crj'
2019-03-26 15:09:17 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.gov.cn/banshi/2012-11/19/content_2269880.htm> (referer: http://www.gov.cn/banshi/wjrs/crj.htm)
Traceback (most recent call last):
  File "/usr/local/lib/python3.7/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python3.7/site-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/Users/a824810056/Desktop/py2.7-GovSpider/GovSpider2/GovSpider2/spiders/govSpider.py", line 72, in parse_item
    os.mkdir(newPath)
FileNotFoundError: [Errno 2] No such file or directory: '/Users/a824810056/Desktop/py2.7-GovSpider/GovSpider2/foregin/banshi/wjrs/crj'
2019-03-26 15:09:17 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.gov.cn/banshi/2005-07/08/content_13036.htm> (referer: http://www.gov.cn/banshi/wjrs/crj.htm)
Traceback (most recent call last):
  File "/usr/local/lib/python3.7/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python3.7/site-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/Users/a824810056/Desktop/py2.7-GovSpider/GovSpider2/GovSpider2/spiders/govSpider.py", line 72, in parse_item
    os.mkdir(newPath)
FileNotFoundError: [Errno 2] No such file or directory: '/Users/a824810056/Desktop/py2.7-GovSpider/GovSpider2/foregin/banshi/wjrs/crj'
2019-03-26 15:09:17 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.gov.cn/banshi/2007-05/10/content_610216.htm> (referer: http://www.gov.cn/banshi/wjrs/crj.htm)
Traceback (most recent call last):
  File "/usr/local/lib/python3.7/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python3.7/site-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/Users/a824810056/Desktop/py2.7-GovSpider/GovSpider2/GovSpider2/spiders/govSpider.py", line 72, in parse_item
    os.mkdir(newPath)
FileNotFoundError: [Errno 2] No such file or directory: '/Users/a824810056/Desktop/py2.7-GovSpider/GovSpider2/foregin/banshi/wjrs/crj'
2019-03-26 15:09:18 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.gov.cn/banshi/2005-10/10/content_75453.htm> (referer: http://www.gov.cn/banshi/zjpq.htm)
Traceback (most recent call last):
  File "/usr/local/lib/python3.7/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python3.7/site-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/Users/a824810056/Desktop/py2.7-GovSpider/GovSpider2/GovSpider2/spiders/govSpider.py", line 72, in parse_item
    os.mkdir(newPath)
FileNotFoundError: [Errno 2] No such file or directory: '/Users/a824810056/Desktop/py2.7-GovSpider/GovSpider2/foregin/banshi/zjpq'
2019-03-26 15:09:18 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.gov.cn/banshi/2005-10/10/content_75529.htm> (referer: http://www.gov.cn/banshi/zjpq.htm)
Traceback (most recent call last):
  File "/usr/local/lib/python3.7/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python3.7/site-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/Users/a824810056/Desktop/py2.7-GovSpider/GovSpider2/GovSpider2/spiders/govSpider.py", line 72, in parse_item
    os.mkdir(newPath)
FileNotFoundError: [Errno 2] No such file or directory: '/Users/a824810056/Desktop/py2.7-GovSpider/GovSpider2/foregin/banshi/zjpq'
2019-03-26 15:09:18 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.gov.cn/banshi/2005-10/10/content_75460.htm> (referer: http://www.gov.cn/banshi/zjpq.htm)
Traceback (most recent call last):
  File "/usr/local/lib/python3.7/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python3.7/site-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/Users/a824810056/Desktop/py2.7-GovSpider/GovSpider2/GovSpider2/spiders/govSpider.py", line 72, in parse_item
    os.mkdir(newPath)
FileNotFoundError: [Errno 2] No such file or directory: '/Users/a824810056/Desktop/py2.7-GovSpider/GovSpider2/foregin/banshi/zjpq'
2019-03-26 15:09:18 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.gov.cn/banshi/2005-10/10/content_75526.htm> (referer: http://www.gov.cn/banshi/zjpq.htm)
Traceback (most recent call last):
  File "/usr/local/lib/python3.7/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python3.7/site-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/Users/a824810056/Desktop/py2.7-GovSpider/GovSpider2/GovSpider2/spiders/govSpider.py", line 72, in parse_item
    os.mkdir(newPath)
FileNotFoundError: [Errno 2] No such file or directory: '/Users/a824810056/Desktop/py2.7-GovSpider/GovSpider2/foregin/banshi/zjpq'
2019-03-26 15:09:18 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.gov.cn/banshi/2005-10/10/content_75518.htm> (referer: http://www.gov.cn/banshi/zjpq.htm)
Traceback (most recent call last):
  File "/usr/local/lib/python3.7/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python3.7/site-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/Users/a824810056/Desktop/py2.7-GovSpider/GovSpider2/GovSpider2/spiders/govSpider.py", line 72, in parse_item
    os.mkdir(newPath)
FileNotFoundError: [Errno 2] No such file or directory: '/Users/a824810056/Desktop/py2.7-GovSpider/GovSpider2/foregin/banshi/zjpq'
2019-03-26 15:09:18 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.gov.cn/banshi/2005-06/23/content_75551.htm> (referer: http://www.gov.cn/banshi/zjpq.htm)
Traceback (most recent call last):
  File "/usr/local/lib/python3.7/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python3.7/site-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/Users/a824810056/Desktop/py2.7-GovSpider/GovSpider2/GovSpider2/spiders/govSpider.py", line 72, in parse_item
    os.mkdir(newPath)
FileNotFoundError: [Errno 2] No such file or directory: '/Users/a824810056/Desktop/py2.7-GovSpider/GovSpider2/foregin/banshi/zjpq'
2019-03-26 15:09:18 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.gov.cn/banshi/2005-10/10/content_75500.htm> (referer: http://www.gov.cn/banshi/zjpq.htm)
Traceback (most recent call last):
  File "/usr/local/lib/python3.7/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python3.7/site-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/Users/a824810056/Desktop/py2.7-GovSpider/GovSpider2/GovSpider2/spiders/govSpider.py", line 72, in parse_item
    os.mkdir(newPath)
FileNotFoundError: [Errno 2] No such file or directory: '/Users/a824810056/Desktop/py2.7-GovSpider/GovSpider2/foregin/banshi/zjpq'
2019-03-26 15:09:18 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.gov.cn/banshi/2005-06/23/content_8734.htm> (referer: http://www.gov.cn/banshi/zjpq.htm)
Traceback (most recent call last):
  File "/usr/local/lib/python3.7/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python3.7/site-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/Users/a824810056/Desktop/py2.7-GovSpider/GovSpider2/GovSpider2/spiders/govSpider.py", line 72, in parse_item
    os.mkdir(newPath)
FileNotFoundError: [Errno 2] No such file or directory: '/Users/a824810056/Desktop/py2.7-GovSpider/GovSpider2/foregin/banshi/zjpq'
2019-03-26 15:09:18 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.gov.cn/banshi/2005-10/10/content_75553.htm> (referer: http://www.gov.cn/banshi/zjpq.htm)
Traceback (most recent call last):
  File "/usr/local/lib/python3.7/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python3.7/site-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/Users/a824810056/Desktop/py2.7-GovSpider/GovSpider2/GovSpider2/spiders/govSpider.py", line 72, in parse_item
    os.mkdir(newPath)
FileNotFoundError: [Errno 2] No such file or directory: '/Users/a824810056/Desktop/py2.7-GovSpider/GovSpider2/foregin/banshi/zjpq'
2019-03-26 15:09:18 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.gov.cn/banshi/2006-03/02/content_215803.htm> (referer: http://www.gov.cn/banshi/zjpq.htm)
Traceback (most recent call last):
  File "/usr/local/lib/python3.7/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python3.7/site-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/Users/a824810056/Desktop/py2.7-GovSpider/GovSpider2/GovSpider2/spiders/govSpider.py", line 72, in parse_item
    os.mkdir(newPath)
FileNotFoundError: [Errno 2] No such file or directory: '/Users/a824810056/Desktop/py2.7-GovSpider/GovSpider2/foregin/banshi/zjpq'
2019-03-26 15:09:18 [scrapy.core.engine] INFO: Closing spider (finished)
2019-03-26 15:09:18 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 11301,
 'downloader/request_count': 31,
 'downloader/request_method_count/GET': 31,
 'downloader/response_bytes': 515826,
 'downloader/response_count': 31,
 'downloader/response_status_count/200': 31,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2019, 3, 26, 7, 9, 18, 935975),
 'log_count/ERROR': 28,
 'log_count/INFO': 9,
 'memusage/max': 50106368,
 'memusage/startup': 50106368,
 'offsite/domains': 1,
 'offsite/filtered': 1,
 'request_depth_max': 1,
 'response_received_count': 31,
 'robotstxt/request_count': 1,
 'robotstxt/response_count': 1,
 'robotstxt/response_status_count/200': 1,
 'scheduler/dequeued': 30,
 'scheduler/dequeued/memory': 30,
 'scheduler/enqueued': 30,
 'scheduler/enqueued/memory': 30,
 'spider_exceptions/FileNotFoundError': 28,
 'start_time': datetime.datetime(2019, 3, 26, 7, 9, 16, 351745)}
2019-03-26 15:09:18 [scrapy.core.engine] INFO: Spider closed (finished)
2019-03-26 15:10:23 [scrapy.utils.log] INFO: Scrapy 1.6.0 started (bot: GovSpider2)
2019-03-26 15:10:23 [scrapy.utils.log] INFO: Versions: lxml 4.3.2.0, libxml2 2.9.9, cssselect 1.0.3, parsel 1.5.1, w3lib 1.20.0, Twisted 18.9.0, Python 3.7.2 (default, Feb 13 2019, 10:07:58) - [Clang 10.0.0 (clang-1000.11.45.5)], pyOpenSSL 19.0.0 (OpenSSL 1.1.1b  26 Feb 2019), cryptography 2.6.1, Platform Darwin-18.2.0-x86_64-i386-64bit
2019-03-26 15:10:23 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'GovSpider2', 'LOG_FILE': 'log/spiderlog20190326.txt', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'GovSpider2.spiders', 'ROBOTSTXT_OBEY': True, 'SPIDER_MODULES': ['GovSpider2.spiders']}
2019-03-26 15:10:23 [scrapy.extensions.telnet] INFO: Telnet Password: 9d5afc2163076d0f
2019-03-26 15:10:23 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats']
2019-03-26 15:10:23 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.robotstxt.RobotsTxtMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2019-03-26 15:10:23 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2019-03-26 15:10:23 [scrapy.middleware] INFO: Enabled item pipelines:
['GovSpider2.pipelines.Govspider2Pipeline']
2019-03-26 15:10:23 [scrapy.core.engine] INFO: Spider opened
2019-03-26 15:10:23 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-03-26 15:10:23 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023
2019-03-26 15:10:23 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.gov.cn/banshi/2005-07/06/content_12279.htm> (referer: http://www.gov.cn/banshi/wjrs/crj.htm)
Traceback (most recent call last):
  File "/usr/local/lib/python3.7/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python3.7/site-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/Users/a824810056/Desktop/py2.7-GovSpider/GovSpider2/GovSpider2/spiders/govSpider.py", line 74, in parse_item
    os.mkdir(newPath)
FileNotFoundError: [Errno 2] No such file or directory: '/Users/a824810056/Desktop/py2.7-GovSpider/GovSpider2/foregin/banshi/wjrs/crj'
2019-03-26 15:10:23 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.gov.cn/banshi/2005-05/26/content_1300.htm> (referer: http://www.gov.cn/banshi/wjrs/crj.htm)
Traceback (most recent call last):
  File "/usr/local/lib/python3.7/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python3.7/site-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/Users/a824810056/Desktop/py2.7-GovSpider/GovSpider2/GovSpider2/spiders/govSpider.py", line 74, in parse_item
    os.mkdir(newPath)
FileNotFoundError: [Errno 2] No such file or directory: '/Users/a824810056/Desktop/py2.7-GovSpider/GovSpider2/foregin/banshi/wjrs/crj'
2019-03-26 15:10:23 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.gov.cn/banshi/2006-10/09/content_408010.htm> (referer: http://www.gov.cn/banshi/wjrs/crj.htm)
Traceback (most recent call last):
  File "/usr/local/lib/python3.7/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python3.7/site-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/Users/a824810056/Desktop/py2.7-GovSpider/GovSpider2/GovSpider2/spiders/govSpider.py", line 74, in parse_item
    os.mkdir(newPath)
FileNotFoundError: [Errno 2] No such file or directory: '/Users/a824810056/Desktop/py2.7-GovSpider/GovSpider2/foregin/banshi/wjrs/crj'
2019-03-26 15:10:23 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.gov.cn/banshi/2005-07/08/content_13036.htm> (referer: http://www.gov.cn/banshi/wjrs/crj.htm)
Traceback (most recent call last):
  File "/usr/local/lib/python3.7/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python3.7/site-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/Users/a824810056/Desktop/py2.7-GovSpider/GovSpider2/GovSpider2/spiders/govSpider.py", line 74, in parse_item
    os.mkdir(newPath)
FileNotFoundError: [Errno 2] No such file or directory: '/Users/a824810056/Desktop/py2.7-GovSpider/GovSpider2/foregin/banshi/wjrs/crj'
2019-03-26 15:10:23 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.gov.cn/banshi/2006-08/23/content_368260.htm> (referer: http://www.gov.cn/banshi/wjrs/crj.htm)
Traceback (most recent call last):
  File "/usr/local/lib/python3.7/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python3.7/site-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/Users/a824810056/Desktop/py2.7-GovSpider/GovSpider2/GovSpider2/spiders/govSpider.py", line 74, in parse_item
    os.mkdir(newPath)
FileNotFoundError: [Errno 2] No such file or directory: '/Users/a824810056/Desktop/py2.7-GovSpider/GovSpider2/foregin/banshi/wjrs/crj'
2019-03-26 15:10:23 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.gov.cn/banshi/2006-10/09/content_408014.htm> (referer: http://www.gov.cn/banshi/wjrs/crj.htm)
Traceback (most recent call last):
  File "/usr/local/lib/python3.7/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python3.7/site-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/Users/a824810056/Desktop/py2.7-GovSpider/GovSpider2/GovSpider2/spiders/govSpider.py", line 74, in parse_item
    os.mkdir(newPath)
FileNotFoundError: [Errno 2] No such file or directory: '/Users/a824810056/Desktop/py2.7-GovSpider/GovSpider2/foregin/banshi/wjrs/crj'
2019-03-26 15:10:23 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.gov.cn/banshi/2005-09/12/content_31017.htm> (referer: http://www.gov.cn/banshi/wjrs/crj.htm)
Traceback (most recent call last):
  File "/usr/local/lib/python3.7/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python3.7/site-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/Users/a824810056/Desktop/py2.7-GovSpider/GovSpider2/GovSpider2/spiders/govSpider.py", line 74, in parse_item
    os.mkdir(newPath)
FileNotFoundError: [Errno 2] No such file or directory: '/Users/a824810056/Desktop/py2.7-GovSpider/GovSpider2/foregin/banshi/wjrs/crj'
2019-03-26 15:10:23 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.gov.cn/banshi/2006-10/09/content_408005.htm> (referer: http://www.gov.cn/banshi/wjrs/crj.htm)
Traceback (most recent call last):
  File "/usr/local/lib/python3.7/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python3.7/site-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/Users/a824810056/Desktop/py2.7-GovSpider/GovSpider2/GovSpider2/spiders/govSpider.py", line 74, in parse_item
    os.mkdir(newPath)
FileNotFoundError: [Errno 2] No such file or directory: '/Users/a824810056/Desktop/py2.7-GovSpider/GovSpider2/foregin/banshi/wjrs/crj'
2019-03-26 15:10:23 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.gov.cn/banshi/2006-10/09/content_408018.htm> (referer: http://www.gov.cn/banshi/wjrs/crj.htm)
Traceback (most recent call last):
  File "/usr/local/lib/python3.7/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python3.7/site-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/Users/a824810056/Desktop/py2.7-GovSpider/GovSpider2/GovSpider2/spiders/govSpider.py", line 74, in parse_item
    os.mkdir(newPath)
FileNotFoundError: [Errno 2] No such file or directory: '/Users/a824810056/Desktop/py2.7-GovSpider/GovSpider2/foregin/banshi/wjrs/crj'
2019-03-26 15:10:23 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.gov.cn/banshi/2007-05/10/content_610216.htm> (referer: http://www.gov.cn/banshi/wjrs/crj.htm)
Traceback (most recent call last):
  File "/usr/local/lib/python3.7/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python3.7/site-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/Users/a824810056/Desktop/py2.7-GovSpider/GovSpider2/GovSpider2/spiders/govSpider.py", line 74, in parse_item
    os.mkdir(newPath)
FileNotFoundError: [Errno 2] No such file or directory: '/Users/a824810056/Desktop/py2.7-GovSpider/GovSpider2/foregin/banshi/wjrs/crj'
2019-03-26 15:10:23 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.gov.cn/banshi/2012-11/19/content_2269877.htm> (referer: http://www.gov.cn/banshi/wjrs/crj.htm)
Traceback (most recent call last):
  File "/usr/local/lib/python3.7/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python3.7/site-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/Users/a824810056/Desktop/py2.7-GovSpider/GovSpider2/GovSpider2/spiders/govSpider.py", line 74, in parse_item
    os.mkdir(newPath)
FileNotFoundError: [Errno 2] No such file or directory: '/Users/a824810056/Desktop/py2.7-GovSpider/GovSpider2/foregin/banshi/wjrs/crj'
2019-03-26 15:10:23 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.gov.cn/banshi/2012-11/19/content_2269878.htm> (referer: http://www.gov.cn/banshi/wjrs/crj.htm)
Traceback (most recent call last):
  File "/usr/local/lib/python3.7/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python3.7/site-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/Users/a824810056/Desktop/py2.7-GovSpider/GovSpider2/GovSpider2/spiders/govSpider.py", line 74, in parse_item
    os.mkdir(newPath)
FileNotFoundError: [Errno 2] No such file or directory: '/Users/a824810056/Desktop/py2.7-GovSpider/GovSpider2/foregin/banshi/wjrs/crj'
2019-03-26 15:10:23 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.gov.cn/banshi/2012-11/19/content_2269876.htm> (referer: http://www.gov.cn/banshi/wjrs/crj.htm)
Traceback (most recent call last):
  File "/usr/local/lib/python3.7/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python3.7/site-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/Users/a824810056/Desktop/py2.7-GovSpider/GovSpider2/GovSpider2/spiders/govSpider.py", line 74, in parse_item
    os.mkdir(newPath)
FileNotFoundError: [Errno 2] No such file or directory: '/Users/a824810056/Desktop/py2.7-GovSpider/GovSpider2/foregin/banshi/wjrs/crj'
2019-03-26 15:10:23 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.gov.cn/banshi/2012-11/19/content_2269880.htm> (referer: http://www.gov.cn/banshi/wjrs/crj.htm)
Traceback (most recent call last):
  File "/usr/local/lib/python3.7/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python3.7/site-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/Users/a824810056/Desktop/py2.7-GovSpider/GovSpider2/GovSpider2/spiders/govSpider.py", line 74, in parse_item
    os.mkdir(newPath)
FileNotFoundError: [Errno 2] No such file or directory: '/Users/a824810056/Desktop/py2.7-GovSpider/GovSpider2/foregin/banshi/wjrs/crj'
2019-03-26 15:10:23 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.gov.cn/banshi/2005-10/10/content_75460.htm> (referer: http://www.gov.cn/banshi/zjpq.htm)
Traceback (most recent call last):
  File "/usr/local/lib/python3.7/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python3.7/site-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/Users/a824810056/Desktop/py2.7-GovSpider/GovSpider2/GovSpider2/spiders/govSpider.py", line 74, in parse_item
    os.mkdir(newPath)
FileNotFoundError: [Errno 2] No such file or directory: '/Users/a824810056/Desktop/py2.7-GovSpider/GovSpider2/foregin/banshi/zjpq'
2019-03-26 15:10:23 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.gov.cn/banshi/2005-06/23/content_75551.htm> (referer: http://www.gov.cn/banshi/zjpq.htm)
Traceback (most recent call last):
  File "/usr/local/lib/python3.7/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python3.7/site-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/Users/a824810056/Desktop/py2.7-GovSpider/GovSpider2/GovSpider2/spiders/govSpider.py", line 74, in parse_item
    os.mkdir(newPath)
FileNotFoundError: [Errno 2] No such file or directory: '/Users/a824810056/Desktop/py2.7-GovSpider/GovSpider2/foregin/banshi/zjpq'
2019-03-26 15:10:23 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.gov.cn/banshi/2005-06/08/content_4836.htm> (referer: http://www.gov.cn/banshi/wjrs/crj.htm)
Traceback (most recent call last):
  File "/usr/local/lib/python3.7/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python3.7/site-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/Users/a824810056/Desktop/py2.7-GovSpider/GovSpider2/GovSpider2/spiders/govSpider.py", line 74, in parse_item
    os.mkdir(newPath)
FileNotFoundError: [Errno 2] No such file or directory: '/Users/a824810056/Desktop/py2.7-GovSpider/GovSpider2/foregin/banshi/wjrs/crj'
2019-03-26 15:10:23 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.gov.cn/banshi/2005-06/08/content_4837.htm> (referer: http://www.gov.cn/banshi/wjrs/crj.htm)
Traceback (most recent call last):
  File "/usr/local/lib/python3.7/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python3.7/site-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/Users/a824810056/Desktop/py2.7-GovSpider/GovSpider2/GovSpider2/spiders/govSpider.py", line 74, in parse_item
    os.mkdir(newPath)
FileNotFoundError: [Errno 2] No such file or directory: '/Users/a824810056/Desktop/py2.7-GovSpider/GovSpider2/foregin/banshi/wjrs/crj'
2019-03-26 15:10:23 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.gov.cn/banshi/2012-11/19/content_2269879.htm> (referer: http://www.gov.cn/banshi/wjrs/crj.htm)
Traceback (most recent call last):
  File "/usr/local/lib/python3.7/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python3.7/site-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/Users/a824810056/Desktop/py2.7-GovSpider/GovSpider2/GovSpider2/spiders/govSpider.py", line 74, in parse_item
    os.mkdir(newPath)
FileNotFoundError: [Errno 2] No such file or directory: '/Users/a824810056/Desktop/py2.7-GovSpider/GovSpider2/foregin/banshi/wjrs/crj'
2019-03-26 15:10:23 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.gov.cn/banshi/2005-10/10/content_75518.htm> (referer: http://www.gov.cn/banshi/zjpq.htm)
Traceback (most recent call last):
  File "/usr/local/lib/python3.7/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python3.7/site-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/Users/a824810056/Desktop/py2.7-GovSpider/GovSpider2/GovSpider2/spiders/govSpider.py", line 74, in parse_item
    os.mkdir(newPath)
FileNotFoundError: [Errno 2] No such file or directory: '/Users/a824810056/Desktop/py2.7-GovSpider/GovSpider2/foregin/banshi/zjpq'
2019-03-26 15:10:23 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.gov.cn/banshi/2005-10/10/content_75529.htm> (referer: http://www.gov.cn/banshi/zjpq.htm)
Traceback (most recent call last):
  File "/usr/local/lib/python3.7/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python3.7/site-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/Users/a824810056/Desktop/py2.7-GovSpider/GovSpider2/GovSpider2/spiders/govSpider.py", line 74, in parse_item
    os.mkdir(newPath)
FileNotFoundError: [Errno 2] No such file or directory: '/Users/a824810056/Desktop/py2.7-GovSpider/GovSpider2/foregin/banshi/zjpq'
2019-03-26 15:10:23 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.gov.cn/banshi/2005-06/23/content_8734.htm> (referer: http://www.gov.cn/banshi/zjpq.htm)
Traceback (most recent call last):
  File "/usr/local/lib/python3.7/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python3.7/site-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/Users/a824810056/Desktop/py2.7-GovSpider/GovSpider2/GovSpider2/spiders/govSpider.py", line 74, in parse_item
    os.mkdir(newPath)
FileNotFoundError: [Errno 2] No such file or directory: '/Users/a824810056/Desktop/py2.7-GovSpider/GovSpider2/foregin/banshi/zjpq'
2019-03-26 15:10:23 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.gov.cn/banshi/2005-10/10/content_75500.htm> (referer: http://www.gov.cn/banshi/zjpq.htm)
Traceback (most recent call last):
  File "/usr/local/lib/python3.7/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python3.7/site-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/Users/a824810056/Desktop/py2.7-GovSpider/GovSpider2/GovSpider2/spiders/govSpider.py", line 74, in parse_item
    os.mkdir(newPath)
FileNotFoundError: [Errno 2] No such file or directory: '/Users/a824810056/Desktop/py2.7-GovSpider/GovSpider2/foregin/banshi/zjpq'
2019-03-26 15:10:23 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.gov.cn/banshi/2006-10/09/content_408016.htm> (referer: http://www.gov.cn/banshi/wjrs/crj.htm)
Traceback (most recent call last):
  File "/usr/local/lib/python3.7/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python3.7/site-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/Users/a824810056/Desktop/py2.7-GovSpider/GovSpider2/GovSpider2/spiders/govSpider.py", line 74, in parse_item
    os.mkdir(newPath)
FileNotFoundError: [Errno 2] No such file or directory: '/Users/a824810056/Desktop/py2.7-GovSpider/GovSpider2/foregin/banshi/wjrs/crj'
2019-03-26 15:10:23 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.gov.cn/banshi/2005-10/10/content_75553.htm> (referer: http://www.gov.cn/banshi/zjpq.htm)
Traceback (most recent call last):
  File "/usr/local/lib/python3.7/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python3.7/site-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/Users/a824810056/Desktop/py2.7-GovSpider/GovSpider2/GovSpider2/spiders/govSpider.py", line 74, in parse_item
    os.mkdir(newPath)
FileNotFoundError: [Errno 2] No such file or directory: '/Users/a824810056/Desktop/py2.7-GovSpider/GovSpider2/foregin/banshi/zjpq'
2019-03-26 15:10:23 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.gov.cn/banshi/2005-10/10/content_75526.htm> (referer: http://www.gov.cn/banshi/zjpq.htm)
Traceback (most recent call last):
  File "/usr/local/lib/python3.7/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python3.7/site-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/Users/a824810056/Desktop/py2.7-GovSpider/GovSpider2/GovSpider2/spiders/govSpider.py", line 74, in parse_item
    os.mkdir(newPath)
FileNotFoundError: [Errno 2] No such file or directory: '/Users/a824810056/Desktop/py2.7-GovSpider/GovSpider2/foregin/banshi/zjpq'
2019-03-26 15:10:23 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.gov.cn/banshi/2006-03/02/content_215803.htm> (referer: http://www.gov.cn/banshi/zjpq.htm)
Traceback (most recent call last):
  File "/usr/local/lib/python3.7/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python3.7/site-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/Users/a824810056/Desktop/py2.7-GovSpider/GovSpider2/GovSpider2/spiders/govSpider.py", line 74, in parse_item
    os.mkdir(newPath)
FileNotFoundError: [Errno 2] No such file or directory: '/Users/a824810056/Desktop/py2.7-GovSpider/GovSpider2/foregin/banshi/zjpq'
2019-03-26 15:10:24 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.gov.cn/banshi/2005-10/10/content_75453.htm> (referer: http://www.gov.cn/banshi/zjpq.htm)
Traceback (most recent call last):
  File "/usr/local/lib/python3.7/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python3.7/site-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/Users/a824810056/Desktop/py2.7-GovSpider/GovSpider2/GovSpider2/spiders/govSpider.py", line 74, in parse_item
    os.mkdir(newPath)
FileNotFoundError: [Errno 2] No such file or directory: '/Users/a824810056/Desktop/py2.7-GovSpider/GovSpider2/foregin/banshi/zjpq'
2019-03-26 15:10:24 [scrapy.core.engine] INFO: Closing spider (finished)
2019-03-26 15:10:24 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 11301,
 'downloader/request_count': 31,
 'downloader/request_method_count/GET': 31,
 'downloader/response_bytes': 515826,
 'downloader/response_count': 31,
 'downloader/response_status_count/200': 31,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2019, 3, 26, 7, 10, 24, 29436),
 'log_count/ERROR': 28,
 'log_count/INFO': 9,
 'memusage/max': 49938432,
 'memusage/startup': 49938432,
 'offsite/domains': 1,
 'offsite/filtered': 1,
 'request_depth_max': 1,
 'response_received_count': 31,
 'robotstxt/request_count': 1,
 'robotstxt/response_count': 1,
 'robotstxt/response_status_count/200': 1,
 'scheduler/dequeued': 30,
 'scheduler/dequeued/memory': 30,
 'scheduler/enqueued': 30,
 'scheduler/enqueued/memory': 30,
 'spider_exceptions/FileNotFoundError': 28,
 'start_time': datetime.datetime(2019, 3, 26, 7, 10, 23, 116308)}
2019-03-26 15:10:24 [scrapy.core.engine] INFO: Spider closed (finished)
2019-03-26 15:12:25 [scrapy.utils.log] INFO: Scrapy 1.6.0 started (bot: GovSpider2)
2019-03-26 15:12:25 [scrapy.utils.log] INFO: Versions: lxml 4.3.2.0, libxml2 2.9.9, cssselect 1.0.3, parsel 1.5.1, w3lib 1.20.0, Twisted 18.9.0, Python 3.7.2 (default, Feb 13 2019, 10:07:58) - [Clang 10.0.0 (clang-1000.11.45.5)], pyOpenSSL 19.0.0 (OpenSSL 1.1.1b  26 Feb 2019), cryptography 2.6.1, Platform Darwin-18.2.0-x86_64-i386-64bit
2019-03-26 15:12:25 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'GovSpider2', 'LOG_FILE': 'log/spiderlog20190326.txt', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'GovSpider2.spiders', 'ROBOTSTXT_OBEY': True, 'SPIDER_MODULES': ['GovSpider2.spiders']}
2019-03-26 15:12:25 [scrapy.extensions.telnet] INFO: Telnet Password: 1ba117198dddfc13
2019-03-26 15:12:25 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats']
2019-03-26 15:12:25 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.robotstxt.RobotsTxtMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2019-03-26 15:12:25 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2019-03-26 15:12:25 [scrapy.middleware] INFO: Enabled item pipelines:
['GovSpider2.pipelines.Govspider2Pipeline']
2019-03-26 15:12:25 [scrapy.core.engine] INFO: Spider opened
2019-03-26 15:12:25 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-03-26 15:12:25 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023
2019-03-26 15:12:25 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.gov.cn/banshi/2005-07/06/content_12279.htm> (referer: http://www.gov.cn/banshi/wjrs/crj.htm)
Traceback (most recent call last):
  File "/usr/local/lib/python3.7/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python3.7/site-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/Users/a824810056/Desktop/py2.7-GovSpider/GovSpider2/GovSpider2/spiders/govSpider.py", line 78, in parse_item
    os.mkdir(newPath)
FileNotFoundError: [Errno 2] No such file or directory: '/Users/a824810056/Desktop/py2.7-GovSpider/GovSpider2/foregin/banshi/wjrs/crj'
2019-03-26 15:12:25 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.gov.cn/banshi/2005-09/12/content_31017.htm> (referer: http://www.gov.cn/banshi/wjrs/crj.htm)
Traceback (most recent call last):
  File "/usr/local/lib/python3.7/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python3.7/site-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/Users/a824810056/Desktop/py2.7-GovSpider/GovSpider2/GovSpider2/spiders/govSpider.py", line 78, in parse_item
    os.mkdir(newPath)
FileNotFoundError: [Errno 2] No such file or directory: '/Users/a824810056/Desktop/py2.7-GovSpider/GovSpider2/foregin/banshi/wjrs/crj'
2019-03-26 15:12:25 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.gov.cn/banshi/2005-07/08/content_13036.htm> (referer: http://www.gov.cn/banshi/wjrs/crj.htm)
Traceback (most recent call last):
  File "/usr/local/lib/python3.7/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python3.7/site-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/Users/a824810056/Desktop/py2.7-GovSpider/GovSpider2/GovSpider2/spiders/govSpider.py", line 78, in parse_item
    os.mkdir(newPath)
FileNotFoundError: [Errno 2] No such file or directory: '/Users/a824810056/Desktop/py2.7-GovSpider/GovSpider2/foregin/banshi/wjrs/crj'
2019-03-26 15:12:25 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.gov.cn/banshi/2005-05/26/content_1300.htm> (referer: http://www.gov.cn/banshi/wjrs/crj.htm)
Traceback (most recent call last):
  File "/usr/local/lib/python3.7/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python3.7/site-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/Users/a824810056/Desktop/py2.7-GovSpider/GovSpider2/GovSpider2/spiders/govSpider.py", line 78, in parse_item
    os.mkdir(newPath)
FileNotFoundError: [Errno 2] No such file or directory: '/Users/a824810056/Desktop/py2.7-GovSpider/GovSpider2/foregin/banshi/wjrs/crj'
2019-03-26 15:12:25 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.gov.cn/banshi/2006-10/09/content_408016.htm> (referer: http://www.gov.cn/banshi/wjrs/crj.htm)
Traceback (most recent call last):
  File "/usr/local/lib/python3.7/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python3.7/site-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/Users/a824810056/Desktop/py2.7-GovSpider/GovSpider2/GovSpider2/spiders/govSpider.py", line 78, in parse_item
    os.mkdir(newPath)
FileNotFoundError: [Errno 2] No such file or directory: '/Users/a824810056/Desktop/py2.7-GovSpider/GovSpider2/foregin/banshi/wjrs/crj'
2019-03-26 15:12:25 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.gov.cn/banshi/2005-06/08/content_4837.htm> (referer: http://www.gov.cn/banshi/wjrs/crj.htm)
Traceback (most recent call last):
  File "/usr/local/lib/python3.7/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python3.7/site-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/Users/a824810056/Desktop/py2.7-GovSpider/GovSpider2/GovSpider2/spiders/govSpider.py", line 78, in parse_item
    os.mkdir(newPath)
FileNotFoundError: [Errno 2] No such file or directory: '/Users/a824810056/Desktop/py2.7-GovSpider/GovSpider2/foregin/banshi/wjrs/crj'
2019-03-26 15:12:25 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.gov.cn/banshi/2006-10/09/content_408014.htm> (referer: http://www.gov.cn/banshi/wjrs/crj.htm)
Traceback (most recent call last):
  File "/usr/local/lib/python3.7/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python3.7/site-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/Users/a824810056/Desktop/py2.7-GovSpider/GovSpider2/GovSpider2/spiders/govSpider.py", line 78, in parse_item
    os.mkdir(newPath)
FileNotFoundError: [Errno 2] No such file or directory: '/Users/a824810056/Desktop/py2.7-GovSpider/GovSpider2/foregin/banshi/wjrs/crj'
2019-03-26 15:12:25 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.gov.cn/banshi/2006-08/23/content_368260.htm> (referer: http://www.gov.cn/banshi/wjrs/crj.htm)
Traceback (most recent call last):
  File "/usr/local/lib/python3.7/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python3.7/site-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/Users/a824810056/Desktop/py2.7-GovSpider/GovSpider2/GovSpider2/spiders/govSpider.py", line 78, in parse_item
    os.mkdir(newPath)
FileNotFoundError: [Errno 2] No such file or directory: '/Users/a824810056/Desktop/py2.7-GovSpider/GovSpider2/foregin/banshi/wjrs/crj'
2019-03-26 15:12:25 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.gov.cn/banshi/2012-11/19/content_2269877.htm> (referer: http://www.gov.cn/banshi/wjrs/crj.htm)
Traceback (most recent call last):
  File "/usr/local/lib/python3.7/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python3.7/site-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/Users/a824810056/Desktop/py2.7-GovSpider/GovSpider2/GovSpider2/spiders/govSpider.py", line 78, in parse_item
    os.mkdir(newPath)
FileNotFoundError: [Errno 2] No such file or directory: '/Users/a824810056/Desktop/py2.7-GovSpider/GovSpider2/foregin/banshi/wjrs/crj'
2019-03-26 15:12:25 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.gov.cn/banshi/2006-10/09/content_408018.htm> (referer: http://www.gov.cn/banshi/wjrs/crj.htm)
Traceback (most recent call last):
  File "/usr/local/lib/python3.7/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python3.7/site-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/Users/a824810056/Desktop/py2.7-GovSpider/GovSpider2/GovSpider2/spiders/govSpider.py", line 78, in parse_item
    os.mkdir(newPath)
FileNotFoundError: [Errno 2] No such file or directory: '/Users/a824810056/Desktop/py2.7-GovSpider/GovSpider2/foregin/banshi/wjrs/crj'
2019-03-26 15:12:25 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.gov.cn/banshi/2012-11/19/content_2269879.htm> (referer: http://www.gov.cn/banshi/wjrs/crj.htm)
Traceback (most recent call last):
  File "/usr/local/lib/python3.7/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python3.7/site-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/Users/a824810056/Desktop/py2.7-GovSpider/GovSpider2/GovSpider2/spiders/govSpider.py", line 78, in parse_item
    os.mkdir(newPath)
FileNotFoundError: [Errno 2] No such file or directory: '/Users/a824810056/Desktop/py2.7-GovSpider/GovSpider2/foregin/banshi/wjrs/crj'
2019-03-26 15:12:25 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.gov.cn/banshi/2012-11/19/content_2269878.htm> (referer: http://www.gov.cn/banshi/wjrs/crj.htm)
Traceback (most recent call last):
  File "/usr/local/lib/python3.7/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python3.7/site-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/Users/a824810056/Desktop/py2.7-GovSpider/GovSpider2/GovSpider2/spiders/govSpider.py", line 78, in parse_item
    os.mkdir(newPath)
FileNotFoundError: [Errno 2] No such file or directory: '/Users/a824810056/Desktop/py2.7-GovSpider/GovSpider2/foregin/banshi/wjrs/crj'
2019-03-26 15:12:25 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.gov.cn/banshi/2006-10/09/content_408010.htm> (referer: http://www.gov.cn/banshi/wjrs/crj.htm)
Traceback (most recent call last):
  File "/usr/local/lib/python3.7/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python3.7/site-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/Users/a824810056/Desktop/py2.7-GovSpider/GovSpider2/GovSpider2/spiders/govSpider.py", line 78, in parse_item
    os.mkdir(newPath)
FileNotFoundError: [Errno 2] No such file or directory: '/Users/a824810056/Desktop/py2.7-GovSpider/GovSpider2/foregin/banshi/wjrs/crj'
2019-03-26 15:12:25 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.gov.cn/banshi/2007-05/10/content_610216.htm> (referer: http://www.gov.cn/banshi/wjrs/crj.htm)
Traceback (most recent call last):
  File "/usr/local/lib/python3.7/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python3.7/site-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/Users/a824810056/Desktop/py2.7-GovSpider/GovSpider2/GovSpider2/spiders/govSpider.py", line 78, in parse_item
    os.mkdir(newPath)
FileNotFoundError: [Errno 2] No such file or directory: '/Users/a824810056/Desktop/py2.7-GovSpider/GovSpider2/foregin/banshi/wjrs/crj'
2019-03-26 15:12:25 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.gov.cn/banshi/2012-11/19/content_2269880.htm> (referer: http://www.gov.cn/banshi/wjrs/crj.htm)
Traceback (most recent call last):
  File "/usr/local/lib/python3.7/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python3.7/site-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/Users/a824810056/Desktop/py2.7-GovSpider/GovSpider2/GovSpider2/spiders/govSpider.py", line 78, in parse_item
    os.mkdir(newPath)
FileNotFoundError: [Errno 2] No such file or directory: '/Users/a824810056/Desktop/py2.7-GovSpider/GovSpider2/foregin/banshi/wjrs/crj'
2019-03-26 15:12:26 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.gov.cn/banshi/2006-10/09/content_408005.htm> (referer: http://www.gov.cn/banshi/wjrs/crj.htm)
Traceback (most recent call last):
  File "/usr/local/lib/python3.7/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python3.7/site-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/Users/a824810056/Desktop/py2.7-GovSpider/GovSpider2/GovSpider2/spiders/govSpider.py", line 78, in parse_item
    os.mkdir(newPath)
FileNotFoundError: [Errno 2] No such file or directory: '/Users/a824810056/Desktop/py2.7-GovSpider/GovSpider2/foregin/banshi/wjrs/crj'
2019-03-26 15:12:26 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.gov.cn/banshi/2012-11/19/content_2269876.htm> (referer: http://www.gov.cn/banshi/wjrs/crj.htm)
Traceback (most recent call last):
  File "/usr/local/lib/python3.7/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python3.7/site-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/Users/a824810056/Desktop/py2.7-GovSpider/GovSpider2/GovSpider2/spiders/govSpider.py", line 78, in parse_item
    os.mkdir(newPath)
FileNotFoundError: [Errno 2] No such file or directory: '/Users/a824810056/Desktop/py2.7-GovSpider/GovSpider2/foregin/banshi/wjrs/crj'
2019-03-26 15:12:26 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.gov.cn/banshi/2005-06/23/content_75551.htm> (referer: http://www.gov.cn/banshi/zjpq.htm)
Traceback (most recent call last):
  File "/usr/local/lib/python3.7/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python3.7/site-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/Users/a824810056/Desktop/py2.7-GovSpider/GovSpider2/GovSpider2/spiders/govSpider.py", line 78, in parse_item
    os.mkdir(newPath)
FileNotFoundError: [Errno 2] No such file or directory: '/Users/a824810056/Desktop/py2.7-GovSpider/GovSpider2/foregin/banshi/zjpq'
2019-03-26 15:12:26 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.gov.cn/banshi/2005-10/10/content_75553.htm> (referer: http://www.gov.cn/banshi/zjpq.htm)
Traceback (most recent call last):
  File "/usr/local/lib/python3.7/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python3.7/site-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/Users/a824810056/Desktop/py2.7-GovSpider/GovSpider2/GovSpider2/spiders/govSpider.py", line 78, in parse_item
    os.mkdir(newPath)
FileNotFoundError: [Errno 2] No such file or directory: '/Users/a824810056/Desktop/py2.7-GovSpider/GovSpider2/foregin/banshi/zjpq'
2019-03-26 15:12:26 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.gov.cn/banshi/2005-10/10/content_75500.htm> (referer: http://www.gov.cn/banshi/zjpq.htm)
Traceback (most recent call last):
  File "/usr/local/lib/python3.7/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python3.7/site-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/Users/a824810056/Desktop/py2.7-GovSpider/GovSpider2/GovSpider2/spiders/govSpider.py", line 78, in parse_item
    os.mkdir(newPath)
FileNotFoundError: [Errno 2] No such file or directory: '/Users/a824810056/Desktop/py2.7-GovSpider/GovSpider2/foregin/banshi/zjpq'
2019-03-26 15:12:26 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.gov.cn/banshi/2006-03/02/content_215803.htm> (referer: http://www.gov.cn/banshi/zjpq.htm)
Traceback (most recent call last):
  File "/usr/local/lib/python3.7/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python3.7/site-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/Users/a824810056/Desktop/py2.7-GovSpider/GovSpider2/GovSpider2/spiders/govSpider.py", line 78, in parse_item
    os.mkdir(newPath)
FileNotFoundError: [Errno 2] No such file or directory: '/Users/a824810056/Desktop/py2.7-GovSpider/GovSpider2/foregin/banshi/zjpq'
2019-03-26 15:12:26 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.gov.cn/banshi/2005-10/10/content_75453.htm> (referer: http://www.gov.cn/banshi/zjpq.htm)
Traceback (most recent call last):
  File "/usr/local/lib/python3.7/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python3.7/site-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/Users/a824810056/Desktop/py2.7-GovSpider/GovSpider2/GovSpider2/spiders/govSpider.py", line 78, in parse_item
    os.mkdir(newPath)
FileNotFoundError: [Errno 2] No such file or directory: '/Users/a824810056/Desktop/py2.7-GovSpider/GovSpider2/foregin/banshi/zjpq'
2019-03-26 15:12:26 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.gov.cn/banshi/2005-10/10/content_75460.htm> (referer: http://www.gov.cn/banshi/zjpq.htm)
Traceback (most recent call last):
  File "/usr/local/lib/python3.7/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python3.7/site-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/Users/a824810056/Desktop/py2.7-GovSpider/GovSpider2/GovSpider2/spiders/govSpider.py", line 78, in parse_item
    os.mkdir(newPath)
FileNotFoundError: [Errno 2] No such file or directory: '/Users/a824810056/Desktop/py2.7-GovSpider/GovSpider2/foregin/banshi/zjpq'
2019-03-26 15:12:26 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.gov.cn/banshi/2005-06/23/content_8734.htm> (referer: http://www.gov.cn/banshi/zjpq.htm)
Traceback (most recent call last):
  File "/usr/local/lib/python3.7/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python3.7/site-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/Users/a824810056/Desktop/py2.7-GovSpider/GovSpider2/GovSpider2/spiders/govSpider.py", line 78, in parse_item
    os.mkdir(newPath)
FileNotFoundError: [Errno 2] No such file or directory: '/Users/a824810056/Desktop/py2.7-GovSpider/GovSpider2/foregin/banshi/zjpq'
2019-03-26 15:12:26 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.gov.cn/banshi/2005-10/10/content_75518.htm> (referer: http://www.gov.cn/banshi/zjpq.htm)
Traceback (most recent call last):
  File "/usr/local/lib/python3.7/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python3.7/site-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/Users/a824810056/Desktop/py2.7-GovSpider/GovSpider2/GovSpider2/spiders/govSpider.py", line 78, in parse_item
    os.mkdir(newPath)
FileNotFoundError: [Errno 2] No such file or directory: '/Users/a824810056/Desktop/py2.7-GovSpider/GovSpider2/foregin/banshi/zjpq'
2019-03-26 15:12:26 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.gov.cn/banshi/2005-10/10/content_75526.htm> (referer: http://www.gov.cn/banshi/zjpq.htm)
Traceback (most recent call last):
  File "/usr/local/lib/python3.7/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python3.7/site-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/Users/a824810056/Desktop/py2.7-GovSpider/GovSpider2/GovSpider2/spiders/govSpider.py", line 78, in parse_item
    os.mkdir(newPath)
FileNotFoundError: [Errno 2] No such file or directory: '/Users/a824810056/Desktop/py2.7-GovSpider/GovSpider2/foregin/banshi/zjpq'
2019-03-26 15:12:26 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.gov.cn/banshi/2005-10/10/content_75529.htm> (referer: http://www.gov.cn/banshi/zjpq.htm)
Traceback (most recent call last):
  File "/usr/local/lib/python3.7/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python3.7/site-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/Users/a824810056/Desktop/py2.7-GovSpider/GovSpider2/GovSpider2/spiders/govSpider.py", line 78, in parse_item
    os.mkdir(newPath)
FileNotFoundError: [Errno 2] No such file or directory: '/Users/a824810056/Desktop/py2.7-GovSpider/GovSpider2/foregin/banshi/zjpq'
2019-03-26 15:12:26 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.gov.cn/banshi/2005-06/08/content_4836.htm> (referer: http://www.gov.cn/banshi/wjrs/crj.htm)
Traceback (most recent call last):
  File "/usr/local/lib/python3.7/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python3.7/site-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/Users/a824810056/Desktop/py2.7-GovSpider/GovSpider2/GovSpider2/spiders/govSpider.py", line 78, in parse_item
    os.mkdir(newPath)
FileNotFoundError: [Errno 2] No such file or directory: '/Users/a824810056/Desktop/py2.7-GovSpider/GovSpider2/foregin/banshi/wjrs/crj'
2019-03-26 15:12:26 [scrapy.core.engine] INFO: Closing spider (finished)
2019-03-26 15:12:26 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 11301,
 'downloader/request_count': 31,
 'downloader/request_method_count/GET': 31,
 'downloader/response_bytes': 515826,
 'downloader/response_count': 31,
 'downloader/response_status_count/200': 31,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2019, 3, 26, 7, 12, 26, 179768),
 'log_count/ERROR': 28,
 'log_count/INFO': 9,
 'memusage/max': 50155520,
 'memusage/startup': 50155520,
 'offsite/domains': 1,
 'offsite/filtered': 1,
 'request_depth_max': 1,
 'response_received_count': 31,
 'robotstxt/request_count': 1,
 'robotstxt/response_count': 1,
 'robotstxt/response_status_count/200': 1,
 'scheduler/dequeued': 30,
 'scheduler/dequeued/memory': 30,
 'scheduler/enqueued': 30,
 'scheduler/enqueued/memory': 30,
 'spider_exceptions/FileNotFoundError': 28,
 'start_time': datetime.datetime(2019, 3, 26, 7, 12, 25, 192640)}
2019-03-26 15:12:26 [scrapy.core.engine] INFO: Spider closed (finished)
2019-03-26 15:12:49 [scrapy.utils.log] INFO: Scrapy 1.6.0 started (bot: GovSpider2)
2019-03-26 15:12:49 [scrapy.utils.log] INFO: Versions: lxml 4.3.2.0, libxml2 2.9.9, cssselect 1.0.3, parsel 1.5.1, w3lib 1.20.0, Twisted 18.9.0, Python 3.7.2 (default, Feb 13 2019, 10:07:58) - [Clang 10.0.0 (clang-1000.11.45.5)], pyOpenSSL 19.0.0 (OpenSSL 1.1.1b  26 Feb 2019), cryptography 2.6.1, Platform Darwin-18.2.0-x86_64-i386-64bit
2019-03-26 15:12:49 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'GovSpider2', 'LOG_FILE': 'log/spiderlog20190326.txt', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'GovSpider2.spiders', 'ROBOTSTXT_OBEY': True, 'SPIDER_MODULES': ['GovSpider2.spiders']}
2019-03-26 15:12:49 [scrapy.extensions.telnet] INFO: Telnet Password: acef6b548196ca95
2019-03-26 15:12:49 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats']
2019-03-26 15:12:49 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.robotstxt.RobotsTxtMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2019-03-26 15:12:49 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2019-03-26 15:12:49 [scrapy.middleware] INFO: Enabled item pipelines:
['GovSpider2.pipelines.Govspider2Pipeline']
2019-03-26 15:12:49 [scrapy.core.engine] INFO: Spider opened
2019-03-26 15:12:49 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-03-26 15:12:49 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023
2019-03-26 15:12:49 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.gov.cn/banshi/2006-10/09/content_408016.htm> (referer: http://www.gov.cn/banshi/wjrs/crj.htm)
Traceback (most recent call last):
  File "/usr/local/lib/python3.7/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python3.7/site-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/Users/a824810056/Desktop/py2.7-GovSpider/GovSpider2/GovSpider2/spiders/govSpider.py", line 80, in parse_item
    os.mkdir(newPath)
FileNotFoundError: [Errno 2] No such file or directory: '/Users/a824810056/Desktop/py2.7-GovSpider/GovSpider2/foregin/banshi/wjrs/crj'
2019-03-26 15:12:50 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.gov.cn/banshi/2006-10/09/content_408010.htm> (referer: http://www.gov.cn/banshi/wjrs/crj.htm)
Traceback (most recent call last):
  File "/usr/local/lib/python3.7/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python3.7/site-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/Users/a824810056/Desktop/py2.7-GovSpider/GovSpider2/GovSpider2/spiders/govSpider.py", line 80, in parse_item
    os.mkdir(newPath)
FileNotFoundError: [Errno 2] No such file or directory: '/Users/a824810056/Desktop/py2.7-GovSpider/GovSpider2/foregin/banshi/wjrs/crj'
2019-03-26 15:12:50 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.gov.cn/banshi/2005-06/08/content_4836.htm> (referer: http://www.gov.cn/banshi/wjrs/crj.htm)
Traceback (most recent call last):
  File "/usr/local/lib/python3.7/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python3.7/site-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/Users/a824810056/Desktop/py2.7-GovSpider/GovSpider2/GovSpider2/spiders/govSpider.py", line 80, in parse_item
    os.mkdir(newPath)
FileNotFoundError: [Errno 2] No such file or directory: '/Users/a824810056/Desktop/py2.7-GovSpider/GovSpider2/foregin/banshi/wjrs/crj'
2019-03-26 15:12:50 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.gov.cn/banshi/2005-07/06/content_12279.htm> (referer: http://www.gov.cn/banshi/wjrs/crj.htm)
Traceback (most recent call last):
  File "/usr/local/lib/python3.7/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python3.7/site-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/Users/a824810056/Desktop/py2.7-GovSpider/GovSpider2/GovSpider2/spiders/govSpider.py", line 80, in parse_item
    os.mkdir(newPath)
FileNotFoundError: [Errno 2] No such file or directory: '/Users/a824810056/Desktop/py2.7-GovSpider/GovSpider2/foregin/banshi/wjrs/crj'
2019-03-26 15:12:50 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.gov.cn/banshi/2006-10/09/content_408005.htm> (referer: http://www.gov.cn/banshi/wjrs/crj.htm)
Traceback (most recent call last):
  File "/usr/local/lib/python3.7/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python3.7/site-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/Users/a824810056/Desktop/py2.7-GovSpider/GovSpider2/GovSpider2/spiders/govSpider.py", line 80, in parse_item
    os.mkdir(newPath)
FileNotFoundError: [Errno 2] No such file or directory: '/Users/a824810056/Desktop/py2.7-GovSpider/GovSpider2/foregin/banshi/wjrs/crj'
2019-03-26 15:12:50 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.gov.cn/banshi/2006-10/09/content_408018.htm> (referer: http://www.gov.cn/banshi/wjrs/crj.htm)
Traceback (most recent call last):
  File "/usr/local/lib/python3.7/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python3.7/site-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/Users/a824810056/Desktop/py2.7-GovSpider/GovSpider2/GovSpider2/spiders/govSpider.py", line 80, in parse_item
    os.mkdir(newPath)
FileNotFoundError: [Errno 2] No such file or directory: '/Users/a824810056/Desktop/py2.7-GovSpider/GovSpider2/foregin/banshi/wjrs/crj'
2019-03-26 15:12:50 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.gov.cn/banshi/2005-07/08/content_13036.htm> (referer: http://www.gov.cn/banshi/wjrs/crj.htm)
Traceback (most recent call last):
  File "/usr/local/lib/python3.7/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python3.7/site-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/Users/a824810056/Desktop/py2.7-GovSpider/GovSpider2/GovSpider2/spiders/govSpider.py", line 80, in parse_item
    os.mkdir(newPath)
FileNotFoundError: [Errno 2] No such file or directory: '/Users/a824810056/Desktop/py2.7-GovSpider/GovSpider2/foregin/banshi/wjrs/crj'
2019-03-26 15:12:50 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.gov.cn/banshi/2005-06/08/content_4837.htm> (referer: http://www.gov.cn/banshi/wjrs/crj.htm)
Traceback (most recent call last):
  File "/usr/local/lib/python3.7/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python3.7/site-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/Users/a824810056/Desktop/py2.7-GovSpider/GovSpider2/GovSpider2/spiders/govSpider.py", line 80, in parse_item
    os.mkdir(newPath)
FileNotFoundError: [Errno 2] No such file or directory: '/Users/a824810056/Desktop/py2.7-GovSpider/GovSpider2/foregin/banshi/wjrs/crj'
2019-03-26 15:12:50 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.gov.cn/banshi/2005-05/26/content_1300.htm> (referer: http://www.gov.cn/banshi/wjrs/crj.htm)
Traceback (most recent call last):
  File "/usr/local/lib/python3.7/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python3.7/site-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/Users/a824810056/Desktop/py2.7-GovSpider/GovSpider2/GovSpider2/spiders/govSpider.py", line 80, in parse_item
    os.mkdir(newPath)
FileNotFoundError: [Errno 2] No such file or directory: '/Users/a824810056/Desktop/py2.7-GovSpider/GovSpider2/foregin/banshi/wjrs/crj'
2019-03-26 15:12:50 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.gov.cn/banshi/2012-11/19/content_2269877.htm> (referer: http://www.gov.cn/banshi/wjrs/crj.htm)
Traceback (most recent call last):
  File "/usr/local/lib/python3.7/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python3.7/site-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/Users/a824810056/Desktop/py2.7-GovSpider/GovSpider2/GovSpider2/spiders/govSpider.py", line 80, in parse_item
    os.mkdir(newPath)
FileNotFoundError: [Errno 2] No such file or directory: '/Users/a824810056/Desktop/py2.7-GovSpider/GovSpider2/foregin/banshi/wjrs/crj'
2019-03-26 15:12:50 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.gov.cn/banshi/2005-10/10/content_75518.htm> (referer: http://www.gov.cn/banshi/zjpq.htm)
Traceback (most recent call last):
  File "/usr/local/lib/python3.7/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python3.7/site-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/Users/a824810056/Desktop/py2.7-GovSpider/GovSpider2/GovSpider2/spiders/govSpider.py", line 80, in parse_item
    os.mkdir(newPath)
FileNotFoundError: [Errno 2] No such file or directory: '/Users/a824810056/Desktop/py2.7-GovSpider/GovSpider2/foregin/banshi/zjpq'
2019-03-26 15:12:50 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.gov.cn/banshi/2005-09/12/content_31017.htm> (referer: http://www.gov.cn/banshi/wjrs/crj.htm)
Traceback (most recent call last):
  File "/usr/local/lib/python3.7/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python3.7/site-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/Users/a824810056/Desktop/py2.7-GovSpider/GovSpider2/GovSpider2/spiders/govSpider.py", line 80, in parse_item
    os.mkdir(newPath)
FileNotFoundError: [Errno 2] No such file or directory: '/Users/a824810056/Desktop/py2.7-GovSpider/GovSpider2/foregin/banshi/wjrs/crj'
2019-03-26 15:12:50 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.gov.cn/banshi/2005-10/10/content_75526.htm> (referer: http://www.gov.cn/banshi/zjpq.htm)
Traceback (most recent call last):
  File "/usr/local/lib/python3.7/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python3.7/site-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/Users/a824810056/Desktop/py2.7-GovSpider/GovSpider2/GovSpider2/spiders/govSpider.py", line 80, in parse_item
    os.mkdir(newPath)
FileNotFoundError: [Errno 2] No such file or directory: '/Users/a824810056/Desktop/py2.7-GovSpider/GovSpider2/foregin/banshi/zjpq'
2019-03-26 15:12:50 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.gov.cn/banshi/2005-10/10/content_75529.htm> (referer: http://www.gov.cn/banshi/zjpq.htm)
Traceback (most recent call last):
  File "/usr/local/lib/python3.7/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python3.7/site-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/Users/a824810056/Desktop/py2.7-GovSpider/GovSpider2/GovSpider2/spiders/govSpider.py", line 80, in parse_item
    os.mkdir(newPath)
FileNotFoundError: [Errno 2] No such file or directory: '/Users/a824810056/Desktop/py2.7-GovSpider/GovSpider2/foregin/banshi/zjpq'
2019-03-26 15:12:50 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.gov.cn/banshi/2006-10/09/content_408014.htm> (referer: http://www.gov.cn/banshi/wjrs/crj.htm)
Traceback (most recent call last):
  File "/usr/local/lib/python3.7/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python3.7/site-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/Users/a824810056/Desktop/py2.7-GovSpider/GovSpider2/GovSpider2/spiders/govSpider.py", line 80, in parse_item
    os.mkdir(newPath)
FileNotFoundError: [Errno 2] No such file or directory: '/Users/a824810056/Desktop/py2.7-GovSpider/GovSpider2/foregin/banshi/wjrs/crj'
2019-03-26 15:12:50 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.gov.cn/banshi/2005-10/10/content_75453.htm> (referer: http://www.gov.cn/banshi/zjpq.htm)
Traceback (most recent call last):
  File "/usr/local/lib/python3.7/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python3.7/site-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/Users/a824810056/Desktop/py2.7-GovSpider/GovSpider2/GovSpider2/spiders/govSpider.py", line 80, in parse_item
    os.mkdir(newPath)
FileNotFoundError: [Errno 2] No such file or directory: '/Users/a824810056/Desktop/py2.7-GovSpider/GovSpider2/foregin/banshi/zjpq'
2019-03-26 15:12:50 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.gov.cn/banshi/2005-10/10/content_75460.htm> (referer: http://www.gov.cn/banshi/zjpq.htm)
Traceback (most recent call last):
  File "/usr/local/lib/python3.7/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python3.7/site-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/Users/a824810056/Desktop/py2.7-GovSpider/GovSpider2/GovSpider2/spiders/govSpider.py", line 80, in parse_item
    os.mkdir(newPath)
FileNotFoundError: [Errno 2] No such file or directory: '/Users/a824810056/Desktop/py2.7-GovSpider/GovSpider2/foregin/banshi/zjpq'
2019-03-26 15:12:50 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.gov.cn/banshi/2005-10/10/content_75500.htm> (referer: http://www.gov.cn/banshi/zjpq.htm)
Traceback (most recent call last):
  File "/usr/local/lib/python3.7/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python3.7/site-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/Users/a824810056/Desktop/py2.7-GovSpider/GovSpider2/GovSpider2/spiders/govSpider.py", line 80, in parse_item
    os.mkdir(newPath)
FileNotFoundError: [Errno 2] No such file or directory: '/Users/a824810056/Desktop/py2.7-GovSpider/GovSpider2/foregin/banshi/zjpq'
2019-03-26 15:12:50 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.gov.cn/banshi/2005-10/10/content_75553.htm> (referer: http://www.gov.cn/banshi/zjpq.htm)
Traceback (most recent call last):
  File "/usr/local/lib/python3.7/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python3.7/site-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/Users/a824810056/Desktop/py2.7-GovSpider/GovSpider2/GovSpider2/spiders/govSpider.py", line 80, in parse_item
    os.mkdir(newPath)
FileNotFoundError: [Errno 2] No such file or directory: '/Users/a824810056/Desktop/py2.7-GovSpider/GovSpider2/foregin/banshi/zjpq'
2019-03-26 15:12:50 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.gov.cn/banshi/2006-08/23/content_368260.htm> (referer: http://www.gov.cn/banshi/wjrs/crj.htm)
Traceback (most recent call last):
  File "/usr/local/lib/python3.7/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python3.7/site-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/Users/a824810056/Desktop/py2.7-GovSpider/GovSpider2/GovSpider2/spiders/govSpider.py", line 80, in parse_item
    os.mkdir(newPath)
FileNotFoundError: [Errno 2] No such file or directory: '/Users/a824810056/Desktop/py2.7-GovSpider/GovSpider2/foregin/banshi/wjrs/crj'
2019-03-26 15:12:50 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.gov.cn/banshi/2012-11/19/content_2269880.htm> (referer: http://www.gov.cn/banshi/wjrs/crj.htm)
Traceback (most recent call last):
  File "/usr/local/lib/python3.7/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python3.7/site-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/Users/a824810056/Desktop/py2.7-GovSpider/GovSpider2/GovSpider2/spiders/govSpider.py", line 80, in parse_item
    os.mkdir(newPath)
FileNotFoundError: [Errno 2] No such file or directory: '/Users/a824810056/Desktop/py2.7-GovSpider/GovSpider2/foregin/banshi/wjrs/crj'
2019-03-26 15:12:50 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.gov.cn/banshi/2007-05/10/content_610216.htm> (referer: http://www.gov.cn/banshi/wjrs/crj.htm)
Traceback (most recent call last):
  File "/usr/local/lib/python3.7/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python3.7/site-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/Users/a824810056/Desktop/py2.7-GovSpider/GovSpider2/GovSpider2/spiders/govSpider.py", line 80, in parse_item
    os.mkdir(newPath)
FileNotFoundError: [Errno 2] No such file or directory: '/Users/a824810056/Desktop/py2.7-GovSpider/GovSpider2/foregin/banshi/wjrs/crj'
2019-03-26 15:12:50 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.gov.cn/banshi/2012-11/19/content_2269876.htm> (referer: http://www.gov.cn/banshi/wjrs/crj.htm)
Traceback (most recent call last):
  File "/usr/local/lib/python3.7/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python3.7/site-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/Users/a824810056/Desktop/py2.7-GovSpider/GovSpider2/GovSpider2/spiders/govSpider.py", line 80, in parse_item
    os.mkdir(newPath)
FileNotFoundError: [Errno 2] No such file or directory: '/Users/a824810056/Desktop/py2.7-GovSpider/GovSpider2/foregin/banshi/wjrs/crj'
2019-03-26 15:12:50 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.gov.cn/banshi/2006-03/02/content_215803.htm> (referer: http://www.gov.cn/banshi/zjpq.htm)
Traceback (most recent call last):
  File "/usr/local/lib/python3.7/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python3.7/site-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/Users/a824810056/Desktop/py2.7-GovSpider/GovSpider2/GovSpider2/spiders/govSpider.py", line 80, in parse_item
    os.mkdir(newPath)
FileNotFoundError: [Errno 2] No such file or directory: '/Users/a824810056/Desktop/py2.7-GovSpider/GovSpider2/foregin/banshi/zjpq'
2019-03-26 15:12:50 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.gov.cn/banshi/2012-11/19/content_2269878.htm> (referer: http://www.gov.cn/banshi/wjrs/crj.htm)
Traceback (most recent call last):
  File "/usr/local/lib/python3.7/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python3.7/site-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/Users/a824810056/Desktop/py2.7-GovSpider/GovSpider2/GovSpider2/spiders/govSpider.py", line 80, in parse_item
    os.mkdir(newPath)
FileNotFoundError: [Errno 2] No such file or directory: '/Users/a824810056/Desktop/py2.7-GovSpider/GovSpider2/foregin/banshi/wjrs/crj'
2019-03-26 15:12:50 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.gov.cn/banshi/2012-11/19/content_2269879.htm> (referer: http://www.gov.cn/banshi/wjrs/crj.htm)
Traceback (most recent call last):
  File "/usr/local/lib/python3.7/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python3.7/site-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/Users/a824810056/Desktop/py2.7-GovSpider/GovSpider2/GovSpider2/spiders/govSpider.py", line 80, in parse_item
    os.mkdir(newPath)
FileNotFoundError: [Errno 2] No such file or directory: '/Users/a824810056/Desktop/py2.7-GovSpider/GovSpider2/foregin/banshi/wjrs/crj'
2019-03-26 15:12:50 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.gov.cn/banshi/2005-06/23/content_8734.htm> (referer: http://www.gov.cn/banshi/zjpq.htm)
Traceback (most recent call last):
  File "/usr/local/lib/python3.7/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python3.7/site-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/Users/a824810056/Desktop/py2.7-GovSpider/GovSpider2/GovSpider2/spiders/govSpider.py", line 80, in parse_item
    os.mkdir(newPath)
FileNotFoundError: [Errno 2] No such file or directory: '/Users/a824810056/Desktop/py2.7-GovSpider/GovSpider2/foregin/banshi/zjpq'
2019-03-26 15:12:50 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.gov.cn/banshi/2005-06/23/content_75551.htm> (referer: http://www.gov.cn/banshi/zjpq.htm)
Traceback (most recent call last):
  File "/usr/local/lib/python3.7/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python3.7/site-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/Users/a824810056/Desktop/py2.7-GovSpider/GovSpider2/GovSpider2/spiders/govSpider.py", line 80, in parse_item
    os.mkdir(newPath)
FileNotFoundError: [Errno 2] No such file or directory: '/Users/a824810056/Desktop/py2.7-GovSpider/GovSpider2/foregin/banshi/zjpq'
2019-03-26 15:12:50 [scrapy.core.engine] INFO: Closing spider (finished)
2019-03-26 15:12:50 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 11301,
 'downloader/request_count': 31,
 'downloader/request_method_count/GET': 31,
 'downloader/response_bytes': 515824,
 'downloader/response_count': 31,
 'downloader/response_status_count/200': 31,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2019, 3, 26, 7, 12, 50, 441306),
 'log_count/ERROR': 28,
 'log_count/INFO': 9,
 'memusage/max': 50077696,
 'memusage/startup': 50077696,
 'offsite/domains': 1,
 'offsite/filtered': 1,
 'request_depth_max': 1,
 'response_received_count': 31,
 'robotstxt/request_count': 1,
 'robotstxt/response_count': 1,
 'robotstxt/response_status_count/200': 1,
 'scheduler/dequeued': 30,
 'scheduler/dequeued/memory': 30,
 'scheduler/enqueued': 30,
 'scheduler/enqueued/memory': 30,
 'spider_exceptions/FileNotFoundError': 28,
 'start_time': datetime.datetime(2019, 3, 26, 7, 12, 49, 554641)}
2019-03-26 15:12:50 [scrapy.core.engine] INFO: Spider closed (finished)
2019-03-26 15:15:47 [scrapy.utils.log] INFO: Scrapy 1.6.0 started (bot: GovSpider2)
2019-03-26 15:15:47 [scrapy.utils.log] INFO: Versions: lxml 4.3.2.0, libxml2 2.9.9, cssselect 1.0.3, parsel 1.5.1, w3lib 1.20.0, Twisted 18.9.0, Python 3.7.2 (default, Feb 13 2019, 10:07:58) - [Clang 10.0.0 (clang-1000.11.45.5)], pyOpenSSL 19.0.0 (OpenSSL 1.1.1b  26 Feb 2019), cryptography 2.6.1, Platform Darwin-18.2.0-x86_64-i386-64bit
2019-03-26 15:15:47 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'GovSpider2', 'LOG_FILE': 'log/spiderlog20190326.txt', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'GovSpider2.spiders', 'ROBOTSTXT_OBEY': True, 'SPIDER_MODULES': ['GovSpider2.spiders']}
2019-03-26 15:15:47 [scrapy.extensions.telnet] INFO: Telnet Password: 45180b206c70546f
2019-03-26 15:15:47 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats']
2019-03-26 15:15:47 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.robotstxt.RobotsTxtMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2019-03-26 15:15:47 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2019-03-26 15:15:47 [scrapy.middleware] INFO: Enabled item pipelines:
['GovSpider2.pipelines.Govspider2Pipeline']
2019-03-26 15:15:47 [scrapy.core.engine] INFO: Spider opened
2019-03-26 15:15:47 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-03-26 15:15:47 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023
2019-03-26 15:15:48 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.gov.cn/banshi/2006-03/02/content_215803.htm> (referer: http://www.gov.cn/banshi/zjpq.htm)
Traceback (most recent call last):
  File "/usr/local/lib/python3.7/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python3.7/site-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/Users/a824810056/Desktop/py2.7-GovSpider/GovSpider2/GovSpider2/spiders/govSpider.py", line 80, in parse_item
    os.mkdir(newPath)
FileNotFoundError: [Errno 2] No such file or directory: '/Users/a824810056/Desktop/py2.7-GovSpider/GovSpider2/foregin/banshi/zjpq'
2019-03-26 15:15:48 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.gov.cn/banshi/2005-06/23/content_75551.htm> (referer: http://www.gov.cn/banshi/zjpq.htm)
Traceback (most recent call last):
  File "/usr/local/lib/python3.7/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python3.7/site-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/Users/a824810056/Desktop/py2.7-GovSpider/GovSpider2/GovSpider2/spiders/govSpider.py", line 80, in parse_item
    os.mkdir(newPath)
FileNotFoundError: [Errno 2] No such file or directory: '/Users/a824810056/Desktop/py2.7-GovSpider/GovSpider2/foregin/banshi/zjpq'
2019-03-26 15:15:48 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.gov.cn/banshi/2005-10/10/content_75526.htm> (referer: http://www.gov.cn/banshi/zjpq.htm)
Traceback (most recent call last):
  File "/usr/local/lib/python3.7/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python3.7/site-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/Users/a824810056/Desktop/py2.7-GovSpider/GovSpider2/GovSpider2/spiders/govSpider.py", line 80, in parse_item
    os.mkdir(newPath)
FileNotFoundError: [Errno 2] No such file or directory: '/Users/a824810056/Desktop/py2.7-GovSpider/GovSpider2/foregin/banshi/zjpq'
2019-03-26 15:15:48 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.gov.cn/banshi/2005-10/10/content_75453.htm> (referer: http://www.gov.cn/banshi/zjpq.htm)
Traceback (most recent call last):
  File "/usr/local/lib/python3.7/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python3.7/site-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/Users/a824810056/Desktop/py2.7-GovSpider/GovSpider2/GovSpider2/spiders/govSpider.py", line 80, in parse_item
    os.mkdir(newPath)
FileNotFoundError: [Errno 2] No such file or directory: '/Users/a824810056/Desktop/py2.7-GovSpider/GovSpider2/foregin/banshi/zjpq'
2019-03-26 15:15:48 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.gov.cn/banshi/2005-10/10/content_75553.htm> (referer: http://www.gov.cn/banshi/zjpq.htm)
Traceback (most recent call last):
  File "/usr/local/lib/python3.7/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python3.7/site-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/Users/a824810056/Desktop/py2.7-GovSpider/GovSpider2/GovSpider2/spiders/govSpider.py", line 80, in parse_item
    os.mkdir(newPath)
FileNotFoundError: [Errno 2] No such file or directory: '/Users/a824810056/Desktop/py2.7-GovSpider/GovSpider2/foregin/banshi/zjpq'
2019-03-26 15:15:48 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.gov.cn/banshi/2005-10/10/content_75460.htm> (referer: http://www.gov.cn/banshi/zjpq.htm)
Traceback (most recent call last):
  File "/usr/local/lib/python3.7/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python3.7/site-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/Users/a824810056/Desktop/py2.7-GovSpider/GovSpider2/GovSpider2/spiders/govSpider.py", line 80, in parse_item
    os.mkdir(newPath)
FileNotFoundError: [Errno 2] No such file or directory: '/Users/a824810056/Desktop/py2.7-GovSpider/GovSpider2/foregin/banshi/zjpq'
2019-03-26 15:15:48 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.gov.cn/banshi/2005-06/23/content_8734.htm> (referer: http://www.gov.cn/banshi/zjpq.htm)
Traceback (most recent call last):
  File "/usr/local/lib/python3.7/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python3.7/site-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/Users/a824810056/Desktop/py2.7-GovSpider/GovSpider2/GovSpider2/spiders/govSpider.py", line 80, in parse_item
    os.mkdir(newPath)
FileNotFoundError: [Errno 2] No such file or directory: '/Users/a824810056/Desktop/py2.7-GovSpider/GovSpider2/foregin/banshi/zjpq'
2019-03-26 15:15:48 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.gov.cn/banshi/2005-10/10/content_75529.htm> (referer: http://www.gov.cn/banshi/zjpq.htm)
Traceback (most recent call last):
  File "/usr/local/lib/python3.7/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python3.7/site-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/Users/a824810056/Desktop/py2.7-GovSpider/GovSpider2/GovSpider2/spiders/govSpider.py", line 80, in parse_item
    os.mkdir(newPath)
FileNotFoundError: [Errno 2] No such file or directory: '/Users/a824810056/Desktop/py2.7-GovSpider/GovSpider2/foregin/banshi/zjpq'
2019-03-26 15:15:48 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.gov.cn/banshi/2005-10/10/content_75500.htm> (referer: http://www.gov.cn/banshi/zjpq.htm)
Traceback (most recent call last):
  File "/usr/local/lib/python3.7/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python3.7/site-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/Users/a824810056/Desktop/py2.7-GovSpider/GovSpider2/GovSpider2/spiders/govSpider.py", line 80, in parse_item
    os.mkdir(newPath)
FileNotFoundError: [Errno 2] No such file or directory: '/Users/a824810056/Desktop/py2.7-GovSpider/GovSpider2/foregin/banshi/zjpq'
2019-03-26 15:15:48 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.gov.cn/banshi/2005-10/10/content_75518.htm> (referer: http://www.gov.cn/banshi/zjpq.htm)
Traceback (most recent call last):
  File "/usr/local/lib/python3.7/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python3.7/site-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/Users/a824810056/Desktop/py2.7-GovSpider/GovSpider2/GovSpider2/spiders/govSpider.py", line 80, in parse_item
    os.mkdir(newPath)
FileNotFoundError: [Errno 2] No such file or directory: '/Users/a824810056/Desktop/py2.7-GovSpider/GovSpider2/foregin/banshi/zjpq'
2019-03-26 15:15:48 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.gov.cn/banshi/2005-07/06/content_12279.htm> (referer: http://www.gov.cn/banshi/wjrs/crj.htm)
Traceback (most recent call last):
  File "/usr/local/lib/python3.7/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python3.7/site-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/Users/a824810056/Desktop/py2.7-GovSpider/GovSpider2/GovSpider2/spiders/govSpider.py", line 80, in parse_item
    os.mkdir(newPath)
FileNotFoundError: [Errno 2] No such file or directory: '/Users/a824810056/Desktop/py2.7-GovSpider/GovSpider2/foregin/banshi/wjrs/crj'
2019-03-26 15:15:48 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.gov.cn/banshi/2005-07/08/content_13036.htm> (referer: http://www.gov.cn/banshi/wjrs/crj.htm)
Traceback (most recent call last):
  File "/usr/local/lib/python3.7/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python3.7/site-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/Users/a824810056/Desktop/py2.7-GovSpider/GovSpider2/GovSpider2/spiders/govSpider.py", line 80, in parse_item
    os.mkdir(newPath)
FileNotFoundError: [Errno 2] No such file or directory: '/Users/a824810056/Desktop/py2.7-GovSpider/GovSpider2/foregin/banshi/wjrs/crj'
2019-03-26 15:15:48 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.gov.cn/banshi/2005-06/08/content_4837.htm> (referer: http://www.gov.cn/banshi/wjrs/crj.htm)
Traceback (most recent call last):
  File "/usr/local/lib/python3.7/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python3.7/site-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/Users/a824810056/Desktop/py2.7-GovSpider/GovSpider2/GovSpider2/spiders/govSpider.py", line 80, in parse_item
    os.mkdir(newPath)
FileNotFoundError: [Errno 2] No such file or directory: '/Users/a824810056/Desktop/py2.7-GovSpider/GovSpider2/foregin/banshi/wjrs/crj'
2019-03-26 15:15:48 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.gov.cn/banshi/2005-06/08/content_4836.htm> (referer: http://www.gov.cn/banshi/wjrs/crj.htm)
Traceback (most recent call last):
  File "/usr/local/lib/python3.7/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python3.7/site-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/Users/a824810056/Desktop/py2.7-GovSpider/GovSpider2/GovSpider2/spiders/govSpider.py", line 80, in parse_item
    os.mkdir(newPath)
FileNotFoundError: [Errno 2] No such file or directory: '/Users/a824810056/Desktop/py2.7-GovSpider/GovSpider2/foregin/banshi/wjrs/crj'
2019-03-26 15:15:48 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.gov.cn/banshi/2005-05/26/content_1300.htm> (referer: http://www.gov.cn/banshi/wjrs/crj.htm)
Traceback (most recent call last):
  File "/usr/local/lib/python3.7/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python3.7/site-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/Users/a824810056/Desktop/py2.7-GovSpider/GovSpider2/GovSpider2/spiders/govSpider.py", line 80, in parse_item
    os.mkdir(newPath)
FileNotFoundError: [Errno 2] No such file or directory: '/Users/a824810056/Desktop/py2.7-GovSpider/GovSpider2/foregin/banshi/wjrs/crj'
2019-03-26 15:15:48 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.gov.cn/banshi/2006-10/09/content_408016.htm> (referer: http://www.gov.cn/banshi/wjrs/crj.htm)
Traceback (most recent call last):
  File "/usr/local/lib/python3.7/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python3.7/site-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/Users/a824810056/Desktop/py2.7-GovSpider/GovSpider2/GovSpider2/spiders/govSpider.py", line 80, in parse_item
    os.mkdir(newPath)
FileNotFoundError: [Errno 2] No such file or directory: '/Users/a824810056/Desktop/py2.7-GovSpider/GovSpider2/foregin/banshi/wjrs/crj'
2019-03-26 15:15:48 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.gov.cn/banshi/2006-08/23/content_368260.htm> (referer: http://www.gov.cn/banshi/wjrs/crj.htm)
Traceback (most recent call last):
  File "/usr/local/lib/python3.7/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python3.7/site-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/Users/a824810056/Desktop/py2.7-GovSpider/GovSpider2/GovSpider2/spiders/govSpider.py", line 80, in parse_item
    os.mkdir(newPath)
FileNotFoundError: [Errno 2] No such file or directory: '/Users/a824810056/Desktop/py2.7-GovSpider/GovSpider2/foregin/banshi/wjrs/crj'
2019-03-26 15:15:48 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.gov.cn/banshi/2006-10/09/content_408005.htm> (referer: http://www.gov.cn/banshi/wjrs/crj.htm)
Traceback (most recent call last):
  File "/usr/local/lib/python3.7/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python3.7/site-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/Users/a824810056/Desktop/py2.7-GovSpider/GovSpider2/GovSpider2/spiders/govSpider.py", line 80, in parse_item
    os.mkdir(newPath)
FileNotFoundError: [Errno 2] No such file or directory: '/Users/a824810056/Desktop/py2.7-GovSpider/GovSpider2/foregin/banshi/wjrs/crj'
2019-03-26 15:15:48 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.gov.cn/banshi/2006-10/09/content_408014.htm> (referer: http://www.gov.cn/banshi/wjrs/crj.htm)
Traceback (most recent call last):
  File "/usr/local/lib/python3.7/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python3.7/site-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/Users/a824810056/Desktop/py2.7-GovSpider/GovSpider2/GovSpider2/spiders/govSpider.py", line 80, in parse_item
    os.mkdir(newPath)
FileNotFoundError: [Errno 2] No such file or directory: '/Users/a824810056/Desktop/py2.7-GovSpider/GovSpider2/foregin/banshi/wjrs/crj'
2019-03-26 15:15:48 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.gov.cn/banshi/2005-09/12/content_31017.htm> (referer: http://www.gov.cn/banshi/wjrs/crj.htm)
Traceback (most recent call last):
  File "/usr/local/lib/python3.7/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python3.7/site-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/Users/a824810056/Desktop/py2.7-GovSpider/GovSpider2/GovSpider2/spiders/govSpider.py", line 80, in parse_item
    os.mkdir(newPath)
FileNotFoundError: [Errno 2] No such file or directory: '/Users/a824810056/Desktop/py2.7-GovSpider/GovSpider2/foregin/banshi/wjrs/crj'
2019-03-26 15:15:48 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.gov.cn/banshi/2006-10/09/content_408018.htm> (referer: http://www.gov.cn/banshi/wjrs/crj.htm)
Traceback (most recent call last):
  File "/usr/local/lib/python3.7/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python3.7/site-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/Users/a824810056/Desktop/py2.7-GovSpider/GovSpider2/GovSpider2/spiders/govSpider.py", line 80, in parse_item
    os.mkdir(newPath)
FileNotFoundError: [Errno 2] No such file or directory: '/Users/a824810056/Desktop/py2.7-GovSpider/GovSpider2/foregin/banshi/wjrs/crj'
2019-03-26 15:15:48 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.gov.cn/banshi/2012-11/19/content_2269877.htm> (referer: http://www.gov.cn/banshi/wjrs/crj.htm)
Traceback (most recent call last):
  File "/usr/local/lib/python3.7/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python3.7/site-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/Users/a824810056/Desktop/py2.7-GovSpider/GovSpider2/GovSpider2/spiders/govSpider.py", line 80, in parse_item
    os.mkdir(newPath)
FileNotFoundError: [Errno 2] No such file or directory: '/Users/a824810056/Desktop/py2.7-GovSpider/GovSpider2/foregin/banshi/wjrs/crj'
2019-03-26 15:15:48 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.gov.cn/banshi/2006-10/09/content_408010.htm> (referer: http://www.gov.cn/banshi/wjrs/crj.htm)
Traceback (most recent call last):
  File "/usr/local/lib/python3.7/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python3.7/site-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/Users/a824810056/Desktop/py2.7-GovSpider/GovSpider2/GovSpider2/spiders/govSpider.py", line 80, in parse_item
    os.mkdir(newPath)
FileNotFoundError: [Errno 2] No such file or directory: '/Users/a824810056/Desktop/py2.7-GovSpider/GovSpider2/foregin/banshi/wjrs/crj'
2019-03-26 15:15:48 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.gov.cn/banshi/2012-11/19/content_2269878.htm> (referer: http://www.gov.cn/banshi/wjrs/crj.htm)
Traceback (most recent call last):
  File "/usr/local/lib/python3.7/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python3.7/site-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/Users/a824810056/Desktop/py2.7-GovSpider/GovSpider2/GovSpider2/spiders/govSpider.py", line 80, in parse_item
    os.mkdir(newPath)
FileNotFoundError: [Errno 2] No such file or directory: '/Users/a824810056/Desktop/py2.7-GovSpider/GovSpider2/foregin/banshi/wjrs/crj'
2019-03-26 15:15:48 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.gov.cn/banshi/2012-11/19/content_2269880.htm> (referer: http://www.gov.cn/banshi/wjrs/crj.htm)
Traceback (most recent call last):
  File "/usr/local/lib/python3.7/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python3.7/site-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/Users/a824810056/Desktop/py2.7-GovSpider/GovSpider2/GovSpider2/spiders/govSpider.py", line 80, in parse_item
    os.mkdir(newPath)
FileNotFoundError: [Errno 2] No such file or directory: '/Users/a824810056/Desktop/py2.7-GovSpider/GovSpider2/foregin/banshi/wjrs/crj'
2019-03-26 15:15:48 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.gov.cn/banshi/2007-05/10/content_610216.htm> (referer: http://www.gov.cn/banshi/wjrs/crj.htm)
Traceback (most recent call last):
  File "/usr/local/lib/python3.7/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python3.7/site-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/Users/a824810056/Desktop/py2.7-GovSpider/GovSpider2/GovSpider2/spiders/govSpider.py", line 80, in parse_item
    os.mkdir(newPath)
FileNotFoundError: [Errno 2] No such file or directory: '/Users/a824810056/Desktop/py2.7-GovSpider/GovSpider2/foregin/banshi/wjrs/crj'
2019-03-26 15:15:48 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.gov.cn/banshi/2012-11/19/content_2269876.htm> (referer: http://www.gov.cn/banshi/wjrs/crj.htm)
Traceback (most recent call last):
  File "/usr/local/lib/python3.7/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python3.7/site-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/Users/a824810056/Desktop/py2.7-GovSpider/GovSpider2/GovSpider2/spiders/govSpider.py", line 80, in parse_item
    os.mkdir(newPath)
FileNotFoundError: [Errno 2] No such file or directory: '/Users/a824810056/Desktop/py2.7-GovSpider/GovSpider2/foregin/banshi/wjrs/crj'
2019-03-26 15:15:48 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.gov.cn/banshi/2012-11/19/content_2269879.htm> (referer: http://www.gov.cn/banshi/wjrs/crj.htm)
Traceback (most recent call last):
  File "/usr/local/lib/python3.7/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python3.7/site-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/Users/a824810056/Desktop/py2.7-GovSpider/GovSpider2/GovSpider2/spiders/govSpider.py", line 80, in parse_item
    os.mkdir(newPath)
FileNotFoundError: [Errno 2] No such file or directory: '/Users/a824810056/Desktop/py2.7-GovSpider/GovSpider2/foregin/banshi/wjrs/crj'
2019-03-26 15:15:48 [scrapy.core.engine] INFO: Closing spider (finished)
2019-03-26 15:15:48 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 11301,
 'downloader/request_count': 31,
 'downloader/request_method_count/GET': 31,
 'downloader/response_bytes': 515826,
 'downloader/response_count': 31,
 'downloader/response_status_count/200': 31,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2019, 3, 26, 7, 15, 48, 559857),
 'log_count/ERROR': 28,
 'log_count/INFO': 9,
 'memusage/max': 49876992,
 'memusage/startup': 49876992,
 'offsite/domains': 1,
 'offsite/filtered': 1,
 'request_depth_max': 1,
 'response_received_count': 31,
 'robotstxt/request_count': 1,
 'robotstxt/response_count': 1,
 'robotstxt/response_status_count/200': 1,
 'scheduler/dequeued': 30,
 'scheduler/dequeued/memory': 30,
 'scheduler/enqueued': 30,
 'scheduler/enqueued/memory': 30,
 'spider_exceptions/FileNotFoundError': 28,
 'start_time': datetime.datetime(2019, 3, 26, 7, 15, 47, 465523)}
2019-03-26 15:15:48 [scrapy.core.engine] INFO: Spider closed (finished)
2019-03-26 15:17:28 [scrapy.utils.log] INFO: Scrapy 1.6.0 started (bot: GovSpider2)
2019-03-26 15:17:28 [scrapy.utils.log] INFO: Versions: lxml 4.3.2.0, libxml2 2.9.9, cssselect 1.0.3, parsel 1.5.1, w3lib 1.20.0, Twisted 18.9.0, Python 3.7.2 (default, Feb 13 2019, 10:07:58) - [Clang 10.0.0 (clang-1000.11.45.5)], pyOpenSSL 19.0.0 (OpenSSL 1.1.1b  26 Feb 2019), cryptography 2.6.1, Platform Darwin-18.2.0-x86_64-i386-64bit
2019-03-26 15:17:28 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'GovSpider2', 'LOG_FILE': 'log/spiderlog20190326.txt', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'GovSpider2.spiders', 'ROBOTSTXT_OBEY': True, 'SPIDER_MODULES': ['GovSpider2.spiders']}
2019-03-26 15:17:28 [scrapy.extensions.telnet] INFO: Telnet Password: 2baa67d6b26a7987
2019-03-26 15:17:28 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats']
2019-03-26 15:17:28 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.robotstxt.RobotsTxtMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2019-03-26 15:17:28 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2019-03-26 15:17:28 [scrapy.middleware] INFO: Enabled item pipelines:
['GovSpider2.pipelines.Govspider2Pipeline']
2019-03-26 15:17:28 [scrapy.core.engine] INFO: Spider opened
2019-03-26 15:17:28 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-03-26 15:17:28 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023
2019-03-26 15:17:28 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.gov.cn/banshi/2005-07/08/content_13036.htm> (referer: http://www.gov.cn/banshi/wjrs/crj.htm)
Traceback (most recent call last):
  File "/usr/local/lib/python3.7/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python3.7/site-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/Users/a824810056/Desktop/py2.7-GovSpider/GovSpider2/GovSpider2/spiders/govSpider.py", line 82, in parse_item
    os.mkdir(newPath)
FileNotFoundError: [Errno 2] No such file or directory: '/Users/a824810056/Desktop/py2.7-GovSpider/GovSpider2/foregin/banshi/wjrs/crj'
2019-03-26 15:17:28 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.gov.cn/banshi/2006-10/09/content_408016.htm> (referer: http://www.gov.cn/banshi/wjrs/crj.htm)
Traceback (most recent call last):
  File "/usr/local/lib/python3.7/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python3.7/site-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/Users/a824810056/Desktop/py2.7-GovSpider/GovSpider2/GovSpider2/spiders/govSpider.py", line 82, in parse_item
    os.mkdir(newPath)
FileNotFoundError: [Errno 2] No such file or directory: '/Users/a824810056/Desktop/py2.7-GovSpider/GovSpider2/foregin/banshi/wjrs/crj'
2019-03-26 15:17:28 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.gov.cn/banshi/2005-06/08/content_4836.htm> (referer: http://www.gov.cn/banshi/wjrs/crj.htm)
Traceback (most recent call last):
  File "/usr/local/lib/python3.7/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python3.7/site-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/Users/a824810056/Desktop/py2.7-GovSpider/GovSpider2/GovSpider2/spiders/govSpider.py", line 82, in parse_item
    os.mkdir(newPath)
FileNotFoundError: [Errno 2] No such file or directory: '/Users/a824810056/Desktop/py2.7-GovSpider/GovSpider2/foregin/banshi/wjrs/crj'
2019-03-26 15:17:28 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.gov.cn/banshi/2005-06/08/content_4837.htm> (referer: http://www.gov.cn/banshi/wjrs/crj.htm)
Traceback (most recent call last):
  File "/usr/local/lib/python3.7/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python3.7/site-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/Users/a824810056/Desktop/py2.7-GovSpider/GovSpider2/GovSpider2/spiders/govSpider.py", line 82, in parse_item
    os.mkdir(newPath)
FileNotFoundError: [Errno 2] No such file or directory: '/Users/a824810056/Desktop/py2.7-GovSpider/GovSpider2/foregin/banshi/wjrs/crj'
2019-03-26 15:17:28 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.gov.cn/banshi/2005-07/06/content_12279.htm> (referer: http://www.gov.cn/banshi/wjrs/crj.htm)
Traceback (most recent call last):
  File "/usr/local/lib/python3.7/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python3.7/site-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/Users/a824810056/Desktop/py2.7-GovSpider/GovSpider2/GovSpider2/spiders/govSpider.py", line 82, in parse_item
    os.mkdir(newPath)
FileNotFoundError: [Errno 2] No such file or directory: '/Users/a824810056/Desktop/py2.7-GovSpider/GovSpider2/foregin/banshi/wjrs/crj'
2019-03-26 15:17:28 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.gov.cn/banshi/2006-10/09/content_408018.htm> (referer: http://www.gov.cn/banshi/wjrs/crj.htm)
Traceback (most recent call last):
  File "/usr/local/lib/python3.7/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python3.7/site-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/Users/a824810056/Desktop/py2.7-GovSpider/GovSpider2/GovSpider2/spiders/govSpider.py", line 82, in parse_item
    os.mkdir(newPath)
FileNotFoundError: [Errno 2] No such file or directory: '/Users/a824810056/Desktop/py2.7-GovSpider/GovSpider2/foregin/banshi/wjrs/crj'
2019-03-26 15:17:28 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.gov.cn/banshi/2006-10/09/content_408005.htm> (referer: http://www.gov.cn/banshi/wjrs/crj.htm)
Traceback (most recent call last):
  File "/usr/local/lib/python3.7/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python3.7/site-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/Users/a824810056/Desktop/py2.7-GovSpider/GovSpider2/GovSpider2/spiders/govSpider.py", line 82, in parse_item
    os.mkdir(newPath)
FileNotFoundError: [Errno 2] No such file or directory: '/Users/a824810056/Desktop/py2.7-GovSpider/GovSpider2/foregin/banshi/wjrs/crj'
2019-03-26 15:17:28 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.gov.cn/banshi/2006-08/23/content_368260.htm> (referer: http://www.gov.cn/banshi/wjrs/crj.htm)
Traceback (most recent call last):
  File "/usr/local/lib/python3.7/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python3.7/site-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/Users/a824810056/Desktop/py2.7-GovSpider/GovSpider2/GovSpider2/spiders/govSpider.py", line 82, in parse_item
    os.mkdir(newPath)
FileNotFoundError: [Errno 2] No such file or directory: '/Users/a824810056/Desktop/py2.7-GovSpider/GovSpider2/foregin/banshi/wjrs/crj'
2019-03-26 15:17:28 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.gov.cn/banshi/2007-05/10/content_610216.htm> (referer: http://www.gov.cn/banshi/wjrs/crj.htm)
Traceback (most recent call last):
  File "/usr/local/lib/python3.7/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python3.7/site-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/Users/a824810056/Desktop/py2.7-GovSpider/GovSpider2/GovSpider2/spiders/govSpider.py", line 82, in parse_item
    os.mkdir(newPath)
FileNotFoundError: [Errno 2] No such file or directory: '/Users/a824810056/Desktop/py2.7-GovSpider/GovSpider2/foregin/banshi/wjrs/crj'
2019-03-26 15:17:28 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.gov.cn/banshi/2012-11/19/content_2269877.htm> (referer: http://www.gov.cn/banshi/wjrs/crj.htm)
Traceback (most recent call last):
  File "/usr/local/lib/python3.7/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python3.7/site-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/Users/a824810056/Desktop/py2.7-GovSpider/GovSpider2/GovSpider2/spiders/govSpider.py", line 82, in parse_item
    os.mkdir(newPath)
FileNotFoundError: [Errno 2] No such file or directory: '/Users/a824810056/Desktop/py2.7-GovSpider/GovSpider2/foregin/banshi/wjrs/crj'
2019-03-26 15:17:28 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.gov.cn/banshi/2012-11/19/content_2269876.htm> (referer: http://www.gov.cn/banshi/wjrs/crj.htm)
Traceback (most recent call last):
  File "/usr/local/lib/python3.7/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python3.7/site-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/Users/a824810056/Desktop/py2.7-GovSpider/GovSpider2/GovSpider2/spiders/govSpider.py", line 82, in parse_item
    os.mkdir(newPath)
FileNotFoundError: [Errno 2] No such file or directory: '/Users/a824810056/Desktop/py2.7-GovSpider/GovSpider2/foregin/banshi/wjrs/crj'
2019-03-26 15:17:28 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.gov.cn/banshi/2012-11/19/content_2269878.htm> (referer: http://www.gov.cn/banshi/wjrs/crj.htm)
Traceback (most recent call last):
  File "/usr/local/lib/python3.7/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python3.7/site-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/Users/a824810056/Desktop/py2.7-GovSpider/GovSpider2/GovSpider2/spiders/govSpider.py", line 82, in parse_item
    os.mkdir(newPath)
FileNotFoundError: [Errno 2] No such file or directory: '/Users/a824810056/Desktop/py2.7-GovSpider/GovSpider2/foregin/banshi/wjrs/crj'
2019-03-26 15:17:28 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.gov.cn/banshi/2012-11/19/content_2269880.htm> (referer: http://www.gov.cn/banshi/wjrs/crj.htm)
Traceback (most recent call last):
  File "/usr/local/lib/python3.7/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python3.7/site-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/Users/a824810056/Desktop/py2.7-GovSpider/GovSpider2/GovSpider2/spiders/govSpider.py", line 82, in parse_item
    os.mkdir(newPath)
FileNotFoundError: [Errno 2] No such file or directory: '/Users/a824810056/Desktop/py2.7-GovSpider/GovSpider2/foregin/banshi/wjrs/crj'
2019-03-26 15:17:29 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.gov.cn/banshi/2006-10/09/content_408010.htm> (referer: http://www.gov.cn/banshi/wjrs/crj.htm)
Traceback (most recent call last):
  File "/usr/local/lib/python3.7/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python3.7/site-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/Users/a824810056/Desktop/py2.7-GovSpider/GovSpider2/GovSpider2/spiders/govSpider.py", line 82, in parse_item
    os.mkdir(newPath)
FileNotFoundError: [Errno 2] No such file or directory: '/Users/a824810056/Desktop/py2.7-GovSpider/GovSpider2/foregin/banshi/wjrs/crj'
2019-03-26 15:17:29 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.gov.cn/banshi/2012-11/19/content_2269879.htm> (referer: http://www.gov.cn/banshi/wjrs/crj.htm)
Traceback (most recent call last):
  File "/usr/local/lib/python3.7/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python3.7/site-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/Users/a824810056/Desktop/py2.7-GovSpider/GovSpider2/GovSpider2/spiders/govSpider.py", line 82, in parse_item
    os.mkdir(newPath)
FileNotFoundError: [Errno 2] No such file or directory: '/Users/a824810056/Desktop/py2.7-GovSpider/GovSpider2/foregin/banshi/wjrs/crj'
2019-03-26 15:17:29 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.gov.cn/banshi/2005-09/12/content_31017.htm> (referer: http://www.gov.cn/banshi/wjrs/crj.htm)
Traceback (most recent call last):
  File "/usr/local/lib/python3.7/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python3.7/site-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/Users/a824810056/Desktop/py2.7-GovSpider/GovSpider2/GovSpider2/spiders/govSpider.py", line 82, in parse_item
    os.mkdir(newPath)
FileNotFoundError: [Errno 2] No such file or directory: '/Users/a824810056/Desktop/py2.7-GovSpider/GovSpider2/foregin/banshi/wjrs/crj'
2019-03-26 15:17:29 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.gov.cn/banshi/2006-10/09/content_408014.htm> (referer: http://www.gov.cn/banshi/wjrs/crj.htm)
Traceback (most recent call last):
  File "/usr/local/lib/python3.7/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python3.7/site-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/Users/a824810056/Desktop/py2.7-GovSpider/GovSpider2/GovSpider2/spiders/govSpider.py", line 82, in parse_item
    os.mkdir(newPath)
FileNotFoundError: [Errno 2] No such file or directory: '/Users/a824810056/Desktop/py2.7-GovSpider/GovSpider2/foregin/banshi/wjrs/crj'
2019-03-26 15:17:29 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.gov.cn/banshi/2005-05/26/content_1300.htm> (referer: http://www.gov.cn/banshi/wjrs/crj.htm)
Traceback (most recent call last):
  File "/usr/local/lib/python3.7/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python3.7/site-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/Users/a824810056/Desktop/py2.7-GovSpider/GovSpider2/GovSpider2/spiders/govSpider.py", line 82, in parse_item
    os.mkdir(newPath)
FileNotFoundError: [Errno 2] No such file or directory: '/Users/a824810056/Desktop/py2.7-GovSpider/GovSpider2/foregin/banshi/wjrs/crj'
2019-03-26 15:17:30 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.gov.cn/banshi/2005-10/10/content_75526.htm> (referer: http://www.gov.cn/banshi/zjpq.htm)
Traceback (most recent call last):
  File "/usr/local/lib/python3.7/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python3.7/site-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/Users/a824810056/Desktop/py2.7-GovSpider/GovSpider2/GovSpider2/spiders/govSpider.py", line 82, in parse_item
    os.mkdir(newPath)
FileNotFoundError: [Errno 2] No such file or directory: '/Users/a824810056/Desktop/py2.7-GovSpider/GovSpider2/foregin/banshi/zjpq'
2019-03-26 15:17:30 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.gov.cn/banshi/2005-10/10/content_75453.htm> (referer: http://www.gov.cn/banshi/zjpq.htm)
Traceback (most recent call last):
  File "/usr/local/lib/python3.7/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python3.7/site-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/Users/a824810056/Desktop/py2.7-GovSpider/GovSpider2/GovSpider2/spiders/govSpider.py", line 82, in parse_item
    os.mkdir(newPath)
FileNotFoundError: [Errno 2] No such file or directory: '/Users/a824810056/Desktop/py2.7-GovSpider/GovSpider2/foregin/banshi/zjpq'
2019-03-26 15:17:30 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.gov.cn/banshi/2005-10/10/content_75500.htm> (referer: http://www.gov.cn/banshi/zjpq.htm)
Traceback (most recent call last):
  File "/usr/local/lib/python3.7/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python3.7/site-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/Users/a824810056/Desktop/py2.7-GovSpider/GovSpider2/GovSpider2/spiders/govSpider.py", line 82, in parse_item
    os.mkdir(newPath)
FileNotFoundError: [Errno 2] No such file or directory: '/Users/a824810056/Desktop/py2.7-GovSpider/GovSpider2/foregin/banshi/zjpq'
2019-03-26 15:17:30 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.gov.cn/banshi/2005-06/23/content_75551.htm> (referer: http://www.gov.cn/banshi/zjpq.htm)
Traceback (most recent call last):
  File "/usr/local/lib/python3.7/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python3.7/site-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/Users/a824810056/Desktop/py2.7-GovSpider/GovSpider2/GovSpider2/spiders/govSpider.py", line 82, in parse_item
    os.mkdir(newPath)
FileNotFoundError: [Errno 2] No such file or directory: '/Users/a824810056/Desktop/py2.7-GovSpider/GovSpider2/foregin/banshi/zjpq'
2019-03-26 15:17:30 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.gov.cn/banshi/2005-10/10/content_75529.htm> (referer: http://www.gov.cn/banshi/zjpq.htm)
Traceback (most recent call last):
  File "/usr/local/lib/python3.7/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python3.7/site-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/Users/a824810056/Desktop/py2.7-GovSpider/GovSpider2/GovSpider2/spiders/govSpider.py", line 82, in parse_item
    os.mkdir(newPath)
FileNotFoundError: [Errno 2] No such file or directory: '/Users/a824810056/Desktop/py2.7-GovSpider/GovSpider2/foregin/banshi/zjpq'
2019-03-26 15:17:30 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.gov.cn/banshi/2005-10/10/content_75553.htm> (referer: http://www.gov.cn/banshi/zjpq.htm)
Traceback (most recent call last):
  File "/usr/local/lib/python3.7/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python3.7/site-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/Users/a824810056/Desktop/py2.7-GovSpider/GovSpider2/GovSpider2/spiders/govSpider.py", line 82, in parse_item
    os.mkdir(newPath)
FileNotFoundError: [Errno 2] No such file or directory: '/Users/a824810056/Desktop/py2.7-GovSpider/GovSpider2/foregin/banshi/zjpq'
2019-03-26 15:17:30 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.gov.cn/banshi/2005-10/10/content_75460.htm> (referer: http://www.gov.cn/banshi/zjpq.htm)
Traceback (most recent call last):
  File "/usr/local/lib/python3.7/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python3.7/site-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/Users/a824810056/Desktop/py2.7-GovSpider/GovSpider2/GovSpider2/spiders/govSpider.py", line 82, in parse_item
    os.mkdir(newPath)
FileNotFoundError: [Errno 2] No such file or directory: '/Users/a824810056/Desktop/py2.7-GovSpider/GovSpider2/foregin/banshi/zjpq'
2019-03-26 15:17:30 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.gov.cn/banshi/2005-06/23/content_8734.htm> (referer: http://www.gov.cn/banshi/zjpq.htm)
Traceback (most recent call last):
  File "/usr/local/lib/python3.7/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python3.7/site-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/Users/a824810056/Desktop/py2.7-GovSpider/GovSpider2/GovSpider2/spiders/govSpider.py", line 82, in parse_item
    os.mkdir(newPath)
FileNotFoundError: [Errno 2] No such file or directory: '/Users/a824810056/Desktop/py2.7-GovSpider/GovSpider2/foregin/banshi/zjpq'
2019-03-26 15:17:30 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.gov.cn/banshi/2006-03/02/content_215803.htm> (referer: http://www.gov.cn/banshi/zjpq.htm)
Traceback (most recent call last):
  File "/usr/local/lib/python3.7/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python3.7/site-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/Users/a824810056/Desktop/py2.7-GovSpider/GovSpider2/GovSpider2/spiders/govSpider.py", line 82, in parse_item
    os.mkdir(newPath)
FileNotFoundError: [Errno 2] No such file or directory: '/Users/a824810056/Desktop/py2.7-GovSpider/GovSpider2/foregin/banshi/zjpq'
2019-03-26 15:17:30 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.gov.cn/banshi/2005-10/10/content_75518.htm> (referer: http://www.gov.cn/banshi/zjpq.htm)
Traceback (most recent call last):
  File "/usr/local/lib/python3.7/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python3.7/site-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/Users/a824810056/Desktop/py2.7-GovSpider/GovSpider2/GovSpider2/spiders/govSpider.py", line 82, in parse_item
    os.mkdir(newPath)
FileNotFoundError: [Errno 2] No such file or directory: '/Users/a824810056/Desktop/py2.7-GovSpider/GovSpider2/foregin/banshi/zjpq'
2019-03-26 15:17:30 [scrapy.core.engine] INFO: Closing spider (finished)
2019-03-26 15:17:30 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 11301,
 'downloader/request_count': 31,
 'downloader/request_method_count/GET': 31,
 'downloader/response_bytes': 515846,
 'downloader/response_count': 31,
 'downloader/response_status_count/200': 31,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2019, 3, 26, 7, 17, 30, 851874),
 'log_count/ERROR': 28,
 'log_count/INFO': 9,
 'memusage/max': 50114560,
 'memusage/startup': 50114560,
 'offsite/domains': 1,
 'offsite/filtered': 1,
 'request_depth_max': 1,
 'response_received_count': 31,
 'robotstxt/request_count': 1,
 'robotstxt/response_count': 1,
 'robotstxt/response_status_count/200': 1,
 'scheduler/dequeued': 30,
 'scheduler/dequeued/memory': 30,
 'scheduler/enqueued': 30,
 'scheduler/enqueued/memory': 30,
 'spider_exceptions/FileNotFoundError': 28,
 'start_time': datetime.datetime(2019, 3, 26, 7, 17, 28, 306132)}
2019-03-26 15:17:30 [scrapy.core.engine] INFO: Spider closed (finished)
2019-03-26 15:19:06 [scrapy.utils.log] INFO: Scrapy 1.6.0 started (bot: GovSpider2)
2019-03-26 15:19:06 [scrapy.utils.log] INFO: Versions: lxml 4.3.2.0, libxml2 2.9.9, cssselect 1.0.3, parsel 1.5.1, w3lib 1.20.0, Twisted 18.9.0, Python 3.7.2 (default, Feb 13 2019, 10:07:58) - [Clang 10.0.0 (clang-1000.11.45.5)], pyOpenSSL 19.0.0 (OpenSSL 1.1.1b  26 Feb 2019), cryptography 2.6.1, Platform Darwin-18.2.0-x86_64-i386-64bit
2019-03-26 15:19:06 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'GovSpider2', 'LOG_FILE': 'log/spiderlog20190326.txt', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'GovSpider2.spiders', 'ROBOTSTXT_OBEY': True, 'SPIDER_MODULES': ['GovSpider2.spiders']}
2019-03-26 15:19:06 [scrapy.extensions.telnet] INFO: Telnet Password: 3ad04002ba0ac798
2019-03-26 15:19:06 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats']
2019-03-26 15:19:06 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.robotstxt.RobotsTxtMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2019-03-26 15:19:06 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2019-03-26 15:19:06 [scrapy.middleware] INFO: Enabled item pipelines:
['GovSpider2.pipelines.Govspider2Pipeline']
2019-03-26 15:19:06 [scrapy.core.engine] INFO: Spider opened
2019-03-26 15:19:06 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-03-26 15:19:06 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023
2019-03-26 15:19:06 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.gov.cn/banshi/2005-07/06/content_12279.htm> (referer: http://www.gov.cn/banshi/wjrs/crj.htm)
Traceback (most recent call last):
  File "/usr/local/lib/python3.7/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python3.7/site-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/Users/a824810056/Desktop/py2.7-GovSpider/GovSpider2/GovSpider2/spiders/govSpider.py", line 84, in parse_item
    os.mkdir(newPath)
FileNotFoundError: [Errno 2] No such file or directory: '/Users/a824810056/Desktop/py2.7-GovSpider/GovSpider2/foregin/banshi/wjrs/crj'
2019-03-26 15:19:06 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.gov.cn/banshi/2005-05/26/content_1300.htm> (referer: http://www.gov.cn/banshi/wjrs/crj.htm)
Traceback (most recent call last):
  File "/usr/local/lib/python3.7/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python3.7/site-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/Users/a824810056/Desktop/py2.7-GovSpider/GovSpider2/GovSpider2/spiders/govSpider.py", line 84, in parse_item
    os.mkdir(newPath)
FileNotFoundError: [Errno 2] No such file or directory: '/Users/a824810056/Desktop/py2.7-GovSpider/GovSpider2/foregin/banshi/wjrs/crj'
2019-03-26 15:19:06 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.gov.cn/banshi/2006-10/09/content_408010.htm> (referer: http://www.gov.cn/banshi/wjrs/crj.htm)
Traceback (most recent call last):
  File "/usr/local/lib/python3.7/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python3.7/site-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/Users/a824810056/Desktop/py2.7-GovSpider/GovSpider2/GovSpider2/spiders/govSpider.py", line 84, in parse_item
    os.mkdir(newPath)
FileNotFoundError: [Errno 2] No such file or directory: '/Users/a824810056/Desktop/py2.7-GovSpider/GovSpider2/foregin/banshi/wjrs/crj'
2019-03-26 15:19:06 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.gov.cn/banshi/2005-07/08/content_13036.htm> (referer: http://www.gov.cn/banshi/wjrs/crj.htm)
Traceback (most recent call last):
  File "/usr/local/lib/python3.7/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python3.7/site-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/Users/a824810056/Desktop/py2.7-GovSpider/GovSpider2/GovSpider2/spiders/govSpider.py", line 84, in parse_item
    os.mkdir(newPath)
FileNotFoundError: [Errno 2] No such file or directory: '/Users/a824810056/Desktop/py2.7-GovSpider/GovSpider2/foregin/banshi/wjrs/crj'
2019-03-26 15:19:06 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.gov.cn/banshi/2006-10/09/content_408014.htm> (referer: http://www.gov.cn/banshi/wjrs/crj.htm)
Traceback (most recent call last):
  File "/usr/local/lib/python3.7/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python3.7/site-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/Users/a824810056/Desktop/py2.7-GovSpider/GovSpider2/GovSpider2/spiders/govSpider.py", line 84, in parse_item
    os.mkdir(newPath)
FileNotFoundError: [Errno 2] No such file or directory: '/Users/a824810056/Desktop/py2.7-GovSpider/GovSpider2/foregin/banshi/wjrs/crj'
2019-03-26 15:19:06 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.gov.cn/banshi/2005-09/12/content_31017.htm> (referer: http://www.gov.cn/banshi/wjrs/crj.htm)
Traceback (most recent call last):
  File "/usr/local/lib/python3.7/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python3.7/site-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/Users/a824810056/Desktop/py2.7-GovSpider/GovSpider2/GovSpider2/spiders/govSpider.py", line 84, in parse_item
    os.mkdir(newPath)
FileNotFoundError: [Errno 2] No such file or directory: '/Users/a824810056/Desktop/py2.7-GovSpider/GovSpider2/foregin/banshi/wjrs/crj'
2019-03-26 15:19:06 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.gov.cn/banshi/2005-06/08/content_4836.htm> (referer: http://www.gov.cn/banshi/wjrs/crj.htm)
Traceback (most recent call last):
  File "/usr/local/lib/python3.7/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python3.7/site-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/Users/a824810056/Desktop/py2.7-GovSpider/GovSpider2/GovSpider2/spiders/govSpider.py", line 84, in parse_item
    os.mkdir(newPath)
FileNotFoundError: [Errno 2] No such file or directory: '/Users/a824810056/Desktop/py2.7-GovSpider/GovSpider2/foregin/banshi/wjrs/crj'
2019-03-26 15:19:06 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.gov.cn/banshi/2006-08/23/content_368260.htm> (referer: http://www.gov.cn/banshi/wjrs/crj.htm)
Traceback (most recent call last):
  File "/usr/local/lib/python3.7/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python3.7/site-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/Users/a824810056/Desktop/py2.7-GovSpider/GovSpider2/GovSpider2/spiders/govSpider.py", line 84, in parse_item
    os.mkdir(newPath)
FileNotFoundError: [Errno 2] No such file or directory: '/Users/a824810056/Desktop/py2.7-GovSpider/GovSpider2/foregin/banshi/wjrs/crj'
2019-03-26 15:19:06 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.gov.cn/banshi/2007-05/10/content_610216.htm> (referer: http://www.gov.cn/banshi/wjrs/crj.htm)
Traceback (most recent call last):
  File "/usr/local/lib/python3.7/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python3.7/site-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/Users/a824810056/Desktop/py2.7-GovSpider/GovSpider2/GovSpider2/spiders/govSpider.py", line 84, in parse_item
    os.mkdir(newPath)
FileNotFoundError: [Errno 2] No such file or directory: '/Users/a824810056/Desktop/py2.7-GovSpider/GovSpider2/foregin/banshi/wjrs/crj'
2019-03-26 15:19:06 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.gov.cn/banshi/2012-11/19/content_2269877.htm> (referer: http://www.gov.cn/banshi/wjrs/crj.htm)
Traceback (most recent call last):
  File "/usr/local/lib/python3.7/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python3.7/site-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/Users/a824810056/Desktop/py2.7-GovSpider/GovSpider2/GovSpider2/spiders/govSpider.py", line 84, in parse_item
    os.mkdir(newPath)
FileNotFoundError: [Errno 2] No such file or directory: '/Users/a824810056/Desktop/py2.7-GovSpider/GovSpider2/foregin/banshi/wjrs/crj'
2019-03-26 15:19:07 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.gov.cn/banshi/2012-11/19/content_2269880.htm> (referer: http://www.gov.cn/banshi/wjrs/crj.htm)
Traceback (most recent call last):
  File "/usr/local/lib/python3.7/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python3.7/site-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/Users/a824810056/Desktop/py2.7-GovSpider/GovSpider2/GovSpider2/spiders/govSpider.py", line 84, in parse_item
    os.mkdir(newPath)
FileNotFoundError: [Errno 2] No such file or directory: '/Users/a824810056/Desktop/py2.7-GovSpider/GovSpider2/foregin/banshi/wjrs/crj'
2019-03-26 15:19:07 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.gov.cn/banshi/2012-11/19/content_2269879.htm> (referer: http://www.gov.cn/banshi/wjrs/crj.htm)
Traceback (most recent call last):
  File "/usr/local/lib/python3.7/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python3.7/site-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/Users/a824810056/Desktop/py2.7-GovSpider/GovSpider2/GovSpider2/spiders/govSpider.py", line 84, in parse_item
    os.mkdir(newPath)
FileNotFoundError: [Errno 2] No such file or directory: '/Users/a824810056/Desktop/py2.7-GovSpider/GovSpider2/foregin/banshi/wjrs/crj'
2019-03-26 15:19:07 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.gov.cn/banshi/2005-10/10/content_75460.htm> (referer: http://www.gov.cn/banshi/zjpq.htm)
Traceback (most recent call last):
  File "/usr/local/lib/python3.7/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python3.7/site-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/Users/a824810056/Desktop/py2.7-GovSpider/GovSpider2/GovSpider2/spiders/govSpider.py", line 84, in parse_item
    os.mkdir(newPath)
FileNotFoundError: [Errno 2] No such file or directory: '/Users/a824810056/Desktop/py2.7-GovSpider/GovSpider2/foregin/banshi/zjpq'
2019-03-26 15:19:07 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.gov.cn/banshi/2006-10/09/content_408018.htm> (referer: http://www.gov.cn/banshi/wjrs/crj.htm)
Traceback (most recent call last):
  File "/usr/local/lib/python3.7/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python3.7/site-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/Users/a824810056/Desktop/py2.7-GovSpider/GovSpider2/GovSpider2/spiders/govSpider.py", line 84, in parse_item
    os.mkdir(newPath)
FileNotFoundError: [Errno 2] No such file or directory: '/Users/a824810056/Desktop/py2.7-GovSpider/GovSpider2/foregin/banshi/wjrs/crj'
2019-03-26 15:19:07 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.gov.cn/banshi/2005-10/10/content_75553.htm> (referer: http://www.gov.cn/banshi/zjpq.htm)
Traceback (most recent call last):
  File "/usr/local/lib/python3.7/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python3.7/site-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/Users/a824810056/Desktop/py2.7-GovSpider/GovSpider2/GovSpider2/spiders/govSpider.py", line 84, in parse_item
    os.mkdir(newPath)
FileNotFoundError: [Errno 2] No such file or directory: '/Users/a824810056/Desktop/py2.7-GovSpider/GovSpider2/foregin/banshi/zjpq'
2019-03-26 15:19:07 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.gov.cn/banshi/2005-06/23/content_75551.htm> (referer: http://www.gov.cn/banshi/zjpq.htm)
Traceback (most recent call last):
  File "/usr/local/lib/python3.7/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python3.7/site-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/Users/a824810056/Desktop/py2.7-GovSpider/GovSpider2/GovSpider2/spiders/govSpider.py", line 84, in parse_item
    os.mkdir(newPath)
FileNotFoundError: [Errno 2] No such file or directory: '/Users/a824810056/Desktop/py2.7-GovSpider/GovSpider2/foregin/banshi/zjpq'
2019-03-26 15:19:07 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.gov.cn/banshi/2005-06/23/content_8734.htm> (referer: http://www.gov.cn/banshi/zjpq.htm)
Traceback (most recent call last):
  File "/usr/local/lib/python3.7/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python3.7/site-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/Users/a824810056/Desktop/py2.7-GovSpider/GovSpider2/GovSpider2/spiders/govSpider.py", line 84, in parse_item
    os.mkdir(newPath)
FileNotFoundError: [Errno 2] No such file or directory: '/Users/a824810056/Desktop/py2.7-GovSpider/GovSpider2/foregin/banshi/zjpq'
2019-03-26 15:19:07 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.gov.cn/banshi/2005-06/08/content_4837.htm> (referer: http://www.gov.cn/banshi/wjrs/crj.htm)
Traceback (most recent call last):
  File "/usr/local/lib/python3.7/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python3.7/site-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/Users/a824810056/Desktop/py2.7-GovSpider/GovSpider2/GovSpider2/spiders/govSpider.py", line 84, in parse_item
    os.mkdir(newPath)
FileNotFoundError: [Errno 2] No such file or directory: '/Users/a824810056/Desktop/py2.7-GovSpider/GovSpider2/foregin/banshi/wjrs/crj'
2019-03-26 15:19:07 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.gov.cn/banshi/2012-11/19/content_2269878.htm> (referer: http://www.gov.cn/banshi/wjrs/crj.htm)
Traceback (most recent call last):
  File "/usr/local/lib/python3.7/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python3.7/site-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/Users/a824810056/Desktop/py2.7-GovSpider/GovSpider2/GovSpider2/spiders/govSpider.py", line 84, in parse_item
    os.mkdir(newPath)
FileNotFoundError: [Errno 2] No such file or directory: '/Users/a824810056/Desktop/py2.7-GovSpider/GovSpider2/foregin/banshi/wjrs/crj'
2019-03-26 15:19:07 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.gov.cn/banshi/2005-10/10/content_75526.htm> (referer: http://www.gov.cn/banshi/zjpq.htm)
Traceback (most recent call last):
  File "/usr/local/lib/python3.7/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python3.7/site-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/Users/a824810056/Desktop/py2.7-GovSpider/GovSpider2/GovSpider2/spiders/govSpider.py", line 84, in parse_item
    os.mkdir(newPath)
FileNotFoundError: [Errno 2] No such file or directory: '/Users/a824810056/Desktop/py2.7-GovSpider/GovSpider2/foregin/banshi/zjpq'
2019-03-26 15:19:07 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.gov.cn/banshi/2005-10/10/content_75500.htm> (referer: http://www.gov.cn/banshi/zjpq.htm)
Traceback (most recent call last):
  File "/usr/local/lib/python3.7/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python3.7/site-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/Users/a824810056/Desktop/py2.7-GovSpider/GovSpider2/GovSpider2/spiders/govSpider.py", line 84, in parse_item
    os.mkdir(newPath)
FileNotFoundError: [Errno 2] No such file or directory: '/Users/a824810056/Desktop/py2.7-GovSpider/GovSpider2/foregin/banshi/zjpq'
2019-03-26 15:19:07 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.gov.cn/banshi/2012-11/19/content_2269876.htm> (referer: http://www.gov.cn/banshi/wjrs/crj.htm)
Traceback (most recent call last):
  File "/usr/local/lib/python3.7/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python3.7/site-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/Users/a824810056/Desktop/py2.7-GovSpider/GovSpider2/GovSpider2/spiders/govSpider.py", line 84, in parse_item
    os.mkdir(newPath)
FileNotFoundError: [Errno 2] No such file or directory: '/Users/a824810056/Desktop/py2.7-GovSpider/GovSpider2/foregin/banshi/wjrs/crj'
2019-03-26 15:19:07 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.gov.cn/banshi/2006-10/09/content_408005.htm> (referer: http://www.gov.cn/banshi/wjrs/crj.htm)
Traceback (most recent call last):
  File "/usr/local/lib/python3.7/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python3.7/site-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/Users/a824810056/Desktop/py2.7-GovSpider/GovSpider2/GovSpider2/spiders/govSpider.py", line 84, in parse_item
    os.mkdir(newPath)
FileNotFoundError: [Errno 2] No such file or directory: '/Users/a824810056/Desktop/py2.7-GovSpider/GovSpider2/foregin/banshi/wjrs/crj'
2019-03-26 15:19:07 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.gov.cn/banshi/2005-10/10/content_75529.htm> (referer: http://www.gov.cn/banshi/zjpq.htm)
Traceback (most recent call last):
  File "/usr/local/lib/python3.7/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python3.7/site-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/Users/a824810056/Desktop/py2.7-GovSpider/GovSpider2/GovSpider2/spiders/govSpider.py", line 84, in parse_item
    os.mkdir(newPath)
FileNotFoundError: [Errno 2] No such file or directory: '/Users/a824810056/Desktop/py2.7-GovSpider/GovSpider2/foregin/banshi/zjpq'
2019-03-26 15:19:07 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.gov.cn/banshi/2005-10/10/content_75518.htm> (referer: http://www.gov.cn/banshi/zjpq.htm)
Traceback (most recent call last):
  File "/usr/local/lib/python3.7/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python3.7/site-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/Users/a824810056/Desktop/py2.7-GovSpider/GovSpider2/GovSpider2/spiders/govSpider.py", line 84, in parse_item
    os.mkdir(newPath)
FileNotFoundError: [Errno 2] No such file or directory: '/Users/a824810056/Desktop/py2.7-GovSpider/GovSpider2/foregin/banshi/zjpq'
2019-03-26 15:19:07 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.gov.cn/banshi/2006-03/02/content_215803.htm> (referer: http://www.gov.cn/banshi/zjpq.htm)
Traceback (most recent call last):
  File "/usr/local/lib/python3.7/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python3.7/site-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/Users/a824810056/Desktop/py2.7-GovSpider/GovSpider2/GovSpider2/spiders/govSpider.py", line 84, in parse_item
    os.mkdir(newPath)
FileNotFoundError: [Errno 2] No such file or directory: '/Users/a824810056/Desktop/py2.7-GovSpider/GovSpider2/foregin/banshi/zjpq'
2019-03-26 15:19:07 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.gov.cn/banshi/2005-10/10/content_75453.htm> (referer: http://www.gov.cn/banshi/zjpq.htm)
Traceback (most recent call last):
  File "/usr/local/lib/python3.7/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python3.7/site-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/Users/a824810056/Desktop/py2.7-GovSpider/GovSpider2/GovSpider2/spiders/govSpider.py", line 84, in parse_item
    os.mkdir(newPath)
FileNotFoundError: [Errno 2] No such file or directory: '/Users/a824810056/Desktop/py2.7-GovSpider/GovSpider2/foregin/banshi/zjpq'
2019-03-26 15:19:07 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.gov.cn/banshi/2006-10/09/content_408016.htm> (referer: http://www.gov.cn/banshi/wjrs/crj.htm)
Traceback (most recent call last):
  File "/usr/local/lib/python3.7/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python3.7/site-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/Users/a824810056/Desktop/py2.7-GovSpider/GovSpider2/GovSpider2/spiders/govSpider.py", line 84, in parse_item
    os.mkdir(newPath)
FileNotFoundError: [Errno 2] No such file or directory: '/Users/a824810056/Desktop/py2.7-GovSpider/GovSpider2/foregin/banshi/wjrs/crj'
2019-03-26 15:19:07 [scrapy.core.engine] INFO: Closing spider (finished)
2019-03-26 15:19:07 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 11301,
 'downloader/request_count': 31,
 'downloader/request_method_count/GET': 31,
 'downloader/response_bytes': 515826,
 'downloader/response_count': 31,
 'downloader/response_status_count/200': 31,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2019, 3, 26, 7, 19, 7, 628898),
 'log_count/ERROR': 28,
 'log_count/INFO': 9,
 'memusage/max': 49913856,
 'memusage/startup': 49913856,
 'offsite/domains': 1,
 'offsite/filtered': 1,
 'request_depth_max': 1,
 'response_received_count': 31,
 'robotstxt/request_count': 1,
 'robotstxt/response_count': 1,
 'robotstxt/response_status_count/200': 1,
 'scheduler/dequeued': 30,
 'scheduler/dequeued/memory': 30,
 'scheduler/enqueued': 30,
 'scheduler/enqueued/memory': 30,
 'spider_exceptions/FileNotFoundError': 28,
 'start_time': datetime.datetime(2019, 3, 26, 7, 19, 6, 370080)}
2019-03-26 15:19:07 [scrapy.core.engine] INFO: Spider closed (finished)
2019-03-26 15:22:10 [scrapy.utils.log] INFO: Scrapy 1.6.0 started (bot: GovSpider2)
2019-03-26 15:22:10 [scrapy.utils.log] INFO: Versions: lxml 4.3.2.0, libxml2 2.9.9, cssselect 1.0.3, parsel 1.5.1, w3lib 1.20.0, Twisted 18.9.0, Python 3.7.2 (default, Feb 13 2019, 10:07:58) - [Clang 10.0.0 (clang-1000.11.45.5)], pyOpenSSL 19.0.0 (OpenSSL 1.1.1b  26 Feb 2019), cryptography 2.6.1, Platform Darwin-18.2.0-x86_64-i386-64bit
2019-03-26 15:22:10 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'GovSpider2', 'LOG_FILE': 'log/spiderlog20190326.txt', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'GovSpider2.spiders', 'ROBOTSTXT_OBEY': True, 'SPIDER_MODULES': ['GovSpider2.spiders']}
2019-03-26 15:22:10 [scrapy.extensions.telnet] INFO: Telnet Password: ef3fce154caeaef7
2019-03-26 15:22:10 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats']
2019-03-26 15:22:10 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.robotstxt.RobotsTxtMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2019-03-26 15:22:10 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2019-03-26 15:22:10 [scrapy.middleware] INFO: Enabled item pipelines:
['GovSpider2.pipelines.Govspider2Pipeline']
2019-03-26 15:22:10 [scrapy.core.engine] INFO: Spider opened
2019-03-26 15:22:10 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-03-26 15:22:10 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023
2019-03-26 15:22:11 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.gov.cn/banshi/2005-07/06/content_12279.htm> (referer: http://www.gov.cn/banshi/wjrs/crj.htm)
Traceback (most recent call last):
  File "/usr/local/lib/python3.7/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python3.7/site-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/Users/a824810056/Desktop/py2.7-GovSpider/GovSpider2/GovSpider2/spiders/govSpider.py", line 84, in parse_item
    os.mkdir(newPath)
FileNotFoundError: [Errno 2] No such file or directory: '/Users/a824810056/Desktop/py2.7-GovSpider/GovSpider2/foregin/banshi/wjrs/crj'
2019-03-26 15:22:11 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.gov.cn/banshi/2006-10/09/content_408010.htm> (referer: http://www.gov.cn/banshi/wjrs/crj.htm)
Traceback (most recent call last):
  File "/usr/local/lib/python3.7/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python3.7/site-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/Users/a824810056/Desktop/py2.7-GovSpider/GovSpider2/GovSpider2/spiders/govSpider.py", line 84, in parse_item
    os.mkdir(newPath)
FileNotFoundError: [Errno 2] No such file or directory: '/Users/a824810056/Desktop/py2.7-GovSpider/GovSpider2/foregin/banshi/wjrs/crj'
2019-03-26 15:22:11 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.gov.cn/banshi/2005-09/12/content_31017.htm> (referer: http://www.gov.cn/banshi/wjrs/crj.htm)
Traceback (most recent call last):
  File "/usr/local/lib/python3.7/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python3.7/site-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/Users/a824810056/Desktop/py2.7-GovSpider/GovSpider2/GovSpider2/spiders/govSpider.py", line 84, in parse_item
    os.mkdir(newPath)
FileNotFoundError: [Errno 2] No such file or directory: '/Users/a824810056/Desktop/py2.7-GovSpider/GovSpider2/foregin/banshi/wjrs/crj'
2019-03-26 15:22:11 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.gov.cn/banshi/2006-10/09/content_408014.htm> (referer: http://www.gov.cn/banshi/wjrs/crj.htm)
Traceback (most recent call last):
  File "/usr/local/lib/python3.7/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python3.7/site-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/Users/a824810056/Desktop/py2.7-GovSpider/GovSpider2/GovSpider2/spiders/govSpider.py", line 84, in parse_item
    os.mkdir(newPath)
FileNotFoundError: [Errno 2] No such file or directory: '/Users/a824810056/Desktop/py2.7-GovSpider/GovSpider2/foregin/banshi/wjrs/crj'
2019-03-26 15:22:11 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.gov.cn/banshi/2006-10/09/content_408005.htm> (referer: http://www.gov.cn/banshi/wjrs/crj.htm)
Traceback (most recent call last):
  File "/usr/local/lib/python3.7/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python3.7/site-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/Users/a824810056/Desktop/py2.7-GovSpider/GovSpider2/GovSpider2/spiders/govSpider.py", line 84, in parse_item
    os.mkdir(newPath)
FileNotFoundError: [Errno 2] No such file or directory: '/Users/a824810056/Desktop/py2.7-GovSpider/GovSpider2/foregin/banshi/wjrs/crj'
2019-03-26 15:22:11 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.gov.cn/banshi/2005-06/08/content_4836.htm> (referer: http://www.gov.cn/banshi/wjrs/crj.htm)
Traceback (most recent call last):
  File "/usr/local/lib/python3.7/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python3.7/site-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/Users/a824810056/Desktop/py2.7-GovSpider/GovSpider2/GovSpider2/spiders/govSpider.py", line 84, in parse_item
    os.mkdir(newPath)
FileNotFoundError: [Errno 2] No such file or directory: '/Users/a824810056/Desktop/py2.7-GovSpider/GovSpider2/foregin/banshi/wjrs/crj'
2019-03-26 15:22:11 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.gov.cn/banshi/2006-10/09/content_408016.htm> (referer: http://www.gov.cn/banshi/wjrs/crj.htm)
Traceback (most recent call last):
  File "/usr/local/lib/python3.7/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python3.7/site-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/Users/a824810056/Desktop/py2.7-GovSpider/GovSpider2/GovSpider2/spiders/govSpider.py", line 84, in parse_item
    os.mkdir(newPath)
FileNotFoundError: [Errno 2] No such file or directory: '/Users/a824810056/Desktop/py2.7-GovSpider/GovSpider2/foregin/banshi/wjrs/crj'
2019-03-26 15:22:11 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.gov.cn/banshi/2005-05/26/content_1300.htm> (referer: http://www.gov.cn/banshi/wjrs/crj.htm)
Traceback (most recent call last):
  File "/usr/local/lib/python3.7/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python3.7/site-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/Users/a824810056/Desktop/py2.7-GovSpider/GovSpider2/GovSpider2/spiders/govSpider.py", line 84, in parse_item
    os.mkdir(newPath)
FileNotFoundError: [Errno 2] No such file or directory: '/Users/a824810056/Desktop/py2.7-GovSpider/GovSpider2/foregin/banshi/wjrs/crj'
2019-03-26 15:22:11 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.gov.cn/banshi/2006-10/09/content_408018.htm> (referer: http://www.gov.cn/banshi/wjrs/crj.htm)
Traceback (most recent call last):
  File "/usr/local/lib/python3.7/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python3.7/site-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/Users/a824810056/Desktop/py2.7-GovSpider/GovSpider2/GovSpider2/spiders/govSpider.py", line 84, in parse_item
    os.mkdir(newPath)
FileNotFoundError: [Errno 2] No such file or directory: '/Users/a824810056/Desktop/py2.7-GovSpider/GovSpider2/foregin/banshi/wjrs/crj'
2019-03-26 15:22:11 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.gov.cn/banshi/2005-06/08/content_4837.htm> (referer: http://www.gov.cn/banshi/wjrs/crj.htm)
Traceback (most recent call last):
  File "/usr/local/lib/python3.7/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python3.7/site-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/Users/a824810056/Desktop/py2.7-GovSpider/GovSpider2/GovSpider2/spiders/govSpider.py", line 84, in parse_item
    os.mkdir(newPath)
FileNotFoundError: [Errno 2] No such file or directory: '/Users/a824810056/Desktop/py2.7-GovSpider/GovSpider2/foregin/banshi/wjrs/crj'
2019-03-26 15:22:11 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.gov.cn/banshi/2005-07/08/content_13036.htm> (referer: http://www.gov.cn/banshi/wjrs/crj.htm)
Traceback (most recent call last):
  File "/usr/local/lib/python3.7/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python3.7/site-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/Users/a824810056/Desktop/py2.7-GovSpider/GovSpider2/GovSpider2/spiders/govSpider.py", line 84, in parse_item
    os.mkdir(newPath)
FileNotFoundError: [Errno 2] No such file or directory: '/Users/a824810056/Desktop/py2.7-GovSpider/GovSpider2/foregin/banshi/wjrs/crj'
2019-03-26 15:22:11 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.gov.cn/banshi/2012-11/19/content_2269879.htm> (referer: http://www.gov.cn/banshi/wjrs/crj.htm)
Traceback (most recent call last):
  File "/usr/local/lib/python3.7/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python3.7/site-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/Users/a824810056/Desktop/py2.7-GovSpider/GovSpider2/GovSpider2/spiders/govSpider.py", line 84, in parse_item
    os.mkdir(newPath)
FileNotFoundError: [Errno 2] No such file or directory: '/Users/a824810056/Desktop/py2.7-GovSpider/GovSpider2/foregin/banshi/wjrs/crj'
2019-03-26 15:22:11 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.gov.cn/banshi/2005-10/10/content_75526.htm> (referer: http://www.gov.cn/banshi/zjpq.htm)
Traceback (most recent call last):
  File "/usr/local/lib/python3.7/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python3.7/site-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/Users/a824810056/Desktop/py2.7-GovSpider/GovSpider2/GovSpider2/spiders/govSpider.py", line 84, in parse_item
    os.mkdir(newPath)
FileNotFoundError: [Errno 2] No such file or directory: '/Users/a824810056/Desktop/py2.7-GovSpider/GovSpider2/foregin/banshi/zjpq'
2019-03-26 15:22:11 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.gov.cn/banshi/2005-10/10/content_75453.htm> (referer: http://www.gov.cn/banshi/zjpq.htm)
Traceback (most recent call last):
  File "/usr/local/lib/python3.7/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python3.7/site-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/Users/a824810056/Desktop/py2.7-GovSpider/GovSpider2/GovSpider2/spiders/govSpider.py", line 84, in parse_item
    os.mkdir(newPath)
FileNotFoundError: [Errno 2] No such file or directory: '/Users/a824810056/Desktop/py2.7-GovSpider/GovSpider2/foregin/banshi/zjpq'
2019-03-26 15:22:11 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.gov.cn/banshi/2006-08/23/content_368260.htm> (referer: http://www.gov.cn/banshi/wjrs/crj.htm)
Traceback (most recent call last):
  File "/usr/local/lib/python3.7/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python3.7/site-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/Users/a824810056/Desktop/py2.7-GovSpider/GovSpider2/GovSpider2/spiders/govSpider.py", line 84, in parse_item
    os.mkdir(newPath)
FileNotFoundError: [Errno 2] No such file or directory: '/Users/a824810056/Desktop/py2.7-GovSpider/GovSpider2/foregin/banshi/wjrs/crj'
2019-03-26 15:22:11 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.gov.cn/banshi/2012-11/19/content_2269878.htm> (referer: http://www.gov.cn/banshi/wjrs/crj.htm)
Traceback (most recent call last):
  File "/usr/local/lib/python3.7/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python3.7/site-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/Users/a824810056/Desktop/py2.7-GovSpider/GovSpider2/GovSpider2/spiders/govSpider.py", line 84, in parse_item
    os.mkdir(newPath)
FileNotFoundError: [Errno 2] No such file or directory: '/Users/a824810056/Desktop/py2.7-GovSpider/GovSpider2/foregin/banshi/wjrs/crj'
2019-03-26 15:22:11 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.gov.cn/banshi/2005-10/10/content_75500.htm> (referer: http://www.gov.cn/banshi/zjpq.htm)
Traceback (most recent call last):
  File "/usr/local/lib/python3.7/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python3.7/site-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/Users/a824810056/Desktop/py2.7-GovSpider/GovSpider2/GovSpider2/spiders/govSpider.py", line 84, in parse_item
    os.mkdir(newPath)
FileNotFoundError: [Errno 2] No such file or directory: '/Users/a824810056/Desktop/py2.7-GovSpider/GovSpider2/foregin/banshi/zjpq'
2019-03-26 15:22:11 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.gov.cn/banshi/2005-10/10/content_75518.htm> (referer: http://www.gov.cn/banshi/zjpq.htm)
Traceback (most recent call last):
  File "/usr/local/lib/python3.7/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python3.7/site-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/Users/a824810056/Desktop/py2.7-GovSpider/GovSpider2/GovSpider2/spiders/govSpider.py", line 84, in parse_item
    os.mkdir(newPath)
FileNotFoundError: [Errno 2] No such file or directory: '/Users/a824810056/Desktop/py2.7-GovSpider/GovSpider2/foregin/banshi/zjpq'
2019-03-26 15:22:11 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.gov.cn/banshi/2012-11/19/content_2269877.htm> (referer: http://www.gov.cn/banshi/wjrs/crj.htm)
Traceback (most recent call last):
  File "/usr/local/lib/python3.7/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python3.7/site-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/Users/a824810056/Desktop/py2.7-GovSpider/GovSpider2/GovSpider2/spiders/govSpider.py", line 84, in parse_item
    os.mkdir(newPath)
FileNotFoundError: [Errno 2] No such file or directory: '/Users/a824810056/Desktop/py2.7-GovSpider/GovSpider2/foregin/banshi/wjrs/crj'
2019-03-26 15:22:11 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.gov.cn/banshi/2007-05/10/content_610216.htm> (referer: http://www.gov.cn/banshi/wjrs/crj.htm)
Traceback (most recent call last):
  File "/usr/local/lib/python3.7/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python3.7/site-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/Users/a824810056/Desktop/py2.7-GovSpider/GovSpider2/GovSpider2/spiders/govSpider.py", line 84, in parse_item
    os.mkdir(newPath)
FileNotFoundError: [Errno 2] No such file or directory: '/Users/a824810056/Desktop/py2.7-GovSpider/GovSpider2/foregin/banshi/wjrs/crj'
2019-03-26 15:22:11 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.gov.cn/banshi/2006-03/02/content_215803.htm> (referer: http://www.gov.cn/banshi/zjpq.htm)
Traceback (most recent call last):
  File "/usr/local/lib/python3.7/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python3.7/site-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/Users/a824810056/Desktop/py2.7-GovSpider/GovSpider2/GovSpider2/spiders/govSpider.py", line 84, in parse_item
    os.mkdir(newPath)
FileNotFoundError: [Errno 2] No such file or directory: '/Users/a824810056/Desktop/py2.7-GovSpider/GovSpider2/foregin/banshi/zjpq'
2019-03-26 15:22:11 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.gov.cn/banshi/2012-11/19/content_2269880.htm> (referer: http://www.gov.cn/banshi/wjrs/crj.htm)
Traceback (most recent call last):
  File "/usr/local/lib/python3.7/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python3.7/site-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/Users/a824810056/Desktop/py2.7-GovSpider/GovSpider2/GovSpider2/spiders/govSpider.py", line 84, in parse_item
    os.mkdir(newPath)
FileNotFoundError: [Errno 2] No such file or directory: '/Users/a824810056/Desktop/py2.7-GovSpider/GovSpider2/foregin/banshi/wjrs/crj'
2019-03-26 15:22:11 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.gov.cn/banshi/2012-11/19/content_2269876.htm> (referer: http://www.gov.cn/banshi/wjrs/crj.htm)
Traceback (most recent call last):
  File "/usr/local/lib/python3.7/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python3.7/site-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/Users/a824810056/Desktop/py2.7-GovSpider/GovSpider2/GovSpider2/spiders/govSpider.py", line 84, in parse_item
    os.mkdir(newPath)
FileNotFoundError: [Errno 2] No such file or directory: '/Users/a824810056/Desktop/py2.7-GovSpider/GovSpider2/foregin/banshi/wjrs/crj'
2019-03-26 15:22:11 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.gov.cn/banshi/2005-06/23/content_75551.htm> (referer: http://www.gov.cn/banshi/zjpq.htm)
Traceback (most recent call last):
  File "/usr/local/lib/python3.7/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python3.7/site-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/Users/a824810056/Desktop/py2.7-GovSpider/GovSpider2/GovSpider2/spiders/govSpider.py", line 84, in parse_item
    os.mkdir(newPath)
FileNotFoundError: [Errno 2] No such file or directory: '/Users/a824810056/Desktop/py2.7-GovSpider/GovSpider2/foregin/banshi/zjpq'
2019-03-26 15:22:11 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.gov.cn/banshi/2005-10/10/content_75529.htm> (referer: http://www.gov.cn/banshi/zjpq.htm)
Traceback (most recent call last):
  File "/usr/local/lib/python3.7/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python3.7/site-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/Users/a824810056/Desktop/py2.7-GovSpider/GovSpider2/GovSpider2/spiders/govSpider.py", line 84, in parse_item
    os.mkdir(newPath)
FileNotFoundError: [Errno 2] No such file or directory: '/Users/a824810056/Desktop/py2.7-GovSpider/GovSpider2/foregin/banshi/zjpq'
2019-03-26 15:22:11 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.gov.cn/banshi/2005-10/10/content_75460.htm> (referer: http://www.gov.cn/banshi/zjpq.htm)
Traceback (most recent call last):
  File "/usr/local/lib/python3.7/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python3.7/site-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/Users/a824810056/Desktop/py2.7-GovSpider/GovSpider2/GovSpider2/spiders/govSpider.py", line 84, in parse_item
    os.mkdir(newPath)
FileNotFoundError: [Errno 2] No such file or directory: '/Users/a824810056/Desktop/py2.7-GovSpider/GovSpider2/foregin/banshi/zjpq'
2019-03-26 15:22:11 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.gov.cn/banshi/2005-10/10/content_75553.htm> (referer: http://www.gov.cn/banshi/zjpq.htm)
Traceback (most recent call last):
  File "/usr/local/lib/python3.7/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python3.7/site-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/Users/a824810056/Desktop/py2.7-GovSpider/GovSpider2/GovSpider2/spiders/govSpider.py", line 84, in parse_item
    os.mkdir(newPath)
FileNotFoundError: [Errno 2] No such file or directory: '/Users/a824810056/Desktop/py2.7-GovSpider/GovSpider2/foregin/banshi/zjpq'
2019-03-26 15:22:12 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.gov.cn/banshi/2005-06/23/content_8734.htm> (referer: http://www.gov.cn/banshi/zjpq.htm)
Traceback (most recent call last):
  File "/usr/local/lib/python3.7/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python3.7/site-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/Users/a824810056/Desktop/py2.7-GovSpider/GovSpider2/GovSpider2/spiders/govSpider.py", line 84, in parse_item
    os.mkdir(newPath)
FileNotFoundError: [Errno 2] No such file or directory: '/Users/a824810056/Desktop/py2.7-GovSpider/GovSpider2/foregin/banshi/zjpq'
2019-03-26 15:22:12 [scrapy.core.engine] INFO: Closing spider (finished)
2019-03-26 15:22:12 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 11301,
 'downloader/request_count': 31,
 'downloader/request_method_count/GET': 31,
 'downloader/response_bytes': 515826,
 'downloader/response_count': 31,
 'downloader/response_status_count/200': 31,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2019, 3, 26, 7, 22, 12, 25742),
 'log_count/ERROR': 28,
 'log_count/INFO': 9,
 'memusage/max': 49975296,
 'memusage/startup': 49975296,
 'offsite/domains': 1,
 'offsite/filtered': 1,
 'request_depth_max': 1,
 'response_received_count': 31,
 'robotstxt/request_count': 1,
 'robotstxt/response_count': 1,
 'robotstxt/response_status_count/200': 1,
 'scheduler/dequeued': 30,
 'scheduler/dequeued/memory': 30,
 'scheduler/enqueued': 30,
 'scheduler/enqueued/memory': 30,
 'spider_exceptions/FileNotFoundError': 28,
 'start_time': datetime.datetime(2019, 3, 26, 7, 22, 10, 869674)}
2019-03-26 15:22:12 [scrapy.core.engine] INFO: Spider closed (finished)
2019-03-26 15:22:40 [scrapy.utils.log] INFO: Scrapy 1.6.0 started (bot: GovSpider2)
2019-03-26 15:22:40 [scrapy.utils.log] INFO: Versions: lxml 4.3.2.0, libxml2 2.9.9, cssselect 1.0.3, parsel 1.5.1, w3lib 1.20.0, Twisted 18.9.0, Python 3.7.2 (default, Feb 13 2019, 10:07:58) - [Clang 10.0.0 (clang-1000.11.45.5)], pyOpenSSL 19.0.0 (OpenSSL 1.1.1b  26 Feb 2019), cryptography 2.6.1, Platform Darwin-18.2.0-x86_64-i386-64bit
2019-03-26 15:22:40 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'GovSpider2', 'LOG_FILE': 'log/spiderlog20190326.txt', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'GovSpider2.spiders', 'ROBOTSTXT_OBEY': True, 'SPIDER_MODULES': ['GovSpider2.spiders']}
2019-03-26 15:22:40 [scrapy.extensions.telnet] INFO: Telnet Password: af7cf17ae977b84f
2019-03-26 15:22:40 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats']
2019-03-26 15:22:40 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.robotstxt.RobotsTxtMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2019-03-26 15:22:40 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2019-03-26 15:22:40 [scrapy.middleware] INFO: Enabled item pipelines:
['GovSpider2.pipelines.Govspider2Pipeline']
2019-03-26 15:22:40 [scrapy.core.engine] INFO: Spider opened
2019-03-26 15:22:40 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-03-26 15:22:40 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023
2019-03-26 15:22:42 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.gov.cn/banshi/2005-07/06/content_12279.htm> (referer: http://www.gov.cn/banshi/wjrs/crj.htm)
Traceback (most recent call last):
  File "/usr/local/lib/python3.7/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python3.7/site-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/Users/a824810056/Desktop/py2.7-GovSpider/GovSpider2/GovSpider2/spiders/govSpider.py", line 84, in parse_item
    os.mkdir(newPath)
FileNotFoundError: [Errno 2] No such file or directory: '/Users/a824810056/Desktop/py2.7-GovSpider/GovSpider2/foregin/banshi/wjrs/crj'
2019-03-26 15:22:42 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.gov.cn/banshi/2005-10/10/content_75518.htm> (referer: http://www.gov.cn/banshi/zjpq.htm)
Traceback (most recent call last):
  File "/usr/local/lib/python3.7/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python3.7/site-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/Users/a824810056/Desktop/py2.7-GovSpider/GovSpider2/GovSpider2/spiders/govSpider.py", line 84, in parse_item
    os.mkdir(newPath)
FileNotFoundError: [Errno 2] No such file or directory: '/Users/a824810056/Desktop/py2.7-GovSpider/GovSpider2/foregin/banshi/zjpq'
2019-03-26 15:22:42 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.gov.cn/banshi/2005-06/23/content_75551.htm> (referer: http://www.gov.cn/banshi/zjpq.htm)
Traceback (most recent call last):
  File "/usr/local/lib/python3.7/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python3.7/site-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/Users/a824810056/Desktop/py2.7-GovSpider/GovSpider2/GovSpider2/spiders/govSpider.py", line 84, in parse_item
    os.mkdir(newPath)
FileNotFoundError: [Errno 2] No such file or directory: '/Users/a824810056/Desktop/py2.7-GovSpider/GovSpider2/foregin/banshi/zjpq'
2019-03-26 15:22:42 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.gov.cn/banshi/2005-10/10/content_75526.htm> (referer: http://www.gov.cn/banshi/zjpq.htm)
Traceback (most recent call last):
  File "/usr/local/lib/python3.7/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python3.7/site-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/Users/a824810056/Desktop/py2.7-GovSpider/GovSpider2/GovSpider2/spiders/govSpider.py", line 84, in parse_item
    os.mkdir(newPath)
FileNotFoundError: [Errno 2] No such file or directory: '/Users/a824810056/Desktop/py2.7-GovSpider/GovSpider2/foregin/banshi/zjpq'
2019-03-26 15:22:42 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.gov.cn/banshi/2005-06/23/content_8734.htm> (referer: http://www.gov.cn/banshi/zjpq.htm)
Traceback (most recent call last):
  File "/usr/local/lib/python3.7/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python3.7/site-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/Users/a824810056/Desktop/py2.7-GovSpider/GovSpider2/GovSpider2/spiders/govSpider.py", line 84, in parse_item
    os.mkdir(newPath)
FileNotFoundError: [Errno 2] No such file or directory: '/Users/a824810056/Desktop/py2.7-GovSpider/GovSpider2/foregin/banshi/zjpq'
2019-03-26 15:22:42 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.gov.cn/banshi/2005-10/10/content_75460.htm> (referer: http://www.gov.cn/banshi/zjpq.htm)
Traceback (most recent call last):
  File "/usr/local/lib/python3.7/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python3.7/site-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/Users/a824810056/Desktop/py2.7-GovSpider/GovSpider2/GovSpider2/spiders/govSpider.py", line 84, in parse_item
    os.mkdir(newPath)
FileNotFoundError: [Errno 2] No such file or directory: '/Users/a824810056/Desktop/py2.7-GovSpider/GovSpider2/foregin/banshi/zjpq'
2019-03-26 15:22:42 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.gov.cn/banshi/2005-10/10/content_75529.htm> (referer: http://www.gov.cn/banshi/zjpq.htm)
Traceback (most recent call last):
  File "/usr/local/lib/python3.7/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python3.7/site-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/Users/a824810056/Desktop/py2.7-GovSpider/GovSpider2/GovSpider2/spiders/govSpider.py", line 84, in parse_item
    os.mkdir(newPath)
FileNotFoundError: [Errno 2] No such file or directory: '/Users/a824810056/Desktop/py2.7-GovSpider/GovSpider2/foregin/banshi/zjpq'
2019-03-26 15:22:42 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.gov.cn/banshi/2005-10/10/content_75453.htm> (referer: http://www.gov.cn/banshi/zjpq.htm)
Traceback (most recent call last):
  File "/usr/local/lib/python3.7/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python3.7/site-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/Users/a824810056/Desktop/py2.7-GovSpider/GovSpider2/GovSpider2/spiders/govSpider.py", line 84, in parse_item
    os.mkdir(newPath)
FileNotFoundError: [Errno 2] No such file or directory: '/Users/a824810056/Desktop/py2.7-GovSpider/GovSpider2/foregin/banshi/zjpq'
2019-03-26 15:22:42 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.gov.cn/banshi/2005-10/10/content_75553.htm> (referer: http://www.gov.cn/banshi/zjpq.htm)
Traceback (most recent call last):
  File "/usr/local/lib/python3.7/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python3.7/site-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/Users/a824810056/Desktop/py2.7-GovSpider/GovSpider2/GovSpider2/spiders/govSpider.py", line 84, in parse_item
    os.mkdir(newPath)
FileNotFoundError: [Errno 2] No such file or directory: '/Users/a824810056/Desktop/py2.7-GovSpider/GovSpider2/foregin/banshi/zjpq'
2019-03-26 15:22:42 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.gov.cn/banshi/2006-10/09/content_408014.htm> (referer: http://www.gov.cn/banshi/wjrs/crj.htm)
Traceback (most recent call last):
  File "/usr/local/lib/python3.7/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python3.7/site-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/Users/a824810056/Desktop/py2.7-GovSpider/GovSpider2/GovSpider2/spiders/govSpider.py", line 84, in parse_item
    os.mkdir(newPath)
FileNotFoundError: [Errno 2] No such file or directory: '/Users/a824810056/Desktop/py2.7-GovSpider/GovSpider2/foregin/banshi/wjrs/crj'
2019-03-26 15:22:42 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.gov.cn/banshi/2005-05/26/content_1300.htm> (referer: http://www.gov.cn/banshi/wjrs/crj.htm)
Traceback (most recent call last):
  File "/usr/local/lib/python3.7/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python3.7/site-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/Users/a824810056/Desktop/py2.7-GovSpider/GovSpider2/GovSpider2/spiders/govSpider.py", line 84, in parse_item
    os.mkdir(newPath)
FileNotFoundError: [Errno 2] No such file or directory: '/Users/a824810056/Desktop/py2.7-GovSpider/GovSpider2/foregin/banshi/wjrs/crj'
2019-03-26 15:22:42 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.gov.cn/banshi/2005-10/10/content_75500.htm> (referer: http://www.gov.cn/banshi/zjpq.htm)
Traceback (most recent call last):
  File "/usr/local/lib/python3.7/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python3.7/site-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/Users/a824810056/Desktop/py2.7-GovSpider/GovSpider2/GovSpider2/spiders/govSpider.py", line 84, in parse_item
    os.mkdir(newPath)
FileNotFoundError: [Errno 2] No such file or directory: '/Users/a824810056/Desktop/py2.7-GovSpider/GovSpider2/foregin/banshi/zjpq'
2019-03-26 15:22:42 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.gov.cn/banshi/2006-10/09/content_408016.htm> (referer: http://www.gov.cn/banshi/wjrs/crj.htm)
Traceback (most recent call last):
  File "/usr/local/lib/python3.7/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python3.7/site-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/Users/a824810056/Desktop/py2.7-GovSpider/GovSpider2/GovSpider2/spiders/govSpider.py", line 84, in parse_item
    os.mkdir(newPath)
FileNotFoundError: [Errno 2] No such file or directory: '/Users/a824810056/Desktop/py2.7-GovSpider/GovSpider2/foregin/banshi/wjrs/crj'
2019-03-26 15:22:42 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.gov.cn/banshi/2005-06/08/content_4837.htm> (referer: http://www.gov.cn/banshi/wjrs/crj.htm)
Traceback (most recent call last):
  File "/usr/local/lib/python3.7/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python3.7/site-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/Users/a824810056/Desktop/py2.7-GovSpider/GovSpider2/GovSpider2/spiders/govSpider.py", line 84, in parse_item
    os.mkdir(newPath)
FileNotFoundError: [Errno 2] No such file or directory: '/Users/a824810056/Desktop/py2.7-GovSpider/GovSpider2/foregin/banshi/wjrs/crj'
2019-03-26 15:22:42 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.gov.cn/banshi/2005-09/12/content_31017.htm> (referer: http://www.gov.cn/banshi/wjrs/crj.htm)
Traceback (most recent call last):
  File "/usr/local/lib/python3.7/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python3.7/site-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/Users/a824810056/Desktop/py2.7-GovSpider/GovSpider2/GovSpider2/spiders/govSpider.py", line 84, in parse_item
    os.mkdir(newPath)
FileNotFoundError: [Errno 2] No such file or directory: '/Users/a824810056/Desktop/py2.7-GovSpider/GovSpider2/foregin/banshi/wjrs/crj'
2019-03-26 15:22:42 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.gov.cn/banshi/2005-06/08/content_4836.htm> (referer: http://www.gov.cn/banshi/wjrs/crj.htm)
Traceback (most recent call last):
  File "/usr/local/lib/python3.7/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python3.7/site-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/Users/a824810056/Desktop/py2.7-GovSpider/GovSpider2/GovSpider2/spiders/govSpider.py", line 84, in parse_item
    os.mkdir(newPath)
FileNotFoundError: [Errno 2] No such file or directory: '/Users/a824810056/Desktop/py2.7-GovSpider/GovSpider2/foregin/banshi/wjrs/crj'
2019-03-26 15:22:42 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.gov.cn/banshi/2005-07/08/content_13036.htm> (referer: http://www.gov.cn/banshi/wjrs/crj.htm)
Traceback (most recent call last):
  File "/usr/local/lib/python3.7/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python3.7/site-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/Users/a824810056/Desktop/py2.7-GovSpider/GovSpider2/GovSpider2/spiders/govSpider.py", line 84, in parse_item
    os.mkdir(newPath)
FileNotFoundError: [Errno 2] No such file or directory: '/Users/a824810056/Desktop/py2.7-GovSpider/GovSpider2/foregin/banshi/wjrs/crj'
2019-03-26 15:22:42 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.gov.cn/banshi/2007-05/10/content_610216.htm> (referer: http://www.gov.cn/banshi/wjrs/crj.htm)
Traceback (most recent call last):
  File "/usr/local/lib/python3.7/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python3.7/site-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/Users/a824810056/Desktop/py2.7-GovSpider/GovSpider2/GovSpider2/spiders/govSpider.py", line 84, in parse_item
    os.mkdir(newPath)
FileNotFoundError: [Errno 2] No such file or directory: '/Users/a824810056/Desktop/py2.7-GovSpider/GovSpider2/foregin/banshi/wjrs/crj'
2019-03-26 15:22:42 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.gov.cn/banshi/2006-10/09/content_408010.htm> (referer: http://www.gov.cn/banshi/wjrs/crj.htm)
Traceback (most recent call last):
  File "/usr/local/lib/python3.7/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python3.7/site-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/Users/a824810056/Desktop/py2.7-GovSpider/GovSpider2/GovSpider2/spiders/govSpider.py", line 84, in parse_item
    os.mkdir(newPath)
FileNotFoundError: [Errno 2] No such file or directory: '/Users/a824810056/Desktop/py2.7-GovSpider/GovSpider2/foregin/banshi/wjrs/crj'
2019-03-26 15:22:42 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.gov.cn/banshi/2012-11/19/content_2269876.htm> (referer: http://www.gov.cn/banshi/wjrs/crj.htm)
Traceback (most recent call last):
  File "/usr/local/lib/python3.7/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python3.7/site-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/Users/a824810056/Desktop/py2.7-GovSpider/GovSpider2/GovSpider2/spiders/govSpider.py", line 84, in parse_item
    os.mkdir(newPath)
FileNotFoundError: [Errno 2] No such file or directory: '/Users/a824810056/Desktop/py2.7-GovSpider/GovSpider2/foregin/banshi/wjrs/crj'
2019-03-26 15:22:42 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.gov.cn/banshi/2012-11/19/content_2269880.htm> (referer: http://www.gov.cn/banshi/wjrs/crj.htm)
Traceback (most recent call last):
  File "/usr/local/lib/python3.7/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python3.7/site-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/Users/a824810056/Desktop/py2.7-GovSpider/GovSpider2/GovSpider2/spiders/govSpider.py", line 84, in parse_item
    os.mkdir(newPath)
FileNotFoundError: [Errno 2] No such file or directory: '/Users/a824810056/Desktop/py2.7-GovSpider/GovSpider2/foregin/banshi/wjrs/crj'
2019-03-26 15:22:42 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.gov.cn/banshi/2006-03/02/content_215803.htm> (referer: http://www.gov.cn/banshi/zjpq.htm)
Traceback (most recent call last):
  File "/usr/local/lib/python3.7/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python3.7/site-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/Users/a824810056/Desktop/py2.7-GovSpider/GovSpider2/GovSpider2/spiders/govSpider.py", line 84, in parse_item
    os.mkdir(newPath)
FileNotFoundError: [Errno 2] No such file or directory: '/Users/a824810056/Desktop/py2.7-GovSpider/GovSpider2/foregin/banshi/zjpq'
2019-03-26 15:22:42 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.gov.cn/banshi/2006-08/23/content_368260.htm> (referer: http://www.gov.cn/banshi/wjrs/crj.htm)
Traceback (most recent call last):
  File "/usr/local/lib/python3.7/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python3.7/site-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/Users/a824810056/Desktop/py2.7-GovSpider/GovSpider2/GovSpider2/spiders/govSpider.py", line 84, in parse_item
    os.mkdir(newPath)
FileNotFoundError: [Errno 2] No such file or directory: '/Users/a824810056/Desktop/py2.7-GovSpider/GovSpider2/foregin/banshi/wjrs/crj'
2019-03-26 15:22:42 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.gov.cn/banshi/2006-10/09/content_408005.htm> (referer: http://www.gov.cn/banshi/wjrs/crj.htm)
Traceback (most recent call last):
  File "/usr/local/lib/python3.7/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python3.7/site-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/Users/a824810056/Desktop/py2.7-GovSpider/GovSpider2/GovSpider2/spiders/govSpider.py", line 84, in parse_item
    os.mkdir(newPath)
FileNotFoundError: [Errno 2] No such file or directory: '/Users/a824810056/Desktop/py2.7-GovSpider/GovSpider2/foregin/banshi/wjrs/crj'
2019-03-26 15:22:42 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.gov.cn/banshi/2012-11/19/content_2269877.htm> (referer: http://www.gov.cn/banshi/wjrs/crj.htm)
Traceback (most recent call last):
  File "/usr/local/lib/python3.7/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python3.7/site-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/Users/a824810056/Desktop/py2.7-GovSpider/GovSpider2/GovSpider2/spiders/govSpider.py", line 84, in parse_item
    os.mkdir(newPath)
FileNotFoundError: [Errno 2] No such file or directory: '/Users/a824810056/Desktop/py2.7-GovSpider/GovSpider2/foregin/banshi/wjrs/crj'
2019-03-26 15:22:42 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.gov.cn/banshi/2012-11/19/content_2269878.htm> (referer: http://www.gov.cn/banshi/wjrs/crj.htm)
Traceback (most recent call last):
  File "/usr/local/lib/python3.7/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python3.7/site-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/Users/a824810056/Desktop/py2.7-GovSpider/GovSpider2/GovSpider2/spiders/govSpider.py", line 84, in parse_item
    os.mkdir(newPath)
FileNotFoundError: [Errno 2] No such file or directory: '/Users/a824810056/Desktop/py2.7-GovSpider/GovSpider2/foregin/banshi/wjrs/crj'
2019-03-26 15:22:42 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.gov.cn/banshi/2012-11/19/content_2269879.htm> (referer: http://www.gov.cn/banshi/wjrs/crj.htm)
Traceback (most recent call last):
  File "/usr/local/lib/python3.7/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python3.7/site-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/Users/a824810056/Desktop/py2.7-GovSpider/GovSpider2/GovSpider2/spiders/govSpider.py", line 84, in parse_item
    os.mkdir(newPath)
FileNotFoundError: [Errno 2] No such file or directory: '/Users/a824810056/Desktop/py2.7-GovSpider/GovSpider2/foregin/banshi/wjrs/crj'
2019-03-26 15:22:42 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.gov.cn/banshi/2006-10/09/content_408018.htm> (referer: http://www.gov.cn/banshi/wjrs/crj.htm)
Traceback (most recent call last):
  File "/usr/local/lib/python3.7/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python3.7/site-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/Users/a824810056/Desktop/py2.7-GovSpider/GovSpider2/GovSpider2/spiders/govSpider.py", line 84, in parse_item
    os.mkdir(newPath)
FileNotFoundError: [Errno 2] No such file or directory: '/Users/a824810056/Desktop/py2.7-GovSpider/GovSpider2/foregin/banshi/wjrs/crj'
2019-03-26 15:22:42 [scrapy.core.engine] INFO: Closing spider (finished)
2019-03-26 15:22:42 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 11301,
 'downloader/request_count': 31,
 'downloader/request_method_count/GET': 31,
 'downloader/response_bytes': 515824,
 'downloader/response_count': 31,
 'downloader/response_status_count/200': 31,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2019, 3, 26, 7, 22, 42, 484197),
 'log_count/ERROR': 28,
 'log_count/INFO': 9,
 'memusage/max': 50270208,
 'memusage/startup': 50266112,
 'offsite/domains': 1,
 'offsite/filtered': 1,
 'request_depth_max': 1,
 'response_received_count': 31,
 'robotstxt/request_count': 1,
 'robotstxt/response_count': 1,
 'robotstxt/response_status_count/200': 1,
 'scheduler/dequeued': 30,
 'scheduler/dequeued/memory': 30,
 'scheduler/enqueued': 30,
 'scheduler/enqueued/memory': 30,
 'spider_exceptions/FileNotFoundError': 28,
 'start_time': datetime.datetime(2019, 3, 26, 7, 22, 40, 764176)}
2019-03-26 15:22:42 [scrapy.core.engine] INFO: Spider closed (finished)
2019-03-26 15:24:32 [scrapy.utils.log] INFO: Scrapy 1.6.0 started (bot: GovSpider2)
2019-03-26 15:24:32 [scrapy.utils.log] INFO: Versions: lxml 4.3.2.0, libxml2 2.9.9, cssselect 1.0.3, parsel 1.5.1, w3lib 1.20.0, Twisted 18.9.0, Python 3.7.2 (default, Feb 13 2019, 10:07:58) - [Clang 10.0.0 (clang-1000.11.45.5)], pyOpenSSL 19.0.0 (OpenSSL 1.1.1b  26 Feb 2019), cryptography 2.6.1, Platform Darwin-18.2.0-x86_64-i386-64bit
2019-03-26 15:24:32 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'GovSpider2', 'LOG_FILE': 'log/spiderlog20190326.txt', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'GovSpider2.spiders', 'ROBOTSTXT_OBEY': True, 'SPIDER_MODULES': ['GovSpider2.spiders']}
2019-03-26 15:24:32 [scrapy.extensions.telnet] INFO: Telnet Password: 08d4cd263313ccd3
2019-03-26 15:24:32 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats']
2019-03-26 15:24:32 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.robotstxt.RobotsTxtMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2019-03-26 15:24:32 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2019-03-26 15:24:32 [scrapy.middleware] INFO: Enabled item pipelines:
['GovSpider2.pipelines.Govspider2Pipeline']
2019-03-26 15:24:32 [scrapy.core.engine] INFO: Spider opened
2019-03-26 15:24:32 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-03-26 15:24:32 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023
2019-03-26 15:24:34 [scrapy.core.engine] INFO: Closing spider (finished)
2019-03-26 15:24:34 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 11301,
 'downloader/request_count': 31,
 'downloader/request_method_count/GET': 31,
 'downloader/response_bytes': 515826,
 'downloader/response_count': 31,
 'downloader/response_status_count/200': 31,
 'dupefilter/filtered': 28,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2019, 3, 26, 7, 24, 34, 28675),
 'log_count/INFO': 9,
 'memusage/max': 49827840,
 'memusage/startup': 49827840,
 'offsite/domains': 1,
 'offsite/filtered': 1,
 'request_depth_max': 2,
 'response_received_count': 31,
 'robotstxt/request_count': 1,
 'robotstxt/response_count': 1,
 'robotstxt/response_status_count/200': 1,
 'scheduler/dequeued': 30,
 'scheduler/dequeued/memory': 30,
 'scheduler/enqueued': 30,
 'scheduler/enqueued/memory': 30,
 'start_time': datetime.datetime(2019, 3, 26, 7, 24, 32, 889235)}
2019-03-26 15:24:34 [scrapy.core.engine] INFO: Spider closed (finished)
2019-03-26 15:25:21 [scrapy.utils.log] INFO: Scrapy 1.6.0 started (bot: GovSpider2)
2019-03-26 15:25:21 [scrapy.utils.log] INFO: Versions: lxml 4.3.2.0, libxml2 2.9.9, cssselect 1.0.3, parsel 1.5.1, w3lib 1.20.0, Twisted 18.9.0, Python 3.7.2 (default, Feb 13 2019, 10:07:58) - [Clang 10.0.0 (clang-1000.11.45.5)], pyOpenSSL 19.0.0 (OpenSSL 1.1.1b  26 Feb 2019), cryptography 2.6.1, Platform Darwin-18.2.0-x86_64-i386-64bit
2019-03-26 15:25:21 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'GovSpider2', 'LOG_FILE': 'log/spiderlog20190326.txt', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'GovSpider2.spiders', 'ROBOTSTXT_OBEY': True, 'SPIDER_MODULES': ['GovSpider2.spiders']}
2019-03-26 15:25:21 [scrapy.extensions.telnet] INFO: Telnet Password: ac596d194d5a5dc9
2019-03-26 15:25:21 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats']
2019-03-26 15:25:21 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.robotstxt.RobotsTxtMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2019-03-26 15:25:21 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2019-03-26 15:25:21 [scrapy.middleware] INFO: Enabled item pipelines:
['GovSpider2.pipelines.Govspider2Pipeline']
2019-03-26 15:25:21 [scrapy.core.engine] INFO: Spider opened
2019-03-26 15:25:21 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-03-26 15:25:21 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023
2019-03-26 15:25:21 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.gov.cn/banshi/2005-07/06/content_12279.htm> (referer: http://www.gov.cn/banshi/wjrs/crj.htm)
Traceback (most recent call last):
  File "/usr/local/lib/python3.7/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python3.7/site-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/Users/a824810056/Desktop/py2.7-GovSpider/GovSpider2/GovSpider2/spiders/govSpider.py", line 84, in parse_item
    os.mkdir(newPath)
FileNotFoundError: [Errno 2] No such file or directory: '/Users/a824810056/Desktop/py2.7-GovSpider/GovSpider2/foregin/haha/aa/aa'
2019-03-26 15:25:21 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.gov.cn/banshi/2005-10/10/content_75518.htm> (referer: http://www.gov.cn/banshi/zjpq.htm)
Traceback (most recent call last):
  File "/usr/local/lib/python3.7/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python3.7/site-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/Users/a824810056/Desktop/py2.7-GovSpider/GovSpider2/GovSpider2/spiders/govSpider.py", line 84, in parse_item
    os.mkdir(newPath)
FileNotFoundError: [Errno 2] No such file or directory: '/Users/a824810056/Desktop/py2.7-GovSpider/GovSpider2/foregin/haha/aa/aa'
2019-03-26 15:25:21 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.gov.cn/banshi/2005-06/23/content_75551.htm> (referer: http://www.gov.cn/banshi/zjpq.htm)
Traceback (most recent call last):
  File "/usr/local/lib/python3.7/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python3.7/site-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/Users/a824810056/Desktop/py2.7-GovSpider/GovSpider2/GovSpider2/spiders/govSpider.py", line 84, in parse_item
    os.mkdir(newPath)
FileNotFoundError: [Errno 2] No such file or directory: '/Users/a824810056/Desktop/py2.7-GovSpider/GovSpider2/foregin/haha/aa/aa'
2019-03-26 15:25:21 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.gov.cn/banshi/2005-10/10/content_75526.htm> (referer: http://www.gov.cn/banshi/zjpq.htm)
Traceback (most recent call last):
  File "/usr/local/lib/python3.7/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python3.7/site-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/Users/a824810056/Desktop/py2.7-GovSpider/GovSpider2/GovSpider2/spiders/govSpider.py", line 84, in parse_item
    os.mkdir(newPath)
FileNotFoundError: [Errno 2] No such file or directory: '/Users/a824810056/Desktop/py2.7-GovSpider/GovSpider2/foregin/haha/aa/aa'
2019-03-26 15:25:21 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.gov.cn/banshi/2005-10/10/content_75529.htm> (referer: http://www.gov.cn/banshi/zjpq.htm)
Traceback (most recent call last):
  File "/usr/local/lib/python3.7/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python3.7/site-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/Users/a824810056/Desktop/py2.7-GovSpider/GovSpider2/GovSpider2/spiders/govSpider.py", line 84, in parse_item
    os.mkdir(newPath)
FileNotFoundError: [Errno 2] No such file or directory: '/Users/a824810056/Desktop/py2.7-GovSpider/GovSpider2/foregin/haha/aa/aa'
2019-03-26 15:25:21 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.gov.cn/banshi/2005-10/10/content_75453.htm> (referer: http://www.gov.cn/banshi/zjpq.htm)
Traceback (most recent call last):
  File "/usr/local/lib/python3.7/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python3.7/site-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/Users/a824810056/Desktop/py2.7-GovSpider/GovSpider2/GovSpider2/spiders/govSpider.py", line 84, in parse_item
    os.mkdir(newPath)
FileNotFoundError: [Errno 2] No such file or directory: '/Users/a824810056/Desktop/py2.7-GovSpider/GovSpider2/foregin/haha/aa/aa'
2019-03-26 15:25:21 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.gov.cn/banshi/2005-10/10/content_75460.htm> (referer: http://www.gov.cn/banshi/zjpq.htm)
Traceback (most recent call last):
  File "/usr/local/lib/python3.7/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python3.7/site-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/Users/a824810056/Desktop/py2.7-GovSpider/GovSpider2/GovSpider2/spiders/govSpider.py", line 84, in parse_item
    os.mkdir(newPath)
FileNotFoundError: [Errno 2] No such file or directory: '/Users/a824810056/Desktop/py2.7-GovSpider/GovSpider2/foregin/haha/aa/aa'
2019-03-26 15:25:21 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.gov.cn/banshi/2005-10/10/content_75500.htm> (referer: http://www.gov.cn/banshi/zjpq.htm)
Traceback (most recent call last):
  File "/usr/local/lib/python3.7/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python3.7/site-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/Users/a824810056/Desktop/py2.7-GovSpider/GovSpider2/GovSpider2/spiders/govSpider.py", line 84, in parse_item
    os.mkdir(newPath)
FileNotFoundError: [Errno 2] No such file or directory: '/Users/a824810056/Desktop/py2.7-GovSpider/GovSpider2/foregin/haha/aa/aa'
2019-03-26 15:25:21 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.gov.cn/banshi/2005-05/26/content_1300.htm> (referer: http://www.gov.cn/banshi/wjrs/crj.htm)
Traceback (most recent call last):
  File "/usr/local/lib/python3.7/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python3.7/site-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/Users/a824810056/Desktop/py2.7-GovSpider/GovSpider2/GovSpider2/spiders/govSpider.py", line 84, in parse_item
    os.mkdir(newPath)
FileNotFoundError: [Errno 2] No such file or directory: '/Users/a824810056/Desktop/py2.7-GovSpider/GovSpider2/foregin/haha/aa/aa'
2019-03-26 15:25:21 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.gov.cn/banshi/2005-10/10/content_75553.htm> (referer: http://www.gov.cn/banshi/zjpq.htm)
Traceback (most recent call last):
  File "/usr/local/lib/python3.7/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python3.7/site-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/Users/a824810056/Desktop/py2.7-GovSpider/GovSpider2/GovSpider2/spiders/govSpider.py", line 84, in parse_item
    os.mkdir(newPath)
FileNotFoundError: [Errno 2] No such file or directory: '/Users/a824810056/Desktop/py2.7-GovSpider/GovSpider2/foregin/haha/aa/aa'
2019-03-26 15:25:21 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.gov.cn/banshi/2006-10/09/content_408016.htm> (referer: http://www.gov.cn/banshi/wjrs/crj.htm)
Traceback (most recent call last):
  File "/usr/local/lib/python3.7/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python3.7/site-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/Users/a824810056/Desktop/py2.7-GovSpider/GovSpider2/GovSpider2/spiders/govSpider.py", line 84, in parse_item
    os.mkdir(newPath)
FileNotFoundError: [Errno 2] No such file or directory: '/Users/a824810056/Desktop/py2.7-GovSpider/GovSpider2/foregin/haha/aa/aa'
2019-03-26 15:25:21 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.gov.cn/banshi/2005-07/08/content_13036.htm> (referer: http://www.gov.cn/banshi/wjrs/crj.htm)
Traceback (most recent call last):
  File "/usr/local/lib/python3.7/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python3.7/site-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/Users/a824810056/Desktop/py2.7-GovSpider/GovSpider2/GovSpider2/spiders/govSpider.py", line 84, in parse_item
    os.mkdir(newPath)
FileNotFoundError: [Errno 2] No such file or directory: '/Users/a824810056/Desktop/py2.7-GovSpider/GovSpider2/foregin/haha/aa/aa'
2019-03-26 15:25:21 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.gov.cn/banshi/2006-10/09/content_408014.htm> (referer: http://www.gov.cn/banshi/wjrs/crj.htm)
Traceback (most recent call last):
  File "/usr/local/lib/python3.7/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python3.7/site-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/Users/a824810056/Desktop/py2.7-GovSpider/GovSpider2/GovSpider2/spiders/govSpider.py", line 84, in parse_item
    os.mkdir(newPath)
FileNotFoundError: [Errno 2] No such file or directory: '/Users/a824810056/Desktop/py2.7-GovSpider/GovSpider2/foregin/haha/aa/aa'
2019-03-26 15:25:21 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.gov.cn/banshi/2005-06/08/content_4837.htm> (referer: http://www.gov.cn/banshi/wjrs/crj.htm)
Traceback (most recent call last):
  File "/usr/local/lib/python3.7/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python3.7/site-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/Users/a824810056/Desktop/py2.7-GovSpider/GovSpider2/GovSpider2/spiders/govSpider.py", line 84, in parse_item
    os.mkdir(newPath)
FileNotFoundError: [Errno 2] No such file or directory: '/Users/a824810056/Desktop/py2.7-GovSpider/GovSpider2/foregin/haha/aa/aa'
2019-03-26 15:25:21 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.gov.cn/banshi/2005-06/08/content_4836.htm> (referer: http://www.gov.cn/banshi/wjrs/crj.htm)
Traceback (most recent call last):
  File "/usr/local/lib/python3.7/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python3.7/site-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/Users/a824810056/Desktop/py2.7-GovSpider/GovSpider2/GovSpider2/spiders/govSpider.py", line 84, in parse_item
    os.mkdir(newPath)
FileNotFoundError: [Errno 2] No such file or directory: '/Users/a824810056/Desktop/py2.7-GovSpider/GovSpider2/foregin/haha/aa/aa'
2019-03-26 15:25:21 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.gov.cn/banshi/2005-09/12/content_31017.htm> (referer: http://www.gov.cn/banshi/wjrs/crj.htm)
Traceback (most recent call last):
  File "/usr/local/lib/python3.7/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python3.7/site-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/Users/a824810056/Desktop/py2.7-GovSpider/GovSpider2/GovSpider2/spiders/govSpider.py", line 84, in parse_item
    os.mkdir(newPath)
FileNotFoundError: [Errno 2] No such file or directory: '/Users/a824810056/Desktop/py2.7-GovSpider/GovSpider2/foregin/haha/aa/aa'
2019-03-26 15:25:21 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.gov.cn/banshi/2006-08/23/content_368260.htm> (referer: http://www.gov.cn/banshi/wjrs/crj.htm)
Traceback (most recent call last):
  File "/usr/local/lib/python3.7/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python3.7/site-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/Users/a824810056/Desktop/py2.7-GovSpider/GovSpider2/GovSpider2/spiders/govSpider.py", line 84, in parse_item
    os.mkdir(newPath)
FileNotFoundError: [Errno 2] No such file or directory: '/Users/a824810056/Desktop/py2.7-GovSpider/GovSpider2/foregin/haha/aa/aa'
2019-03-26 15:25:21 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.gov.cn/banshi/2005-06/23/content_8734.htm> (referer: http://www.gov.cn/banshi/zjpq.htm)
Traceback (most recent call last):
  File "/usr/local/lib/python3.7/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python3.7/site-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/Users/a824810056/Desktop/py2.7-GovSpider/GovSpider2/GovSpider2/spiders/govSpider.py", line 84, in parse_item
    os.mkdir(newPath)
FileNotFoundError: [Errno 2] No such file or directory: '/Users/a824810056/Desktop/py2.7-GovSpider/GovSpider2/foregin/haha/aa/aa'
2019-03-26 15:25:21 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.gov.cn/banshi/2006-10/09/content_408018.htm> (referer: http://www.gov.cn/banshi/wjrs/crj.htm)
Traceback (most recent call last):
  File "/usr/local/lib/python3.7/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python3.7/site-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/Users/a824810056/Desktop/py2.7-GovSpider/GovSpider2/GovSpider2/spiders/govSpider.py", line 84, in parse_item
    os.mkdir(newPath)
FileNotFoundError: [Errno 2] No such file or directory: '/Users/a824810056/Desktop/py2.7-GovSpider/GovSpider2/foregin/haha/aa/aa'
2019-03-26 15:25:21 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.gov.cn/banshi/2006-03/02/content_215803.htm> (referer: http://www.gov.cn/banshi/zjpq.htm)
Traceback (most recent call last):
  File "/usr/local/lib/python3.7/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python3.7/site-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/Users/a824810056/Desktop/py2.7-GovSpider/GovSpider2/GovSpider2/spiders/govSpider.py", line 84, in parse_item
    os.mkdir(newPath)
FileNotFoundError: [Errno 2] No such file or directory: '/Users/a824810056/Desktop/py2.7-GovSpider/GovSpider2/foregin/haha/aa/aa'
2019-03-26 15:25:21 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.gov.cn/banshi/2006-10/09/content_408005.htm> (referer: http://www.gov.cn/banshi/wjrs/crj.htm)
Traceback (most recent call last):
  File "/usr/local/lib/python3.7/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python3.7/site-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/Users/a824810056/Desktop/py2.7-GovSpider/GovSpider2/GovSpider2/spiders/govSpider.py", line 84, in parse_item
    os.mkdir(newPath)
FileNotFoundError: [Errno 2] No such file or directory: '/Users/a824810056/Desktop/py2.7-GovSpider/GovSpider2/foregin/haha/aa/aa'
2019-03-26 15:25:21 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.gov.cn/banshi/2012-11/19/content_2269880.htm> (referer: http://www.gov.cn/banshi/wjrs/crj.htm)
Traceback (most recent call last):
  File "/usr/local/lib/python3.7/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python3.7/site-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/Users/a824810056/Desktop/py2.7-GovSpider/GovSpider2/GovSpider2/spiders/govSpider.py", line 84, in parse_item
    os.mkdir(newPath)
FileNotFoundError: [Errno 2] No such file or directory: '/Users/a824810056/Desktop/py2.7-GovSpider/GovSpider2/foregin/haha/aa/aa'
2019-03-26 15:25:21 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.gov.cn/banshi/2012-11/19/content_2269877.htm> (referer: http://www.gov.cn/banshi/wjrs/crj.htm)
Traceback (most recent call last):
  File "/usr/local/lib/python3.7/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python3.7/site-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/Users/a824810056/Desktop/py2.7-GovSpider/GovSpider2/GovSpider2/spiders/govSpider.py", line 84, in parse_item
    os.mkdir(newPath)
FileNotFoundError: [Errno 2] No such file or directory: '/Users/a824810056/Desktop/py2.7-GovSpider/GovSpider2/foregin/haha/aa/aa'
2019-03-26 15:25:21 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.gov.cn/banshi/2012-11/19/content_2269876.htm> (referer: http://www.gov.cn/banshi/wjrs/crj.htm)
Traceback (most recent call last):
  File "/usr/local/lib/python3.7/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python3.7/site-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/Users/a824810056/Desktop/py2.7-GovSpider/GovSpider2/GovSpider2/spiders/govSpider.py", line 84, in parse_item
    os.mkdir(newPath)
FileNotFoundError: [Errno 2] No such file or directory: '/Users/a824810056/Desktop/py2.7-GovSpider/GovSpider2/foregin/haha/aa/aa'
2019-03-26 15:25:21 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.gov.cn/banshi/2006-10/09/content_408010.htm> (referer: http://www.gov.cn/banshi/wjrs/crj.htm)
Traceback (most recent call last):
  File "/usr/local/lib/python3.7/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python3.7/site-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/Users/a824810056/Desktop/py2.7-GovSpider/GovSpider2/GovSpider2/spiders/govSpider.py", line 84, in parse_item
    os.mkdir(newPath)
FileNotFoundError: [Errno 2] No such file or directory: '/Users/a824810056/Desktop/py2.7-GovSpider/GovSpider2/foregin/haha/aa/aa'
2019-03-26 15:25:21 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.gov.cn/banshi/2007-05/10/content_610216.htm> (referer: http://www.gov.cn/banshi/wjrs/crj.htm)
Traceback (most recent call last):
  File "/usr/local/lib/python3.7/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python3.7/site-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/Users/a824810056/Desktop/py2.7-GovSpider/GovSpider2/GovSpider2/spiders/govSpider.py", line 84, in parse_item
    os.mkdir(newPath)
FileNotFoundError: [Errno 2] No such file or directory: '/Users/a824810056/Desktop/py2.7-GovSpider/GovSpider2/foregin/haha/aa/aa'
2019-03-26 15:25:21 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.gov.cn/banshi/2012-11/19/content_2269878.htm> (referer: http://www.gov.cn/banshi/wjrs/crj.htm)
Traceback (most recent call last):
  File "/usr/local/lib/python3.7/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python3.7/site-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/Users/a824810056/Desktop/py2.7-GovSpider/GovSpider2/GovSpider2/spiders/govSpider.py", line 84, in parse_item
    os.mkdir(newPath)
FileNotFoundError: [Errno 2] No such file or directory: '/Users/a824810056/Desktop/py2.7-GovSpider/GovSpider2/foregin/haha/aa/aa'
2019-03-26 15:25:21 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.gov.cn/banshi/2012-11/19/content_2269879.htm> (referer: http://www.gov.cn/banshi/wjrs/crj.htm)
Traceback (most recent call last):
  File "/usr/local/lib/python3.7/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python3.7/site-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/Users/a824810056/Desktop/py2.7-GovSpider/GovSpider2/GovSpider2/spiders/govSpider.py", line 84, in parse_item
    os.mkdir(newPath)
FileNotFoundError: [Errno 2] No such file or directory: '/Users/a824810056/Desktop/py2.7-GovSpider/GovSpider2/foregin/haha/aa/aa'
2019-03-26 15:25:21 [scrapy.core.engine] INFO: Closing spider (finished)
2019-03-26 15:25:21 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 11301,
 'downloader/request_count': 31,
 'downloader/request_method_count/GET': 31,
 'downloader/response_bytes': 515824,
 'downloader/response_count': 31,
 'downloader/response_status_count/200': 31,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2019, 3, 26, 7, 25, 21, 795000),
 'log_count/ERROR': 28,
 'log_count/INFO': 9,
 'memusage/max': 50032640,
 'memusage/startup': 50032640,
 'offsite/domains': 1,
 'offsite/filtered': 1,
 'request_depth_max': 1,
 'response_received_count': 31,
 'robotstxt/request_count': 1,
 'robotstxt/response_count': 1,
 'robotstxt/response_status_count/200': 1,
 'scheduler/dequeued': 30,
 'scheduler/dequeued/memory': 30,
 'scheduler/enqueued': 30,
 'scheduler/enqueued/memory': 30,
 'spider_exceptions/FileNotFoundError': 28,
 'start_time': datetime.datetime(2019, 3, 26, 7, 25, 21, 136581)}
2019-03-26 15:25:21 [scrapy.core.engine] INFO: Spider closed (finished)
2019-03-26 15:25:58 [scrapy.utils.log] INFO: Scrapy 1.6.0 started (bot: GovSpider2)
2019-03-26 15:25:58 [scrapy.utils.log] INFO: Versions: lxml 4.3.2.0, libxml2 2.9.9, cssselect 1.0.3, parsel 1.5.1, w3lib 1.20.0, Twisted 18.9.0, Python 3.7.2 (default, Feb 13 2019, 10:07:58) - [Clang 10.0.0 (clang-1000.11.45.5)], pyOpenSSL 19.0.0 (OpenSSL 1.1.1b  26 Feb 2019), cryptography 2.6.1, Platform Darwin-18.2.0-x86_64-i386-64bit
2019-03-26 15:25:58 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'GovSpider2', 'LOG_FILE': 'log/spiderlog20190326.txt', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'GovSpider2.spiders', 'ROBOTSTXT_OBEY': True, 'SPIDER_MODULES': ['GovSpider2.spiders']}
2019-03-26 15:25:58 [scrapy.extensions.telnet] INFO: Telnet Password: 3c9aaacc6551ef28
2019-03-26 15:25:58 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats']
2019-03-26 15:25:58 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.robotstxt.RobotsTxtMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2019-03-26 15:25:58 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2019-03-26 15:25:58 [scrapy.middleware] INFO: Enabled item pipelines:
['GovSpider2.pipelines.Govspider2Pipeline']
2019-03-26 15:25:58 [scrapy.core.engine] INFO: Spider opened
2019-03-26 15:25:58 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-03-26 15:25:58 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023
2019-03-26 15:25:59 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.gov.cn/banshi/2005-05/26/content_1300.htm> (referer: http://www.gov.cn/banshi/wjrs/crj.htm)
Traceback (most recent call last):
  File "/usr/local/lib/python3.7/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python3.7/site-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/Users/a824810056/Desktop/py2.7-GovSpider/GovSpider2/GovSpider2/spiders/govSpider.py", line 84, in parse_item
    os.mkdir(newPath)
FileNotFoundError: [Errno 2] No such file or directory: '/Users/a824810056/Desktop/py2.7-GovSpider/GovSpider2/foregin/haha/aa/aa'
2019-03-26 15:25:59 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.gov.cn/banshi/2005-07/06/content_12279.htm> (referer: http://www.gov.cn/banshi/wjrs/crj.htm)
Traceback (most recent call last):
  File "/usr/local/lib/python3.7/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python3.7/site-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/Users/a824810056/Desktop/py2.7-GovSpider/GovSpider2/GovSpider2/spiders/govSpider.py", line 84, in parse_item
    os.mkdir(newPath)
FileNotFoundError: [Errno 2] No such file or directory: '/Users/a824810056/Desktop/py2.7-GovSpider/GovSpider2/foregin/haha/aa/aa'
2019-03-26 15:25:59 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.gov.cn/banshi/2006-10/09/content_408014.htm> (referer: http://www.gov.cn/banshi/wjrs/crj.htm)
Traceback (most recent call last):
  File "/usr/local/lib/python3.7/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python3.7/site-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/Users/a824810056/Desktop/py2.7-GovSpider/GovSpider2/GovSpider2/spiders/govSpider.py", line 84, in parse_item
    os.mkdir(newPath)
FileNotFoundError: [Errno 2] No such file or directory: '/Users/a824810056/Desktop/py2.7-GovSpider/GovSpider2/foregin/haha/aa/aa'
2019-03-26 15:25:59 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.gov.cn/banshi/2005-09/12/content_31017.htm> (referer: http://www.gov.cn/banshi/wjrs/crj.htm)
Traceback (most recent call last):
  File "/usr/local/lib/python3.7/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python3.7/site-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/Users/a824810056/Desktop/py2.7-GovSpider/GovSpider2/GovSpider2/spiders/govSpider.py", line 84, in parse_item
    os.mkdir(newPath)
FileNotFoundError: [Errno 2] No such file or directory: '/Users/a824810056/Desktop/py2.7-GovSpider/GovSpider2/foregin/haha/aa/aa'
2019-03-26 15:25:59 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.gov.cn/banshi/2006-10/09/content_408010.htm> (referer: http://www.gov.cn/banshi/wjrs/crj.htm)
Traceback (most recent call last):
  File "/usr/local/lib/python3.7/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python3.7/site-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/Users/a824810056/Desktop/py2.7-GovSpider/GovSpider2/GovSpider2/spiders/govSpider.py", line 84, in parse_item
    os.mkdir(newPath)
FileNotFoundError: [Errno 2] No such file or directory: '/Users/a824810056/Desktop/py2.7-GovSpider/GovSpider2/foregin/haha/aa/aa'
2019-03-26 15:25:59 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.gov.cn/banshi/2005-07/08/content_13036.htm> (referer: http://www.gov.cn/banshi/wjrs/crj.htm)
Traceback (most recent call last):
  File "/usr/local/lib/python3.7/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python3.7/site-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/Users/a824810056/Desktop/py2.7-GovSpider/GovSpider2/GovSpider2/spiders/govSpider.py", line 84, in parse_item
    os.mkdir(newPath)
FileNotFoundError: [Errno 2] No such file or directory: '/Users/a824810056/Desktop/py2.7-GovSpider/GovSpider2/foregin/haha/aa/aa'
2019-03-26 15:25:59 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.gov.cn/banshi/2006-10/09/content_408016.htm> (referer: http://www.gov.cn/banshi/wjrs/crj.htm)
Traceback (most recent call last):
  File "/usr/local/lib/python3.7/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python3.7/site-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/Users/a824810056/Desktop/py2.7-GovSpider/GovSpider2/GovSpider2/spiders/govSpider.py", line 84, in parse_item
    os.mkdir(newPath)
FileNotFoundError: [Errno 2] No such file or directory: '/Users/a824810056/Desktop/py2.7-GovSpider/GovSpider2/foregin/haha/aa/aa'
2019-03-26 15:25:59 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.gov.cn/banshi/2006-08/23/content_368260.htm> (referer: http://www.gov.cn/banshi/wjrs/crj.htm)
Traceback (most recent call last):
  File "/usr/local/lib/python3.7/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python3.7/site-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/Users/a824810056/Desktop/py2.7-GovSpider/GovSpider2/GovSpider2/spiders/govSpider.py", line 84, in parse_item
    os.mkdir(newPath)
FileNotFoundError: [Errno 2] No such file or directory: '/Users/a824810056/Desktop/py2.7-GovSpider/GovSpider2/foregin/haha/aa/aa'
2019-03-26 15:25:59 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.gov.cn/banshi/2005-06/08/content_4836.htm> (referer: http://www.gov.cn/banshi/wjrs/crj.htm)
Traceback (most recent call last):
  File "/usr/local/lib/python3.7/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python3.7/site-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/Users/a824810056/Desktop/py2.7-GovSpider/GovSpider2/GovSpider2/spiders/govSpider.py", line 84, in parse_item
    os.mkdir(newPath)
FileNotFoundError: [Errno 2] No such file or directory: '/Users/a824810056/Desktop/py2.7-GovSpider/GovSpider2/foregin/haha/aa/aa'
2019-03-26 15:25:59 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.gov.cn/banshi/2005-10/10/content_75518.htm> (referer: http://www.gov.cn/banshi/zjpq.htm)
Traceback (most recent call last):
  File "/usr/local/lib/python3.7/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python3.7/site-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/Users/a824810056/Desktop/py2.7-GovSpider/GovSpider2/GovSpider2/spiders/govSpider.py", line 84, in parse_item
    os.mkdir(newPath)
FileNotFoundError: [Errno 2] No such file or directory: '/Users/a824810056/Desktop/py2.7-GovSpider/GovSpider2/foregin/haha/aa/aa'
2019-03-26 15:25:59 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.gov.cn/banshi/2006-10/09/content_408005.htm> (referer: http://www.gov.cn/banshi/wjrs/crj.htm)
Traceback (most recent call last):
  File "/usr/local/lib/python3.7/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python3.7/site-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/Users/a824810056/Desktop/py2.7-GovSpider/GovSpider2/GovSpider2/spiders/govSpider.py", line 84, in parse_item
    os.mkdir(newPath)
FileNotFoundError: [Errno 2] No such file or directory: '/Users/a824810056/Desktop/py2.7-GovSpider/GovSpider2/foregin/haha/aa/aa'
2019-03-26 15:25:59 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.gov.cn/banshi/2005-06/08/content_4837.htm> (referer: http://www.gov.cn/banshi/wjrs/crj.htm)
Traceback (most recent call last):
  File "/usr/local/lib/python3.7/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python3.7/site-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/Users/a824810056/Desktop/py2.7-GovSpider/GovSpider2/GovSpider2/spiders/govSpider.py", line 84, in parse_item
    os.mkdir(newPath)
FileNotFoundError: [Errno 2] No such file or directory: '/Users/a824810056/Desktop/py2.7-GovSpider/GovSpider2/foregin/haha/aa/aa'
2019-03-26 15:25:59 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.gov.cn/banshi/2005-10/10/content_75529.htm> (referer: http://www.gov.cn/banshi/zjpq.htm)
Traceback (most recent call last):
  File "/usr/local/lib/python3.7/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python3.7/site-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/Users/a824810056/Desktop/py2.7-GovSpider/GovSpider2/GovSpider2/spiders/govSpider.py", line 84, in parse_item
    os.mkdir(newPath)
FileNotFoundError: [Errno 2] No such file or directory: '/Users/a824810056/Desktop/py2.7-GovSpider/GovSpider2/foregin/haha/aa/aa'
2019-03-26 15:25:59 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.gov.cn/banshi/2005-10/10/content_75526.htm> (referer: http://www.gov.cn/banshi/zjpq.htm)
Traceback (most recent call last):
  File "/usr/local/lib/python3.7/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python3.7/site-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/Users/a824810056/Desktop/py2.7-GovSpider/GovSpider2/GovSpider2/spiders/govSpider.py", line 84, in parse_item
    os.mkdir(newPath)
FileNotFoundError: [Errno 2] No such file or directory: '/Users/a824810056/Desktop/py2.7-GovSpider/GovSpider2/foregin/haha/aa/aa'
2019-03-26 15:25:59 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.gov.cn/banshi/2005-10/10/content_75453.htm> (referer: http://www.gov.cn/banshi/zjpq.htm)
Traceback (most recent call last):
  File "/usr/local/lib/python3.7/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python3.7/site-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/Users/a824810056/Desktop/py2.7-GovSpider/GovSpider2/GovSpider2/spiders/govSpider.py", line 84, in parse_item
    os.mkdir(newPath)
FileNotFoundError: [Errno 2] No such file or directory: '/Users/a824810056/Desktop/py2.7-GovSpider/GovSpider2/foregin/haha/aa/aa'
2019-03-26 15:25:59 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.gov.cn/banshi/2006-10/09/content_408018.htm> (referer: http://www.gov.cn/banshi/wjrs/crj.htm)
Traceback (most recent call last):
  File "/usr/local/lib/python3.7/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python3.7/site-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/Users/a824810056/Desktop/py2.7-GovSpider/GovSpider2/GovSpider2/spiders/govSpider.py", line 84, in parse_item
    os.mkdir(newPath)
FileNotFoundError: [Errno 2] No such file or directory: '/Users/a824810056/Desktop/py2.7-GovSpider/GovSpider2/foregin/haha/aa/aa'
2019-03-26 15:25:59 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.gov.cn/banshi/2005-10/10/content_75500.htm> (referer: http://www.gov.cn/banshi/zjpq.htm)
Traceback (most recent call last):
  File "/usr/local/lib/python3.7/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python3.7/site-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/Users/a824810056/Desktop/py2.7-GovSpider/GovSpider2/GovSpider2/spiders/govSpider.py", line 84, in parse_item
    os.mkdir(newPath)
FileNotFoundError: [Errno 2] No such file or directory: '/Users/a824810056/Desktop/py2.7-GovSpider/GovSpider2/foregin/haha/aa/aa'
2019-03-26 15:25:59 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.gov.cn/banshi/2005-10/10/content_75460.htm> (referer: http://www.gov.cn/banshi/zjpq.htm)
Traceback (most recent call last):
  File "/usr/local/lib/python3.7/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python3.7/site-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/Users/a824810056/Desktop/py2.7-GovSpider/GovSpider2/GovSpider2/spiders/govSpider.py", line 84, in parse_item
    os.mkdir(newPath)
FileNotFoundError: [Errno 2] No such file or directory: '/Users/a824810056/Desktop/py2.7-GovSpider/GovSpider2/foregin/haha/aa/aa'
2019-03-26 15:25:59 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.gov.cn/banshi/2005-10/10/content_75553.htm> (referer: http://www.gov.cn/banshi/zjpq.htm)
Traceback (most recent call last):
  File "/usr/local/lib/python3.7/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python3.7/site-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/Users/a824810056/Desktop/py2.7-GovSpider/GovSpider2/GovSpider2/spiders/govSpider.py", line 84, in parse_item
    os.mkdir(newPath)
FileNotFoundError: [Errno 2] No such file or directory: '/Users/a824810056/Desktop/py2.7-GovSpider/GovSpider2/foregin/haha/aa/aa'
2019-03-26 15:25:59 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.gov.cn/banshi/2005-06/23/content_75551.htm> (referer: http://www.gov.cn/banshi/zjpq.htm)
Traceback (most recent call last):
  File "/usr/local/lib/python3.7/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python3.7/site-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/Users/a824810056/Desktop/py2.7-GovSpider/GovSpider2/GovSpider2/spiders/govSpider.py", line 84, in parse_item
    os.mkdir(newPath)
FileNotFoundError: [Errno 2] No such file or directory: '/Users/a824810056/Desktop/py2.7-GovSpider/GovSpider2/foregin/haha/aa/aa'
2019-03-26 15:25:59 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.gov.cn/banshi/2007-05/10/content_610216.htm> (referer: http://www.gov.cn/banshi/wjrs/crj.htm)
Traceback (most recent call last):
  File "/usr/local/lib/python3.7/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python3.7/site-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/Users/a824810056/Desktop/py2.7-GovSpider/GovSpider2/GovSpider2/spiders/govSpider.py", line 84, in parse_item
    os.mkdir(newPath)
FileNotFoundError: [Errno 2] No such file or directory: '/Users/a824810056/Desktop/py2.7-GovSpider/GovSpider2/foregin/haha/aa/aa'
2019-03-26 15:25:59 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.gov.cn/banshi/2005-06/23/content_8734.htm> (referer: http://www.gov.cn/banshi/zjpq.htm)
Traceback (most recent call last):
  File "/usr/local/lib/python3.7/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python3.7/site-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/Users/a824810056/Desktop/py2.7-GovSpider/GovSpider2/GovSpider2/spiders/govSpider.py", line 84, in parse_item
    os.mkdir(newPath)
FileNotFoundError: [Errno 2] No such file or directory: '/Users/a824810056/Desktop/py2.7-GovSpider/GovSpider2/foregin/haha/aa/aa'
2019-03-26 15:25:59 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.gov.cn/banshi/2006-03/02/content_215803.htm> (referer: http://www.gov.cn/banshi/zjpq.htm)
Traceback (most recent call last):
  File "/usr/local/lib/python3.7/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python3.7/site-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/Users/a824810056/Desktop/py2.7-GovSpider/GovSpider2/GovSpider2/spiders/govSpider.py", line 84, in parse_item
    os.mkdir(newPath)
FileNotFoundError: [Errno 2] No such file or directory: '/Users/a824810056/Desktop/py2.7-GovSpider/GovSpider2/foregin/haha/aa/aa'
2019-03-26 15:25:59 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.gov.cn/banshi/2012-11/19/content_2269879.htm> (referer: http://www.gov.cn/banshi/wjrs/crj.htm)
Traceback (most recent call last):
  File "/usr/local/lib/python3.7/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python3.7/site-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/Users/a824810056/Desktop/py2.7-GovSpider/GovSpider2/GovSpider2/spiders/govSpider.py", line 84, in parse_item
    os.mkdir(newPath)
FileNotFoundError: [Errno 2] No such file or directory: '/Users/a824810056/Desktop/py2.7-GovSpider/GovSpider2/foregin/haha/aa/aa'
2019-03-26 15:25:59 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.gov.cn/banshi/2012-11/19/content_2269876.htm> (referer: http://www.gov.cn/banshi/wjrs/crj.htm)
Traceback (most recent call last):
  File "/usr/local/lib/python3.7/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python3.7/site-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/Users/a824810056/Desktop/py2.7-GovSpider/GovSpider2/GovSpider2/spiders/govSpider.py", line 84, in parse_item
    os.mkdir(newPath)
FileNotFoundError: [Errno 2] No such file or directory: '/Users/a824810056/Desktop/py2.7-GovSpider/GovSpider2/foregin/haha/aa/aa'
2019-03-26 15:25:59 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.gov.cn/banshi/2012-11/19/content_2269877.htm> (referer: http://www.gov.cn/banshi/wjrs/crj.htm)
Traceback (most recent call last):
  File "/usr/local/lib/python3.7/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python3.7/site-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/Users/a824810056/Desktop/py2.7-GovSpider/GovSpider2/GovSpider2/spiders/govSpider.py", line 84, in parse_item
    os.mkdir(newPath)
FileNotFoundError: [Errno 2] No such file or directory: '/Users/a824810056/Desktop/py2.7-GovSpider/GovSpider2/foregin/haha/aa/aa'
2019-03-26 15:25:59 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.gov.cn/banshi/2012-11/19/content_2269878.htm> (referer: http://www.gov.cn/banshi/wjrs/crj.htm)
Traceback (most recent call last):
  File "/usr/local/lib/python3.7/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python3.7/site-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/Users/a824810056/Desktop/py2.7-GovSpider/GovSpider2/GovSpider2/spiders/govSpider.py", line 84, in parse_item
    os.mkdir(newPath)
FileNotFoundError: [Errno 2] No such file or directory: '/Users/a824810056/Desktop/py2.7-GovSpider/GovSpider2/foregin/haha/aa/aa'
2019-03-26 15:25:59 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.gov.cn/banshi/2012-11/19/content_2269880.htm> (referer: http://www.gov.cn/banshi/wjrs/crj.htm)
Traceback (most recent call last):
  File "/usr/local/lib/python3.7/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python3.7/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python3.7/site-packages/scrapy/spiders/crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "/Users/a824810056/Desktop/py2.7-GovSpider/GovSpider2/GovSpider2/spiders/govSpider.py", line 84, in parse_item
    os.mkdir(newPath)
FileNotFoundError: [Errno 2] No such file or directory: '/Users/a824810056/Desktop/py2.7-GovSpider/GovSpider2/foregin/haha/aa/aa'
2019-03-26 15:25:59 [scrapy.core.engine] INFO: Closing spider (finished)
2019-03-26 15:25:59 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 11301,
 'downloader/request_count': 31,
 'downloader/request_method_count/GET': 31,
 'downloader/response_bytes': 515836,
 'downloader/response_count': 31,
 'downloader/response_status_count/200': 31,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2019, 3, 26, 7, 25, 59, 896444),
 'log_count/ERROR': 28,
 'log_count/INFO': 9,
 'memusage/max': 49803264,
 'memusage/startup': 49803264,
 'offsite/domains': 1,
 'offsite/filtered': 1,
 'request_depth_max': 1,
 'response_received_count': 31,
 'robotstxt/request_count': 1,
 'robotstxt/response_count': 1,
 'robotstxt/response_status_count/200': 1,
 'scheduler/dequeued': 30,
 'scheduler/dequeued/memory': 30,
 'scheduler/enqueued': 30,
 'scheduler/enqueued/memory': 30,
 'spider_exceptions/FileNotFoundError': 28,
 'start_time': datetime.datetime(2019, 3, 26, 7, 25, 58, 829700)}
2019-03-26 15:25:59 [scrapy.core.engine] INFO: Spider closed (finished)
2019-03-26 15:27:21 [scrapy.utils.log] INFO: Scrapy 1.6.0 started (bot: GovSpider2)
2019-03-26 15:27:21 [scrapy.utils.log] INFO: Versions: lxml 4.3.2.0, libxml2 2.9.9, cssselect 1.0.3, parsel 1.5.1, w3lib 1.20.0, Twisted 18.9.0, Python 3.7.2 (default, Feb 13 2019, 10:07:58) - [Clang 10.0.0 (clang-1000.11.45.5)], pyOpenSSL 19.0.0 (OpenSSL 1.1.1b  26 Feb 2019), cryptography 2.6.1, Platform Darwin-18.2.0-x86_64-i386-64bit
2019-03-26 15:27:21 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'GovSpider2', 'LOG_FILE': 'log/spiderlog20190326.txt', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'GovSpider2.spiders', 'ROBOTSTXT_OBEY': True, 'SPIDER_MODULES': ['GovSpider2.spiders']}
2019-03-26 15:27:21 [scrapy.extensions.telnet] INFO: Telnet Password: ec86aaf28274d1a3
2019-03-26 15:27:21 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats']
2019-03-26 15:27:21 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.robotstxt.RobotsTxtMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2019-03-26 15:27:21 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2019-03-26 15:27:21 [scrapy.middleware] INFO: Enabled item pipelines:
['GovSpider2.pipelines.Govspider2Pipeline']
2019-03-26 15:27:21 [scrapy.core.engine] INFO: Spider opened
2019-03-26 15:27:21 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-03-26 15:27:21 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023
2019-03-26 15:27:22 [scrapy.core.engine] INFO: Closing spider (finished)
2019-03-26 15:27:22 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 11301,
 'downloader/request_count': 31,
 'downloader/request_method_count/GET': 31,
 'downloader/response_bytes': 515830,
 'downloader/response_count': 31,
 'downloader/response_status_count/200': 31,
 'dupefilter/filtered': 28,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2019, 3, 26, 7, 27, 22, 869610),
 'log_count/INFO': 9,
 'memusage/max': 49905664,
 'memusage/startup': 49905664,
 'offsite/domains': 1,
 'offsite/filtered': 1,
 'request_depth_max': 2,
 'response_received_count': 31,
 'robotstxt/request_count': 1,
 'robotstxt/response_count': 1,
 'robotstxt/response_status_count/200': 1,
 'scheduler/dequeued': 30,
 'scheduler/dequeued/memory': 30,
 'scheduler/enqueued': 30,
 'scheduler/enqueued/memory': 30,
 'start_time': datetime.datetime(2019, 3, 26, 7, 27, 21, 801532)}
2019-03-26 15:27:22 [scrapy.core.engine] INFO: Spider closed (finished)
2019-03-26 15:28:52 [scrapy.utils.log] INFO: Scrapy 1.6.0 started (bot: GovSpider2)
2019-03-26 15:28:52 [scrapy.utils.log] INFO: Versions: lxml 4.3.2.0, libxml2 2.9.9, cssselect 1.0.3, parsel 1.5.1, w3lib 1.20.0, Twisted 18.9.0, Python 3.7.2 (default, Feb 13 2019, 10:07:58) - [Clang 10.0.0 (clang-1000.11.45.5)], pyOpenSSL 19.0.0 (OpenSSL 1.1.1b  26 Feb 2019), cryptography 2.6.1, Platform Darwin-18.2.0-x86_64-i386-64bit
2019-03-26 15:28:52 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'GovSpider2', 'LOG_FILE': 'log/spiderlog20190326.txt', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'GovSpider2.spiders', 'ROBOTSTXT_OBEY': True, 'SPIDER_MODULES': ['GovSpider2.spiders']}
2019-03-26 15:28:52 [scrapy.extensions.telnet] INFO: Telnet Password: 05222c2ecbab6d77
2019-03-26 15:28:52 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats']
2019-03-26 15:28:52 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.robotstxt.RobotsTxtMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2019-03-26 15:28:52 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2019-03-26 15:28:52 [scrapy.middleware] INFO: Enabled item pipelines:
['GovSpider2.pipelines.Govspider2Pipeline']
2019-03-26 15:28:52 [scrapy.core.engine] INFO: Spider opened
2019-03-26 15:28:52 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-03-26 15:28:52 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023
2019-03-26 15:28:58 [scrapy.spidermiddlewares.httperror] INFO: Ignoring response <404 http://www.lm.gov.cn/gb/employment/2004-06/04/content_34302.htm>: HTTP status code is not handled or not allowed
2019-03-26 15:28:58 [scrapy.spidermiddlewares.httperror] INFO: Ignoring response <404 http://www.lm.gov.cn/gb/employment/2004-06/30/content_38180.htm>: HTTP status code is not handled or not allowed
2019-03-26 15:28:58 [scrapy.spidermiddlewares.httperror] INFO: Ignoring response <404 http://www.lm.gov.cn/gb/employment/2004-07/09/content_31814.htm>: HTTP status code is not handled or not allowed
2019-03-26 15:29:01 [scrapy.core.engine] INFO: Closing spider (finished)
2019-03-26 15:29:01 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 89827,
 'downloader/request_count': 244,
 'downloader/request_method_count/GET': 244,
 'downloader/response_bytes': 4283680,
 'downloader/response_count': 244,
 'downloader/response_status_count/200': 240,
 'downloader/response_status_count/404': 4,
 'dupefilter/filtered': 321,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2019, 3, 26, 7, 29, 1, 13357),
 'httperror/response_ignored_count': 3,
 'httperror/response_ignored_status_count/404': 3,
 'log_count/INFO': 12,
 'memusage/max': 49946624,
 'memusage/startup': 49946624,
 'offsite/domains': 3,
 'offsite/filtered': 3,
 'request_depth_max': 2,
 'response_received_count': 244,
 'robotstxt/request_count': 2,
 'robotstxt/response_count': 2,
 'robotstxt/response_status_count/200': 1,
 'robotstxt/response_status_count/404': 1,
 'scheduler/dequeued': 242,
 'scheduler/dequeued/memory': 242,
 'scheduler/enqueued': 242,
 'scheduler/enqueued/memory': 242,
 'start_time': datetime.datetime(2019, 3, 26, 7, 28, 52, 128195)}
2019-03-26 15:29:01 [scrapy.core.engine] INFO: Spider closed (finished)
2019-03-26 15:30:16 [scrapy.utils.log] INFO: Scrapy 1.6.0 started (bot: GovSpider2)
2019-03-26 15:30:16 [scrapy.utils.log] INFO: Versions: lxml 4.3.2.0, libxml2 2.9.9, cssselect 1.0.3, parsel 1.5.1, w3lib 1.20.0, Twisted 18.9.0, Python 3.7.2 (default, Feb 13 2019, 10:07:58) - [Clang 10.0.0 (clang-1000.11.45.5)], pyOpenSSL 19.0.0 (OpenSSL 1.1.1b  26 Feb 2019), cryptography 2.6.1, Platform Darwin-18.2.0-x86_64-i386-64bit
2019-03-26 15:30:16 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'GovSpider2', 'LOG_FILE': 'log/spiderlog20190326.txt', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'GovSpider2.spiders', 'ROBOTSTXT_OBEY': True, 'SPIDER_MODULES': ['GovSpider2.spiders']}
2019-03-26 15:30:16 [scrapy.extensions.telnet] INFO: Telnet Password: d507a8506b3023ed
2019-03-26 15:30:16 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats']
2019-03-26 15:30:16 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.robotstxt.RobotsTxtMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2019-03-26 15:30:16 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2019-03-26 15:30:16 [scrapy.middleware] INFO: Enabled item pipelines:
['GovSpider2.pipelines.Govspider2Pipeline']
2019-03-26 15:30:16 [scrapy.core.engine] INFO: Spider opened
2019-03-26 15:30:16 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-03-26 15:30:16 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023
2019-03-26 15:30:20 [scrapy.spidermiddlewares.httperror] INFO: Ignoring response <404 http://www.lm.gov.cn/gb/employment/2004-06/04/content_34302.htm>: HTTP status code is not handled or not allowed
2019-03-26 15:30:21 [scrapy.spidermiddlewares.httperror] INFO: Ignoring response <404 http://www.lm.gov.cn/gb/employment/2004-07/09/content_31814.htm>: HTTP status code is not handled or not allowed
2019-03-26 15:30:22 [scrapy.spidermiddlewares.httperror] INFO: Ignoring response <404 http://www.lm.gov.cn/gb/employment/2004-06/30/content_38180.htm>: HTTP status code is not handled or not allowed
2019-03-26 15:30:22 [scrapy.core.engine] INFO: Closing spider (finished)
2019-03-26 15:30:22 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 89827,
 'downloader/request_count': 244,
 'downloader/request_method_count/GET': 244,
 'downloader/response_bytes': 4283458,
 'downloader/response_count': 244,
 'downloader/response_status_count/200': 240,
 'downloader/response_status_count/404': 4,
 'dupefilter/filtered': 321,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2019, 3, 26, 7, 30, 22, 990345),
 'httperror/response_ignored_count': 3,
 'httperror/response_ignored_status_count/404': 3,
 'log_count/INFO': 12,
 'memusage/max': 50032640,
 'memusage/startup': 50032640,
 'offsite/domains': 3,
 'offsite/filtered': 3,
 'request_depth_max': 2,
 'response_received_count': 244,
 'robotstxt/request_count': 2,
 'robotstxt/response_count': 2,
 'robotstxt/response_status_count/200': 1,
 'robotstxt/response_status_count/404': 1,
 'scheduler/dequeued': 242,
 'scheduler/dequeued/memory': 242,
 'scheduler/enqueued': 242,
 'scheduler/enqueued/memory': 242,
 'start_time': datetime.datetime(2019, 3, 26, 7, 30, 16, 832378)}
2019-03-26 15:30:22 [scrapy.core.engine] INFO: Spider closed (finished)
2019-03-26 15:30:59 [scrapy.utils.log] INFO: Scrapy 1.6.0 started (bot: GovSpider2)
2019-03-26 15:30:59 [scrapy.utils.log] INFO: Versions: lxml 4.3.2.0, libxml2 2.9.9, cssselect 1.0.3, parsel 1.5.1, w3lib 1.20.0, Twisted 18.9.0, Python 3.7.2 (default, Feb 13 2019, 10:07:58) - [Clang 10.0.0 (clang-1000.11.45.5)], pyOpenSSL 19.0.0 (OpenSSL 1.1.1b  26 Feb 2019), cryptography 2.6.1, Platform Darwin-18.2.0-x86_64-i386-64bit
2019-03-26 15:30:59 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'GovSpider2', 'LOG_FILE': 'log/spiderlog20190326.txt', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'GovSpider2.spiders', 'ROBOTSTXT_OBEY': True, 'SPIDER_MODULES': ['GovSpider2.spiders']}
2019-03-26 15:30:59 [scrapy.extensions.telnet] INFO: Telnet Password: 0eb4900d41474008
2019-03-26 15:30:59 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats']
2019-03-26 15:30:59 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.robotstxt.RobotsTxtMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2019-03-26 15:30:59 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2019-03-26 15:30:59 [scrapy.middleware] INFO: Enabled item pipelines:
['GovSpider2.pipelines.Govspider2Pipeline']
2019-03-26 15:30:59 [scrapy.core.engine] INFO: Spider opened
2019-03-26 15:30:59 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-03-26 15:30:59 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023
2019-03-26 15:31:03 [scrapy.spidermiddlewares.httperror] INFO: Ignoring response <404 http://www.lm.gov.cn/gb/employment/2004-06/04/content_34302.htm>: HTTP status code is not handled or not allowed
2019-03-26 15:31:04 [scrapy.spidermiddlewares.httperror] INFO: Ignoring response <404 http://www.lm.gov.cn/gb/employment/2004-06/30/content_38180.htm>: HTTP status code is not handled or not allowed
2019-03-26 15:31:04 [scrapy.spidermiddlewares.httperror] INFO: Ignoring response <404 http://www.lm.gov.cn/gb/employment/2004-07/09/content_31814.htm>: HTTP status code is not handled or not allowed
2019-03-26 15:31:05 [scrapy.core.engine] INFO: Closing spider (finished)
2019-03-26 15:31:05 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 89887,
 'downloader/request_count': 244,
 'downloader/request_method_count/GET': 244,
 'downloader/response_bytes': 4283438,
 'downloader/response_count': 244,
 'downloader/response_status_count/200': 240,
 'downloader/response_status_count/404': 4,
 'dupefilter/filtered': 321,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2019, 3, 26, 7, 31, 5, 764261),
 'httperror/response_ignored_count': 3,
 'httperror/response_ignored_status_count/404': 3,
 'log_count/INFO': 12,
 'memusage/max': 50077696,
 'memusage/startup': 50077696,
 'offsite/domains': 3,
 'offsite/filtered': 3,
 'request_depth_max': 2,
 'response_received_count': 244,
 'robotstxt/request_count': 2,
 'robotstxt/response_count': 2,
 'robotstxt/response_status_count/200': 1,
 'robotstxt/response_status_count/404': 1,
 'scheduler/dequeued': 242,
 'scheduler/dequeued/memory': 242,
 'scheduler/enqueued': 242,
 'scheduler/enqueued/memory': 242,
 'start_time': datetime.datetime(2019, 3, 26, 7, 30, 59, 724953)}
2019-03-26 15:31:05 [scrapy.core.engine] INFO: Spider closed (finished)
